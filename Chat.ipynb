{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "University of Aberdeen\\\n",
    "Atanas Komsiyski\n",
    "## Evaluating GPT-3.5-turbo for Action Item Extraction in Meeting Transcripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter notebook contains the pipeline for performing chunked linear segmentation for long texts and feeding the transcripts into the GPT model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Libraries\n",
    "To ensure all libraries are installed before executing the notebook run -pip install requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "from openai import OpenAI\n",
    "import tiktoken\n",
    "import tiktoken_ext.openai_public\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "\n",
    "\n",
    "client = OpenAI(api_key=\"<redacted>\") # setting OpenAI API key\n",
    "folder_path = \"ICSI_original_transcripts/transcripts/chosen_transcripts\"   # location of folder containing the meeting transcripts to process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cl100k_base\n"
     ]
    }
   ],
   "source": [
    "# getting the encoding used by our model\n",
    "encoding = tiktoken.encoding_name_for_model(\"gpt-3.5-turbo-0125\") \n",
    "print(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate the number of tokens in a string given the encoding\n",
    "def num_tokens_from_string(string, encoding_name: str):\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function performing the chunked linear segmentation\n",
    "def split_into_chunks(text):\n",
    "    chunks = []\n",
    "    current_chunk = ''\n",
    "    \n",
    "    for line in text:\n",
    "        if num_tokens_from_string(current_chunk, encoding) + num_tokens_from_string(line, encoding) > 16000:  # 16,385 tokens max for gpt-3.5-turbo-0125\n",
    "            # append the current chunk to the list of chunks\n",
    "            chunks.append(current_chunk + \"---\" + \"\\n\")\n",
    "            # start a new chunk with the current line\n",
    "            current_chunk = line\n",
    "        else:\n",
    "            # add the line to the current chunk\n",
    "            current_chunk += line\n",
    "    # append the last chunk\n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk)\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function making the call to the OpenAI API\n",
    "def extract_action_items(list_of_chunks, temperature, max_tokens):\n",
    "    # initialize the list to store completions\n",
    "    completions = []\n",
    "\n",
    "    # iterate over chunks and generate completions\n",
    "    for chunk in list_of_chunks:\n",
    "        completion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Extract all action items from the following meeting transcript and display them in the form of a numbered list.\"},\n",
    "            {\"role\": \"user\", \"content\": chunk}\n",
    "        ],\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "        n=1\n",
    "        )\n",
    "        completions.append(completion)\n",
    "\n",
    "    # concatenate all completions\n",
    "    all_action_items = \"\\n\".join(completion.choices[0].message.content for completion in completions)\n",
    "\n",
    "    return all_action_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function constructing the XML file and cleaning up the GPT output\n",
    "def process_text_file(file_path, file_name, temperatures: dict, max_tokens: int):\n",
    "    \n",
    "    #set name for each meeting\n",
    "    file_node = ET.SubElement(root, \"Meeting\", attrib={\"Name\": file_name})\n",
    "\n",
    "    for temp in temperatures:\n",
    "        temp_node = {}\n",
    "        for i in range(3):\n",
    "            with open(file_path, 'r') as text:\n",
    "                text_chunks = split_into_chunks(text) # returns a list of strings\n",
    "                action_items = extract_action_items(text_chunks, temp, max_tokens) # returns a single string\n",
    "\n",
    "                iteration_node = ET.SubElement(file_node, \"Iteration\", attrib={\"Number\": str(i)}) # number iterations\n",
    "                for item in action_items.split('\\n'):  # Split action items by newline\n",
    "                    if item.startswith(\"Action items:\") or item.startswith(\"Action Items:\") or item.startswith(\"### Action Items:\"): # excluding leading sentence before action item lists\n",
    "                    # skip creating an XML element if the row contains the words above\n",
    "                        continue\n",
    "\n",
    "                    item = re.sub(r\"\\s+\", \" \", item) # replace 1+ spaces with a single space\n",
    "      \n",
    "                    item_node = ET.SubElement(iteration_node, \"Item\") # create <Item> tag for each action item\n",
    "                    item_node.text = re.sub(r\"^\\d+\\.\\s*\", \"\", item) # add text to the tag after using regex to remove the numbering in front of each action item (eg. \"1. \", \"21. \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  Bed002.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  Bed003.txt\n",
      "Processing:  Bed004.txt\n",
      "Processing:  Bed005.txt\n",
      "Processing:  Bed006.txt\n",
      "Processing:  Bed008.txt\n",
      "Processing:  Bed009.txt\n",
      "Processing:  Bed010.txt\n",
      "Processing:  Bmr001.txt\n",
      "Processing:  Bmr002.txt\n",
      "Processing:  Bmr003.txt\n",
      "Processing:  Bmr005.txt\n",
      "Processing:  Bmr006.txt\n",
      "Processing:  Bmr007.txt\n",
      "Processing:  Bmr008.txt\n",
      "Processing:  Bmr009.txt\n",
      "Processing:  Bmr010.txt\n",
      "Processing:  Bro003.txt\n",
      "Processing:  Bro004.txt\n",
      "Processing:  Bro005.txt\n",
      "Processing:  Bro007.txt\n",
      "Processing:  Bro008.txt\n",
      "Processing:  Bro010.txt\n",
      "Processing:  Bro011.txt\n",
      "Processing:  Bro012.txt\n"
     ]
    }
   ],
   "source": [
    "# running all functions to create the XML file containing the extracted by the model action items\n",
    "temperatures = [0.5]\n",
    "max_tokens = 300\n",
    "\n",
    "root = ET.Element(\"Meetings\") # set the root XML element to <Meetings>\n",
    "\n",
    "for file_name in os.listdir(folder_path): # for each file in our folder\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    print(\"Processing: \", file_name) # print progress\n",
    "    results = process_text_file(file_path, file_name, temperatures, max_tokens) # process the files\n",
    "\n",
    "    \n",
    "    tree = ET.ElementTree(root) # create the <Meetings> root element all <Meeting> elements are contained under\n",
    "    tree.write(\"GPT_action_items.xml\", encoding='utf-8', xml_declaration=True) # write the XML elements to file\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
