me013: OK.
me034: Oh, I don't -
me018: I think I'm zero.
me013: Wow!
fn002: Ah-
me034: Hello, hello, hello, hello.
me006: Wh- what causes the crash?
me013: Unprecedented.
me018: Did you fix something?
me034: Hello.
fn002: Five, five.
me006: Oh, maybe it's the turning - turning off and turning on of the mike, right?
me034: Hello, hello.
me013: Uh, you think that's you?
me006: Yeah, OK, mine's working.
me034: Aaa-aaa-aaa. OK. That's me.
me013: Oh. OK. OK. So, um I guess we are um gonna do the digits at the end. Uh
mn007: Channel - channel three, yeah. OK.
fn002: Mmm, channel five?
me034: Channel two.
fn002: Doesn't work?
me034: Two.
me013: Yeah, that's the mike number there, uh
fn002: No?
me018: Is it written on her sheet, I believe.
mn007: Mike four.
me006: Watch this. Yep, that's me.
me013: Uh, mike number five,
fn002: Ah, era el cuatro. Yeah.
me013: and
me018: But, channel
me013: channel - channel four.
fn002: Yeah yeah yeah.
me013: This is you.
fn002: OK. I saw that. Ah - yeah, it's OK.
me013: Yeah. And I'm channel uh two I think, or channel -
me034: Ooo. I think I'm channel two.
me013: Oh, I'm channel - must be channel one. Channel one? Yes, OK.
fn002: Channel -
me013: OK. So uh I also copied uh the results that we all got in the mail I think from uh - from OGI and we'll go - go through them also. So where are we on - on uh our runs?
mn007: Uh so. uh - We - So As I was already said, we - we mainly focused on uh four kind of features. The PLP, the PLP with JRASTA, the MSG, and the MFCC from the baseline Aurora.
me013: Excuse me.
fn002: I decided to talk about that.
me013: Mm-hmm.
mn007: Uh, and we focused for the - the test part on the English and the Italian. Um. We've trained uh several neural networks on - so - on the TI-digits English and on the Italian data and also on the broad uh English uh French and uh Spanish databases. Mmm, so there's our result tables here, for the tandem approach, and um, actually what we - we @@ observed is that if the network is trained on the task data it works pretty well.
me011: I can't get back far enough.
me034: Chicken on the grill.
me013: OK. Our - our uh - There's a - We're pausing for a photo -
me011: Sorry, guys.
me034: Try that corner.
me018: How about over th- from the front of the room?
me034: Yeah, it's longer.
me013: We're pausing for a photo opportunity here. Uh. Uh. So.
me006: Oh wait wait wait wait wait. Wait. Hold on. Hold on. Let me give you a black screen.
me034: Get out of the - Yeah.
me013: OK.
me011: One more.
me013: He's facing this way.
me011: Because we said we were gonna do this and I just remembered.
me013: What? OK, this - this would be a good section for our silence detection.
me006: OK.
me013: Um
me034: Mm-hmm.
me006: Musical chairs everybody!
me013: Oh. OK. So um, you were saying about the training data -
mn007: Yeah, so if the network is trained on the task data um tandem works pretty well. And uh actually we have uh, results are similar
me013: Yeah.
me018: Do you mean if it's trained only on -
mn007: Only on, yeah.
me018: On data from just that task, that language?
mn007: Just that task. But actually we didn't train network on uh both types of data I mean uh phonetically ba- phonetically balanced uh data and task data. We only did either task - task data or uh broad data.
me018: Mmm. Mm-hmm.
mn007: Um Yeah. So,
me013: So how - I mean -
me018: So what's th-
me013: clearly it's gonna be good then but the question is how much worse is it if you have broad data? I mean, my assump- From what I saw from the earlier results, uh I guess last week, was that um, if you trained on one language and tested on another, say, that the results were - were relatively poor.
mn007: Mmm. Yeah.
me013: But - but the question is if you train on one language but you have a broad coverage and then test in another, does that - is that improve things i- c- in comparison?
mn007: If we use the same language?
me013: No, no, no. Different lang- So um If you train on TI-digits and test on Italian digits, you do poorly,
mn007: Mm-hmm.
me013: let's say. I don't have the numbers in front of me, so I'm just imagining.
mn007: But - Yeah but I did not uh do that. We -
me013: E- So, you didn't train on TIMIT and test on - on Italian digits, say?
mn007: No, we did four - four kind of - of testing, actually. The first testing is with task data - So, with nets trained on task data. So for Italian on the Italian speech @@ . The second test is trained on a single language um with broad database, but the same language as the t- task data.
me013: OK.
mn007: But for Italian we choose Spanish which we assume is close to Italian. The third test is by using, um the three language database and the fourth is
me013: W- which in - It has three languages. That's including the w- the - the -
mn007: This includes -
me013: the one that it's -
mn007: Yeah. But not
me018: In-
mn007: digits. I mean it's -
me013: Right.
me018: The three languages is not digits, it's the broad data. OK.
mn007: Yeah And the fourth test is uh excluding from these three languages the language that is the task language.
me013: Oh, OK, yeah, so, that is what I wanted to know.
mn007: Yeah.
me013: I just wasn't saying it very well, I guess.
mn007: Uh, yeah. So um for uh TI-digits for ins- example uh when we go from TI-digits training to TIMIT training uh we lose uh around ten percent, uh.
me013: Relative.
mn007: The error rate increase u- of - of -
me013: Right.
mn007: of ten percent, relative. So this is not so bad. And then when we jump to the multilingual data it's uh it become worse and, well
me013: Ab- about how much?
mn007: Around uh, let's say, twenty perc- twenty percent further. So. Yeah.
me013: Twenty percent further?
mn007: Twenty to - to thirty percent further. Yeah.
me018: And so, remind me, the multilingual stuff is just the broad data. Right?
mn007: Yeah.
me018: It's not the digits. So it's the combination of two things there. It's removing the task specific training and it's adding other languages.
mn007: Yeah. Yeah.
me018: OK.
mn007: But the first step is al- already removing the task s- specific from - from -
me018: Already, right right right.
mn007: So. And we lose -
me018: So they were sort of building here? OK?
mn007: Yeah. Uh So, basically when it's trained on the - the multilingual broad data um or number - so, the - the ratio of our error rates uh with the baseline error rate is around uh one point one. So.
me013: Yes. And it's something like one point three of - of the uh - I- i- if you compare everything to the first case at the baseline, you get something like one point one for the - for the using the same language but a different task, and something like one point three for three - three languages
mn007: No no no.
me013: broad stuff.
mn007: Uh same language we are at uh - for at English at O point eight. So it improves, compared to the baseline. But - So. Le- let me.
me013: I - I - I'm sorry. I - I - I meant something different by baseline
mn007: Tas- task data we are u- Yeah.
me013: So let me - let me - Um, so, um -
mn007: Mmm.
me013: OK, fine. Let's - let's use the conventional meaning of baseline. I - I -
mn007: Hmm.
me013: By baseline here I meant uh using the task specific data.
mn007: Oh yeah, the f- Yeah, OK. Yeah.
me013: But uh - uh, because that's what you were just doing with this ten percent. So I was just - I just trying to understand that. So if we call
mn007: Yeah. Sure.
me013: a factor of w- just one, just normalized to one, the word error rate
mn007: Mmm.
me013: that you have for using TI-digits as - as training and TI-digits as test, uh different words, I'm sure, but -
mn007: Mm-hmm.
me013: but uh, uh the same task and so on. If we call that "one", then what you're saying is
mn007: Mm-hmm.
me013: that the word error rate for the same language but using uh different training data than you're testing on, say TIMIT and so forth,
mn007: Mm-hmm.
me013: it's one point one.
mn007: Yeah, it's around one point one. Yeah.
me013: Right. And if it's - you do go to three languages including the English, it's something like one point three.
mn007: Ye-
me013: That's what you were just saying, I think.
mn007: Uh, more actually. If I -
me018: One point four?
mn007: Yeah.
me018: So, it's an additional thirty percent.
mn007: What would you say? Around one point four yeah.
me013: OK. And if you exclude English, from this combination, what's that?
mn007: If we exclude English, um there is not much difference with the data with English.
me013: Aha!
mn007: So. Yeah.
me013: That's interesting. That's interesting. Do you see? Because -
mn007: Uh.
me013: Uh, so - No, that - that's important. So what - what it's saying here is just that "yes, there is a reduction in performance, when you don't um have the s- when you don't have um
me018: Task data.
me013: Wait a minute, th- th- the -
mn007: Hmm.
me013: No, actually it's interesting. So it's - So when you go to a different task, there's actually not so different. It's when you went to these - So what's the difference between two and three? Between the one point one case and the one point four case? I'm confused.
me018: It's multilingual.
mn007: Yeah. The only difference it's - is that it's multilingual - Um Yeah.
me013: Cuz in both - in both - both of those cases, you don't have the same task.
mn007: Yeah sure.
me013: So is - is the training data for the - for this one point four case - does it include the training data for the one point one case?
mn007: Uh yeah.
me006: Yeah, a fraction of it.
mn007: A part of it, yeah.
me013: How m- how much bigger is it?
mn007: Um
me006: Yeah, um.
mn007: It's two times, actually? Yeah. Um. The English data - No, the multilingual databases are two times the broad English data. We just wanted to keep this, w- well, not too huge. So.
me013: So it's two times, but it includes the - but it includes the broad English data.
mn007: I think so. Do you - Uh, Yeah.
me013: And the broad English data is what you got this one point one with. So that's TIMIT basically right?
me006: Mm-hmm.
mn007: Yeah.
me013: So it's band-limited TIMIT.
me006: Mm-hmm.
mn007: Mm-hmm.
me013: This is all
mn007: Yeah.
me006: Downs-
me013: eight kilohertz sampling.
me006: Right.
me013: So you have band-limited TIMIT, gave you uh almost as good as a result as using TI- digits on a TI-digits test. OK?
mn007: Hmm?
me013: Um and um But, when you add in more training data but keep the neural net the same size, it um performs worse on the TI-digits. OK, now all of this is - This is noisy TI-digits, I assume?
mn007: Yep.
me013: Both training and test? Yeah. OK. Um OK. Well. We - we - we may just need to uh - So I mean it's interesting that h- going to a different - different task didn't seem to hurt us that much, and going to a different language um It doesn't seem to matter - The difference between three and four is not particularly great, so that means that whether you have the language in or not is not such a big deal.
mn007: Mmm.
me013: It sounds like um uh we may need to have more of uh things that are similar to a target language or - I mean. You have the same number of parameters in the neural net, you haven't increased the size of the neural net, and maybe there's just - just not enough complexity to it to represent the variab- increased variability in the - in the training set. That - that could be. Um So, what about - So these are results with uh th- that you're describing now, that they are pretty similar for the different features or - or uh -
mn007: Uh, let me check. Uh. So. This was for the PLP,
me013: Yeah.
mn007: Um. The - Yeah. For the PLP with JRASTA the -
me013: Yeah.
mn007: the - we - This is quite the same tendency, with a slight increase of the error rate, uh if we go to - to TIMIT. And then it's - it gets worse with the multilingual. Um. Yeah. There - there is a difference actually with - b- between PLP and JRASTA is that JRASTA seems to perform better with the highly mismatched condition but slightly - slightly worse for the well matched condition. Mmm.
me013: I have a suggestion, actually, even though it'll delay us slightly, would - would you mind running into the other room and making copies of this? Cuz we're all sort of -
mn007: Yeah, yeah.
me013: If we c- if we could look at it, while we're talking, I think it 'd be uh -
mn007: OK.
me013: Uh, I'll - I'll sing a song or dance or something while you do it, too.
me006: Alright.
me018: So um - Go ahead. Ah, while you're gone I'll ask s- some of my questions.
me013: Yeah.
me018: Um.
me013: Yeah. Uh, this way and just slightly to the left, yeah.
me018: The um - What was - Was this number forty or - It was roughly the same as this one, he said? When you had the two language versus the three language?
me013: Um. That's what he was saying.
me018: That's where he removed English, right?
me006: Yeah.
me013: Right.
me006: It sometimes, actually, depends on what features you're using.
me013: Yeah. But - but i- it sounds like -
me006: Um, but -
me013: I mean. That's interesting because it - it seems like what it's saying is not so much that you got hurt uh because you uh didn't have so much representation of English, because in the other case you don't get hurt any more, at least when it seemed like uh it - it might simply be a case that you have something that is just much more diverse,
me018: Mm-hmm.
me013: but you have the same number of parameters representing it.
me018: Mm-hmm. I wonder - were um all three of these nets using the same output? This multi-language uh labeling?
me006: He - Mm-hmm. He was using uh sixty-four phonemes from SAMPA.
me018: OK, OK.
me006: Yeah.
me018: So this would - From this you would say, "well, it doesn't really matter if we put Finnish into the training of the neural net, if there's gonna be, you know, Finnish in the test data." Right?
me013: Well, it's - it sounds - I mean, we have to be careful, cuz we haven't gotten a good result yet.
me018: Yeah.
me013: And comparing different bad results can be tricky.
me018: Hmm.
me013: But I - I - I - I think it does suggest that it's not so much uh uh cross language as cross type of speech.
me018: Mm-hmm.
me013: It's - it's um - But we did - Oh yeah, the other thing I was asking him, though, is that I think that in the case - Yeah, you - you do have to be careful because of com- compounded results. I think we got some earlier results in which you trained on one language and tested on another and you didn't have three, but you just had one language. So you trained on one type of digits and tested on another. Didn- Wasn't there something of that? Where you, say, trained on Spanish and tested on - on TI-digits, or the other way around? Something like that?
fn002: No.
me013: I thought there was something like that, that he showed me last week. We'll have to wait till we get -
me018: Yeah, that would be interesting.
me013: Um, This may have been what I was asking before, Stephane, but - but, um, wasn't there something that you did, where you trained on one language and tested on another? I mean no - no mixture but just -
me006: I'll get it for you.
mn007: Uh, no, no.
me013: We've never just trained on one lang-
mn007: Training on a single language, you mean, and testing on the other one?
me013: Yeah.
fn002: Not yet.
mn007: Uh, no. So the only task that's similar to this is the training on two languages, and
me013: But we've done a bunch of things where we just trained on one language. Right?
mn007: that -
me013: I mean, you haven't - you haven't done all your tests on multiple languages.
mn007: Uh, No. Either thi- this is test with uh the same language but from the broad data, or it's test with uh different languages also from the broad data, excluding the -
fn002: The early experiment that -
mn007: So, it's - it's three or - three and four.
me018: Did you do different languages from digits?
mn007: Uh. No. You mean training digits on one language and using the net to recognize on the other?
me018: Digits on another language?
mn007: No.
me013: See, I thought you showed me something like that last week. You had a - you had a little -
mn007: Uh, No, I don't think so.
me013: Um What -
me034: These numbers are uh ratio to baseline?
me013: So, I mean wha- what's the - This - this chart - this table that we're looking at is um,
mn007: So.
me013: show- is all testing for TI -digits, or - ?
me006: Bigger is worse. This is error rate, I think.
mn007: So you have uh basically two uh parts. The upper part is for TI-digits
me034: Ratio.
me006: No. No. Yeah, yeah, yeah.
mn007: and it's divided in three rows of four - four rows each.
me006: Mm-hmm.
me013: Yeah.
mn007: And the first four rows is well-matched, then the s- the second group of four rows is mismatched, and finally highly mismatched. And then the lower part is for Italian and it's the same - the same thing.
me018: So, so the upper part is training TI-digits?
mn007: So. It's - it's the HTK results, I mean. So it's HTK training testings
me018: Ah.
mn007: with different kind of features and what appears in the uh left column is the networks that are used for doing this.
me013: Hmm.
mn007: So. Uh Yeah.
me013: Well, What was is that i- What was it that you had done last week when you showed - Do you remember? Wh- when you showed me the - your table last week?
mn007: It- It was part of these results. Mmm. Mmm.
me018: So where is the baseline for the TI-digits located in here?
mn007: You mean the HTK Aurora baseline?
me018: Yeah.
mn007: It's uh the one hundred number. It's, well, all these numbers are the ratio
me018: Ah!
mn007: with respect to the baseline.
me018: Ah, OK, OK.
me013: So this is word - word error rate, so a high number is bad.
mn007: Yeah, this is a word error rate ratio.
fn002: Yeah.
mn007: Yeah.
me018: OK, I see.
mn007: So, seventy point two means that we reduced the error rate uh by thirty - thirty percent. So.
me018: OK, OK, gotcha.
me013: OK,
mn007: Hmm.
me013: so if we take uh um let's see PLP uh with on-line normalization and delta-del- so that's this thing you have circled here in the second column,
mn007: Yeah.
me013: um and "multi-English" refers to what?
mn007: To TIMIT. Mmm. Then you have uh MF, MS and ME which are for French, Spanish and English. And, yeah. Actually I - I uh forgot to say that the multilingual net are trained on uh features without the s- derivatives uh but with increased frame numbers. Mmm. And we can - we can see on the first line of the table that it - it - it's slightly - slightly worse when we don't use delta but it's not - not that much.
me013: Right. So w- w- So, I'm sorry. I missed that. What's MF, MS and ME?
me018: Multi-French, Multi-Spanish
mn007: So. Multi-French, Multi-Spanish, and Multi-English.
me013: Uh OK. So, it's uh broader vocabulary.
mn007: Yeah.
me013: Then - And - OK so I think what I'm - what I saw in your smaller chart that I was thinking of was - was there were some numbers I saw, I think, that included these multiple languages and it - and I was seeing that it got worse. I - I think that was all it was. You had some very limited results that - at that point
mn007: Yeah.
me013: which showed having in these - these other languages. In fact it might have been just this last category, having two languages broad that were - where - where English was removed. So that was cross language and the - and the result was quite poor. What I - we hadn't seen yet was that if you added in the English, it's still poor.
mn007: Yeah. Still poor.
me013: Uh Um now, what's the noise condition um of the training data - Well, I think this is what you were explaining. The noise condition is the same - It's the same uh Aurora noises
mn007: Yeah.
me013: uh, in all these cases
mn007: Yeah.
me013: for the training. So there's not a statistical - sta- a strong st- statistically different noise characteristic between
mn007: No these are the s- s- s- same noises, yeah.
me013: uh the training and test and yet we're seeing some kind of effect -
mn007: At least - at least for the first - for the well-matched, yeah.
me006: Well matched condition.
me013: Right. So there's some kind of a - a - an effect from having these - uh this broader coverage um Now I guess what we should try doing with this is try testing these on u- this same sort of thing on - you probably must have this lined up to do. To try the same t- with the exact same training, do testing on the other languages.
mn007: Mmm.
me013: On - on um - So. Um, oh I well, wait a minute. You have this here, for the Italian. That's right. OK, so,
mn007: Yeah. Yeah, so for the Italian the results are uh stranger um
me013: So.
mn007: Mmm. So what appears is that perhaps Spanish is not very close to Italian because uh, well, when using the - the network trained only on Spanish it's - the error rate is almost uh twice the baseline error rate.
me013: Mm-hmm.
mn007: Mmm. Uh.
me013: Well, I mean, let's see. Is there any difference in - So it's in the uh - So you're saying that when you train on English and uh and - and test on -
mn007: Yeah.
me013: No, you don't have training on English testing -
mn007: There - there is - another difference, is that the noise - the noises are different. Well,
me013: In - in what?
mn007: For - for the Italian part I mean the uh the um networks are trained with noise from Aurora - TI- digits, mmm.
fn002: Aurora-two.
mn007: Yeah.
me013: And the noise is different in th-
mn007: And perhaps the noise are quite different from the noises in the speech that Italian . And -
me013: Do we have any um test sets uh in any other language that um have the same noise as in the Aurora?
fn002: Mmm, no.
mn007: No.
me018: Can I ask something real quick? In - in the upper part - in the English stuff, it looks like the very best number is sixty point nine? and that's in the uh - the third section in the upper part under PLP JRASTA, sort of the middle column?
mn007: Yeah.
me018: I- is that a noisy condition?
mn007: Yeah.
me018: So that's matched training? Is that what that is?
mn007: It's - no, the third part, so it's uh highly mismatched. So. Training and test noise are different.
me018: So - why do you get your best number in - Wouldn't you get your best number in the clean case?
me034: Well, it's relative to the um baseline mismatching
mn007: Yeah.
me018: Ah, OK so these are not -
mn007: Yeah.
me018: OK, alright, I see.
me034: Yeah.
mn007: Yeah.
me018: OK. And then - so, in the - in the um - in the non-mismatched clean case, your best one was under MFCC? That sixty-one point four?
mn007: Yeah. But it's not a clean case. It's a noisy case but uh training and test noises are the same.
me018: Oh! So this upper third?
mn007: So - Yeah.
me018: Uh that's still noisy?
mn007: Yeah.
me018: Ah, OK.
mn007: So it's always noisy basically, and, well, the -
me018: Mm-hmm. I see.
mn007: Mmm.
me013: OK? Um So uh, I think this will take some looking at, thinking about. But, what is uh - what is currently running, that's - uh, i- that - just filling in the holes here or - or - ?
mn007: Uh, no we don't plan to fill the holes but
me013: pretty much? OK.
mn007: actually there is something important, is that um we made a lot of assumption concerning the on-line normalization and we just noticed uh recently that uh the approach that we were using was not uh leading to very good results when we used the straight features to HTK. Um Mmm. So basically d- if you look at the - at the left of the table, the first uh row, with eighty-six, one hundred, and forty-three and seventy-five, these are the results we obtained for Italian uh with straight mmm, PLP features using on-line normalization.
me013: Mm-hmm.
mn007: Mmm. And the, mmm - what's in the table, just at the left of the PLP twelve on-line normalization column, so, the numbers seventy-nine, fifty-four and uh forty-two are the results obtained by uh Pratibha with uh his on-line normalization - uh her on-line normalization approach.
me018: Where is that? seventy-nine, fifty
fn002: Fifty-one? This -
me013: Uh, it's just sort of sitting right on the uh - the column line.
mn007: So.
me013: Uh.
me018: Oh I see, OK.
mn007: Just - uh
me013: Yeah.
mn007: Yeah. So these are the results of OGI with on-line normalization and straight features to HTK. And the previous result, eighty-six and so on,
me013: Yes.
mn007: are with our features straight to HTK. So
me013: Yes.
mn007: what we see that - is - there is that um uh the way we were doing this was not correct, but still the networks are very good. When we use the networks our number are better that
fn002: We improve.
mn007: uh Pratibha results.
me013: So, do you know what was wrong with the on-line normalization, or - ?
mn007: Yeah. There were diff- there were different things and basically, the first thing is the mmm, alpha uh value. So, the recursion uh part. um, I used point five percent, which was the default value in the - in the programs here. And Pratibha used five percent. So it adapts more quickly
me013: Uh-huh. Yes. Yeah.
mn007: Um, but, yeah. I assume that this was not important because uh previous results from - from Dan and - show that basically the both - both values g- give the same - same uh results. It was true on uh TI-digits but it's not true on Italian.
me013: Mm-hmm.
mn007: Uh, second thing is the initialization of the stuff. Actually, uh what we were doing is to start the recursion from the beginning of the utterance. And using initial values that are the global mean and variances measured across the whole database.
me013: Right. Right.
mn007: And Pratibha did something different is that he - uh she initialed the um values of the mean and variance by computing this on the twenty-five first frames of each utterance. Mmm. There were other minor differences, the fact that she used fifteen dissities instead s- instead of thirteen, and that she used Czero instead of log energy. Uh, but the main differences concerns the recursion. So. Uh, I changed the code uh and now we have a baseline that's similar to the OGI baseline.
me013: OK.
mn007: We - It - it's slightly uh different because I don't exactly initialize the same way she does. Actually I start, mmm, I don't wait to a fifteen - twenty-five - twenty-five frames before computing a mean and the variance to e- to - to start the recursion.
me034: Mm-hmm.
me013: Yeah.
mn007: I - I use the on-line scheme and only start the re- recursion after the twenty-five - twenty-fifth frame. But, well it's similar. So uh I retrained the networks with these - well, the - the - the networks are retaining with these new features.
me013: Mm-hmm.
mn007: And, yeah.
me013: OK.
mn007: So basically what I expect is that these numbers will a little bit go down but perhaps not - not so much because I think the neural networks learn perhaps
me013: Right.
mn007: to - even if the features are not normalized. It - it will learn how to normalize and -
me013: Right. OK, but I think that
mn007: Mmm.
me013: given the pressure of time we probably want to draw - because of that especially, we wanna draw some conclusions from this, do some reductions in what we're looking at,
mn007: Yeah.
me013: and make some strong decisions for what we're gonna do testing on before next week. So do you - are you - w-
mn007: Yeah I'd -
me013: did you have something going on, on the side, with uh multi-band or - on - on this, or - ?
mn007: No, I - we plan to start this uh so, act- actually we have discussed uh @@ um, these - what we could do more as a - as a research and - and we were thinking perhaps that uh the way we use the tandem is not - Uh, well, there is basically perhaps a flaw in the - in the - the stuff because we trained the networks - If we trained the networks on the - on a language and a t- or a specific task,
me013: Mm-hmm.
mn007: um, what we ask is - to the network - is to put the bound- the decision boundaries somewhere in the space. And uh mmm and ask the network to put one,
me013: Mmm.
mn007: at one side of the - for - for a particular phoneme at one side of the boundary - decision boundary and one for another phoneme at the other side. And so there is kind of reduction of the information there that's not correct because if we change task and if the phonemes are not in the same context in the new task, obviously the decision boundaries are not - should not be at the same place. But the way the feature gives -
me013: I di-
mn007: The - the way the network gives the features is that it reduce completely the - it removes completely the information - a lot of information from the - the features by uh uh placing the decision boundaries at optimal places for one kind of data but this is not the case for another kind of data.
me013: It's a trade-off, right? Any- anyway go ahead.
mn007: So - Yeah. So uh what we were thinking about is perhaps um one way to solve this problem is increase the number of outputs of the neural networks. Doing something like, um um phonemes within context and, well, basically context dependent phonemes.
me013: Maybe. I mean, I - I think you could make the same argument, it'd be just as legitimate, for hybrid systems as well.
mn007: Yeah but, we know that -
me013: Right. And in fact, th- things get better with context dependent versions. Right?
mn007: Ye- yeah but here it's something different. We want to have features uh well,
me013: Yeah.
mn007: um.
me013: Yeah, but it's still true that what you're doing is you're ignoring - you're - you're coming up with something to represent, whether it's a distribution, probability distribution or features, you're coming up with a set of variables that are representing uh, things that vary w- over context.
mn007: Mm-hmm.
me013: Uh, and you're putting it all together, ignoring the differences in context. That - that's true for the hybrid system, it's true for a tandem system. So, for that reason, when you - in - in - in a hybrid system, when you incorporate context one way or another, you do get better scores.
mn007: Yeah.
me013: OK? But I - it's - it's a big deal to get that. I - I'm - I'm sort of - And once you - the other thing is that once you represent - start representing more and more context it is uh much more um specific to a particular task in language. So um Uh, the - the acoustics associated with uh a particular context, for instance you may have some kinds of contexts that will never occur in one language and will occur frequently in the other, so the qu- the issue of getting enough training for a particular kind of context becomes harder. We already actually don't have a huge amount of training data um
mn007: Yeah, but - mmm, I mean, the - the way we - we do it now is that we have a neural network and basically the net- network is trained almost to give binary decisions.
me013: Right.
mn007: And uh - binary decisions about phonemes. Nnn - Uh
me013: Almost. But I mean it - it - it does give a distribution.
mn007: It's - Yeah.
me013: It's - and - and it is true that if there's two phones that are very similar, that uh the - i- it may prefer one but it will give a reasonably high value to the other, too.
mn007: Yeah. Yeah, sure but uh So basically it's almost binary decisions and um the idea of using more classes is to get something that's less binary decisions.
me013: Oh no, but it would still be even more of a binary decision. It - it'd be even more of one. Because then you would say
mn007: But - yeah, but -
me013: that in - that this phone in this context is a one, but the same phone in a slightly different context is a zero. That would be even - even more distinct of a binary decision. I actually would have thought you'd wanna go the other way and have fewer classes.
mn007: Yeah, but if -
me013: Uh, I mean for instance, the - the thing I was arguing for before, but
mn007: Mmm.
me013: again which I don't think we have time to try, is something in which you would modify the code so you could train to have several outputs on and use articulatory features
mn007: Mm-hmm.
me013: cuz then that would - that would go - that would be much broader and cover many different situations. But if you go to very very fine categories, it's very binary.
mn007: Mmm. Yeah, but I think - Yeah, perhaps you're right, but you have more classes so you - you have more information in your features. So,
me013: Mm-hmm.
mn007: Um You have more information in the
me013: True.
mn007: uh posteriors vector um which means that - But still the information is relevant because it's - it's information that helps to discriminate,
me013: Mm-hmm.
mn007: if it's possible to be able to discriminate
me013: Mm-hmm.
mn007: among the phonemes in context.
me013: Well it's - it's -
mn007: But the -
me013: it's an interesting thought. I mean we - we could disagree about it at length
mn007: Mmm. Mmm.
me013: but the - the real thing is if you're interested in it you'll probably try it and - and we'll see. But - but what I'm more concerned with now, as an operational level, is
mn007: Mmm.
me013: uh, you know, what do we do in four or five days? Uh, and - so we have to be concerned with Are we gonna look at any combinations of things, you know once the nets get retrained so you have this problem out of it.
mn007: Mmm.
me013: Um, are we going to look at multi-band? Are we gonna look at combinations of things? Uh, what questions are we gonna ask, uh now that, I mean, we should probably turn shortly to this OG I note. Um, how are we going to combine with what they've been focusing on? Uh, Uh we haven't been doing any of the LD A RASTA sort of thing.
mn007: Mm-hmm.
me013: And they, although they don't talk about it in this note, um, there's um, the issue of the um Mu law business uh versus the logarithm, um, so.
mn007: Mm-hmm.
me013: So what i- what is going on right now? What's right - you've got nets retraining, Are there - is there - are there any HT K trainings - testings going on?
mn007: N-
fn002: I - I - I'm trying the HTK with eh, PLP twelve on-line delta-delta and MSG filter together.
me013: The combination, I see.
fn002: The combination, yeah. But I haven't result at this moment.
me013: MSG and - and PLP.
fn002: Yeah.
me013: And is this with the revised on-line normalization?
fn002: Ye- Uh, with the old older , yeah.
mn007: Yeah.
me013: Old one. So it's using all the nets for that but again we have the hope that it -
fn002: Yeah. But We can
me013: We have the hope that it -
fn002: know soon.
me013: maybe it's not making too much difference,
fn002: Maybe.
me013: but - but yeah.
fn002: I don't know.
mn007: Yeah.
me013: Uh, OK.
mn007: Uh so there is this combination, yeah. Working on combination obviously. Um, I will start work on multi-band.
fn002: Mm-hmm.
mn007: And we plan to work also on the idea of using both features and net outputs.
fn002: Yep.
mn007: Um. And we think that with this approach perhaps we could reduce the number of outputs of the neural network. Um, So, get simpler networks, because we still have the features. So we have um come up with um different kind of broad phonetic categories. And we have - Basically we have three types of broad phonetic classes. Well, something using place of articulation which - which leads to nine, I think, broad classes. Uh, another which is based on manner, which is - is also something like nine classes. And then, something that combine both, and we have twenty f- twenty-five?
me006: Twenty-seven.
mn007: Twenty-seven broad classes. So like, uh, oh, I don't know, like back vowels, front vowels.
me013: So what you do -
mn007: Um
me013: um I just wanna understand so You have two net or three nets? Was this? How many - how many nets do you have?
mn007: For the moments we do not - don't have nets, I mean,
me013: No nets.
mn007: It's just -
fn002: Begin to work in this.
mn007: Were we just changing the labels to retrain nets with fewer out- outputs.
fn002: We are @@ .
me013: Right. But - but I didn't understand -
mn007: And then - Mm-hmm.
me013: Uh. the software currently just has - uh a - allows for I think, the one - one hot output. So you're having multiple nets and combining them, or - ? Uh, how are you - how are you coming up with - If you say uh If you have a place characteristic and a manner characteristic, how do you -
mn007: It-
me018: I think they have one output.
mn007: It's the single net, yeah.
me013: Oh, it's just one net.
me006: mm-hmm
fn002: Yeah.
mn007: It's one net with um twenty-seven outputs if we have twenty-seven classes, yeah.
me013: I see. I see, OK.
mn007: So it's - Well, it's basically a standard net with fewer classes.
me013: So you're sort of going the other way of what you were saying a bit ago instead of - yeah.
mn007: Yeah, but I think - Yeah.
me006: But including the features.
mn007: B- b-
fn002: Yeah.
mn007: including the features, yeah. I don't think this will work alone. I think it will get worse because
me013: Uh-huh.
mn007: Well, I believe the effect that - of - of too reducing too much the information is basically - basically what happens and - but -
me013: But you think if you include that plus the other features,
mn007: Yeah, because there is perhaps one important thing that the net brings, and OGI show- showed that, is the distinction between sp- speech and silence Because these nets are trained on well-controlled condition. I mean the labels are obtained on clean speech, and we add noise after. So this is one thing And But perhaps, something intermediary using also some broad classes could - could bring so much more information. Uh.
me013: So - so again then we have these broad classes and - well, somewhat broad. I mean, it's twenty-seven instead of sixty-four, basically.
mn007: Yeah.
me013: And you have the original features.
mn007: Yeah.
me013: Which are PLP, or something.
mn007: Mm-hmm.
me013: And then uh, just to remind me, all of that goes into - uh, that all of that is transformed by uh, uh, K- KL or something, or - ?
mn007: There will probably be, yeah, one single KL to transform everything or
fn002: Mu.
me013: Right.
mn007: uh, per-
fn002: No transform the PLP and only transform the other I'm not sure.
mn007: This is still something that yeah, we don't know -
me013: Well no, I think - I see.
fn002: Two e-
me013: So there's a question of whether you would -
mn007: Yeah.
me013: Right. Whether you would transform together or just one.
fn002: @@ it's one.
me013: Yeah. Might wanna try it both ways. But that's interesting. So that's something that you're - you haven't trained yet but are preparing to train, and -
mn007: Yeah.
me013: Yeah. Um
mn007: Mmm.
me013: Yeah, so I think Hynek will be here Monday. Monday or Tuesday. So
mn007: Uh, yeah.
me013: So I think, you know, we need to choose the - choose the experiments carefully, so we can get uh key - key questions answered
mn007: Mm-hmm.
me013: uh before then and leave other ones aside even if it leaves incomplete tables someplace, uh uh, it's - it's really time to - time to choose.
mn007: Mm-hmm.
me013: Um, let me pass this out, by the way. Um These are - Did - did - did I interrupt you? Were there other things that you wanted to -
fn002: Yeah, I have one.
mn007: Uh, no. I don't think so.
fn002: @@
mn007: Yeah, I have one.
me026: Oh, thanks.
me013: Ah! OK.
fn002: We have one. @@
me013: OK, we have lots of them. OK, so um, Something I asked - So they're - they're doing the - the VAD I guess they mean voice activity detection So again, it's the silence - So they've just trained up a net which has two outputs, I believe. Um I asked uh Hynek whether - I haven't talked to Sunil - I asked Hynek whether they compared that to just taking the nets we already had and summing up the probabilities.
mn007: Mm-hmm.
me013: Uh. To get the speech - voice activity detection, or else just using the silence, if there's only one silence output. Um And, he didn't think they had, um. But on the other hand, maybe they can get by with a smaller net and maybe sometimes you don't run the other, maybe there's a computational advantage to having a separate net, anyway.
mn007: Mm-hmm.
me013: So um Their uh - the results look pretty good.
mn007: Yeah.
me013: Um, I mean, not uniformly. I mean, there's a - an example or two that you can find, where it made it slightly worse, but uh in - in all but a couple
mn007: Mmm.
me013: examples. Uh.
fn002: But they have a question of the result. Um how are trained the - the LDA filter? How obtained the LDA filter?
mn007: Mmm.
me013: I- I'm sorry. I don't understand your question.
fn002: Yes, um the LDA filter needs some training set to obtain the filter. Maybe I don't know exactly how they are obtained.
me013: It's on training.
fn002: Training, with the training test of each - You understand me?
me013: No.
fn002: Yeah, uh for example, LDA filter need a set of - a set of training to obtain the filter. And maybe for the Italian, for the TD TE on for Finnish, these filter are - are obtained with their own training set.
me013: Yes. Yes, I don't know. That's - that's - so that's a - that's a very good question, then - now that it - I understand it. It's "yeah, where does the LDA come from?" In the - In earlier experiments, they had taken LDA from a completely different database, right?
fn002: Yeah. Yeah, because maybe it the same situation that the neural network training with their own
mn007: Mmm.
fn002: set.
me013: So that's a good question. Where does it come from? Yeah, I don't know. Um, but uh to tell you the truth, I wasn't actually looking at the LDA so much when I - I was looking at it I was mostly thinking about the - the VAD. And um, it ap- it ap- Oh what does - what does ASP? Oh that's -
mn007: The features, yeah. Yeah.
fn002: I don't understand also what is -
me013: It says "baseline ASP".
fn002: what is the difference between ASP and uh baseline over ?
mn007: Yeah, I don't know.
me034: ASP.
fn002: This is -
me034: Oh.
me013: Anybody know any -
me034: There it is.
me013: Um Cuz there's "baseline Aurora " above it.
me034: Mm-hmm.
me013: And it's - This is mostly better than baseline, although in some cases it's a little worse, in a couple cases.
me034: Well, it says baseline ASP is twenty-three mill
fn002: Yeah.
me034: minus thirteen.
me013: Yeah, it says what it is. But I don't how that's different from -
me034: From the baseline. OK.
me013: I think this was -
fn002: Yeah.
me013: I think this is the same point we were at
mn007: I think -
me013: when - when we were up in Oregon.
mn007: I think it's the Czero - using Czero instead of log energy. Yeah, it's this.
fn002: Ah, OK, mm-hmm. yeah.
me013: Oh. OK.
mn007: It should be that, yeah. Because -
me013: Shouldn't it be -
me018: They s- they say in here that the VAD is not used as an additional feature. Does - does anybody know how they're using it?
me013: Yeah. So - so what they're doing here is,
mn007: Yeah.
me013: i- if you look down at the block diagram, um, they estimate - they get a -
me018: But that -
me013: they get an estimate of whether it's speech or silence, and then they have a median filter of it.
me018: Mm-hmm.
me013: And so um, basically they're trying to find stretches. The median filter is enforcing a - i- it having some continuity.
me018: Mm-hmm.
me013: You find stretches where the combination of the frame wise VAD and the - the median filter say that there's a stretch of silence. And then it's going through and just throwing the data away.
me034: Hmm.
me013: Right? So um -
me018: So it's - it's - I don't understand. You mean it's throwing out frames?
me013: It's throwing out chunks of frames, yeah.
me018: Before -
me013: There's - the - the median filter is enforcing that it's not gonna be single cases of frames, or isolated frames.
me018: Yeah.
me013: So it's throwing out frames and the thing is um, what I don't understand is how they're doing this with HT K. This is -
me018: Yeah, that's what I was just gonna ask. How can you just throw out frames?
me013: Yeah. Well,
mn007: i-
me013: you - you can, right? I mean y- you - you - it stretches again. For single frames I think it would be pretty hard. But if you say speech starts here, speech ends there. Right?
mn007: Yeah.
me018: Yeah. Mm-hmm.
me034: Huh.
mn007: Yeah. Yeah, you can basically remove the - the frames from the feature - feature files. And.
me013: Yeah. Yeah, so I mean in the - i- i- in the - in the decoding, you're saying that we're gonna decode from here to here.
mn007: I t-
me018: Mm-hmm.
me013: I think they're - they're - they're treating it, you know, like uh - well, it's not isolated word, but - but connected, you know, the - the -
me018: In the text they say that this - this is a tentative block diagram of a possible configuration we could think of. So that sort of sounds like they're not doing that yet.
me013: Well. No they - they have numbers though, right? So I think they're - they're doing something like that. I think that they're - they're - I think what I mean by tha- that is they're trying to come up with a block diagram that's plausible for the standard. In other words, it's - uh - I mean from the point of view of - of uh reducing the number of bits you have to transmit it's not a bad idea to detect silence anyway.
me018: Yeah. Yeah. I'm just wondering what exactly did they do up in this table if it wasn't this.
me013: Um. But it's - the thing is it's that - that - that's - that's I - I - Certainly it would be tricky about it intrans- in transmitting voice, uh uh for listening to, is that these kinds of things uh cut speech off a lot. Right? And so um
me018: Mm-hmm. Plus it's gonna introduce delays.
me013: It does introduce delays but they're claiming that it's - it's within the - the boundaries of it.
me018: Mmm.
me013: And the LDA introduces delays, and b- what he's suggesting this here is a parallel path so that it doesn't introduce uh, any more delay. I- it introduces two hundred milliseconds of delay but at the same time the LDA down here - I don't know - Wh- what's the difference between TLDA and SLDA ?
me034: Temporal and spectral.
me013: Ah, thank you.
fn002: Temporal LDA.
me013: Yeah, you would know that.
me034: Yeah
me013: So um. The temporal LDA does in fact include the same - so that - I think he - well, by - by saying this is a b- a tentative block di- diagram I think means if you construct it this way, this - this delay would work in that way and then it'd be OK.
me018: Ah.
me013: They - they clearly did actually remove silent sections in order - because they got these word error rate results. So um I think that it's - it's nice to do that in this because in fact, it's gonna give a better word error result and therefore will help within an evaluation. Whereas to whether this would actually be in a final standard, I don't know. Um. Uh, as you know, part of the problem with evaluation right now is that the word models are pretty bad and nobody wants - has - has approached improving them. So it's possible that a lot of the problems with so many insertions and so forth would go away if they were better word models to begin with. So this might just be a temporary thing. But - But, on the other hand, and maybe - maybe it's a decent idea. So um The question we're gonna wanna go through next week when Hynek shows up I guess is given that we've been - if you look at what we've been trying, we're uh looking at uh, by then I guess, combinations of features and multi-band Uh, and we've been looking at cross-language, cross task issues. And they've been not so much looking at the cross task uh multiple language issues. But they've been looking at uh - at these issues. At the on-line normalization and the uh voice activity detection. And I guess when he comes here we're gonna have to start deciding about um what do we choose from what we've looked at to um blend with some group of things in what they've looked at And once we choose that, how do we split up the effort? Uh, because we still have - even once we choose, we've still got uh another month or so, I mean there's holidays in the way, but - but uh I think the evaluation data comes January thirty- first so there's still a fair amount of time to do things together it's just that they probably should be somewhat more coherent between the two sites in that - that amount of time.
me018: When they removed the silence frames, did they insert some kind of a marker so that the recognizer knows it's - knows when it's time to back trace or something?
me013: Well, see they, I - I think they're Um. I don't know the - the specifics of how they're doing it. They're - they're getting around the way the recognizer works because they're not allowed to um, change the scripts
me018: Oh, right.
me013: for the recognizer, I believe. So. Uh.
me018: Maybe they're just inserting some nummy frames or something?
me013: Uh, you know that's what I had thought. But I don't - I don't think they are. I mean that's - sort of what - the way I had imagined would happen is that on the other side, yeah you
me018: Hmm.
me013: p- put some low level noise or something. Probably don't want all zeros. Most recognizers don't like zeros but
me018: Hmm.
me013: but you know,
me018: Yeah.
me013: put some epsilon in or some rand- sorry epsilon random variable in or something.
me018: Some constant vector.
me013: Maybe not a constant but it doesn't, uh - don't like to divide by the variance of that,
me018: I mean i- w- Or something -
me013: but I mean it's
me018: That's right. But something that - what I mean is something that is very distinguishable from speech.
me013: Mm-hmm.
me018: So that the - the silence model in HTK will always pick it up.
me013: Yeah. So I - I - that's what I thought they would do. or else, uh uh maybe there is some indicator to tell it to start and stop, I don't know.
me018: Hmm.
me013: But whatever they did, I mean they have to play within the rules of this specific evaluation.
me018: Yeah.
me013: We c- we can find out.
me018: Cuz you gotta do something. Otherwise, if it's just a bunch of speech, stuck together -
me013: No they're -
me018: Yeah.
me013: It would do badly and it didn't so badly, right? So they did something.
me018: Yeah, right. Yeah, yeah.
me013: Yeah. Uh. So, OK, So I think this brings me up to date a bit. It hopefully brings other people up to date a bit. And um Um I think - Uh, I wanna look at these numbers off-line a little bit and think about it and - and talk with everybody uh, outside of this meeting. Um, but uh No I mean it sounds like - I mean there - there - there are the usual number of - of little - little problems and bugs and so forth but it sounds like they're getting ironed out. And now we're seem to be kind of in a position to actually uh, look at stuff and - and - and compare things. So I think that's - that's pretty good. Um I don't know what the - One of the things I wonder about, coming back to the first results you talked about, is - is how much, uh things could be helped by more parameters. And uh - And uh how many more parameters we can afford to have, in terms of the uh computational limits. Because anyway when we go to twice as much data and have the same number of parameters, particularly when it's twice as much data and it's quite diverse, um, I wonder if having twice as many parameters would help. Uh, just have a bigger hidden layer.
mn007: Mm-hmm.
me013: Uh But - I doubt it would help by forty per cent. But
mn007: Yeah.
me013: but uh Just curious. How are we doing on the resources? Disk, and -
mn007: I think we're alright, um, not much problems with that.
me013: OK. Computation?
mn007: It's OK. Well this table took uh more than five days to get back .
me013: We - Yeah. Yeah, well.
mn007: But - Yeah.
me013: Are - were you folks using Gin? That's a - that just died, you know?
mn007: Mmm, no. You were using Gin perhaps, yeah? No.
fn002: No.
me006: It just died.
me013: No? Oh, that's good. OK. Yeah, we're gonna get a replacement
fn002: Yes.
me013: server that'll be a faster server, actually. That'll be - It's a
mn007: Hmm.
me013: seven hundred fifty megahertz uh SUN
me034: Tonic.
me013: uh But it won't be installed for a little while.
mn007: Mm-hmm.
me013: U-
me026: Do we -
me013: Go ahead.
me026: Do we have that big new IBM machine the, I think in th-
me013: We have the little tiny IBM machine that might someday grow up to be a big IBM machine. It's got s- slots for eight, uh IBM was donating five, I think we only got two so far, processors. We had originally hoped we were getting eight hundred megahertz processors. They ended up being five fifty. So instead of having eight processors that were eight hundred megahertz, we ended up with two that are five hundred and fifty megahertz. And more are supposed to come soon and there's only a moderate amount of dat- of memory. So I don't think anybody has been sufficiently excited by it to spend much time uh with it, but uh Hopefully, they'll get us some more parts, soon and - Uh, yeah, I think that'll be - once we get it populated, that'll be a nice machine. I mean we will ultimately get eight processors in there. And uh - and uh a nice amount of memory. Uh so it'll be a pr- pretty fast Linux machine.
me026: And if we can do things on Linux, some of the machines we have going already, like Swede?
me013: Mm-hmm.
me026: Um It seems pretty fast.
me013: Mm-hmm.
me026: But - I think Fudge is pretty fast too.
me013: Yeah, I mean you can check with uh Dave Johnson. I mean, it - it's - I think the machine is just sitting there. And it does have two processors, you know and - Somebody could do - you know, uh, check out uh the multi-threading libraries. And I mean i- it's possible that the - I mean, I guess the prudent thing to do would be for somebody to do the work on - on getting our code running on that machine with two processors even though there aren't five or eight. There's - there's - there's gonna be debugging hassles and then we'd be set for when we did have five or eight, to have it really be useful. But. Notice how I said somebody and turned my head your direction. That's one thing you don't get in these recordings. You don't get the - don't get the visuals but -
me026: I- is it um mostly um the neural network trainings that are um slowing us down or the HTK runs that are slowing us down?
me013: Uh, I think yes. Uh, Isn't that right? I mean I think you're - you're sort of held up by both, right? If the - if the neural net trainings were a hundred times faster you still wouldn't be anything - running through these a hundred times faster because you'd be stuck by the HTK trainings, right?
mn007: Mmm. Yeah.
me013: But if the HTK - I mean I think they're both - It sounded like they were roughly equal? Is that about right?
mn007: Yeah.
me013: Yeah.
me026: Because, um I think that'll be running Linux, and Sw- Swede and Fudge are already running Linux so, um I could try to get um the train- the neural network trainings or the HTK stuff running under Linux, and to start with I'm wondering which one I should pick first.
me013: Uh, probably the neural net cuz it's probably - it - it's - it's um - Well, I - I don't know. They both - HTK we use for um this Aurora stuff Um Um, I think It's not clear yet what we're gonna use for trainings uh - Well, there's the trainings uh - is it the training that takes the time, or the decoding? Uh, is it about equal between the two? For - for Aurora?
mn007: For HTK?
me013: For - Yeah. For the Aurora?
mn007: Uh Training is longer.
me013: OK.
mn007: Yeah.
me013: OK. Well, I don't know how we can - I don't know how to - Do we have HTK source? Is that -
mn007: Mmm.
me013: Yeah. You would think that would fairly trivially - the training would, anyway, th- the testing uh I don't - I don't think would parallelize all that well. But I think that you could certainly do d- um, distributed, sort of - Ah, no, it's the - each individual sentence is pretty tricky to parallelize. But you could split up the sentences in a test set.
me018: They have a - they have a thing for doing that and th- they have for awhile, in HT K.
me013: Yeah?
me018: And you can parallelize the training. And run it on several machines and it just basically keeps counts.
me013: Aha!
me018: And there's something - a final thing that you run and it accumulates all the counts together.
me013: I see.
mn007: Mmm.
me018: I don't what their scripts are set up to do for the Aurora stuff, but -
mn007: Yeah.
me013: Something that we haven't really settled on yet is other than this Aurora stuff, uh what do we do, large vocabulary training slash testing for uh tandem systems. Cuz we hadn't really done much with tandem systems for larger stuff. Cuz we had this one collaboration with CMU and we used SPHINX. Uh, we're also gonna be collaborating with SRI and we have their - have theirs. Um So I don't know Um. So I - I think the - the advantage of going with the neural net thing is that we're gonna use the neural net trainings, no matter what,
me026: OK.
me013: for a lot of the things we're doing, whereas, w- exactly which HMM - Gaussian-mixture-based HMM thing we use is gonna depend uh So with that, maybe we should uh go to our digit recitation task. And, it's about eleven fifty. Canned. Uh, I can - I can start over here. Great, uh, could you give Adam a call. Tell him to
me006: Oh.
me013: He's at two nine seven seven. OK. I think we can @@ You know Herve's coming tomorrow, right? Herve will be giving a talk, yeah, talk at eleven.
me006: Hello, is Adam there? Hey Adam, this is Barry. Yeah we're all done. OK, thanks. Bye bye.
me013: Did uh, did everybody sign these consent Er everybody Has everyone signed a consent form before, on previous meetings? You don't have to do it again each time Yes. microphones off