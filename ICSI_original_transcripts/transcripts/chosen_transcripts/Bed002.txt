me003: I guess.
me011: OK, we're on. So just make sure that th- your wireless mike is on, if you're wearing a wireless.
me003: Check one. Check one.
me011: And you should be able to see which one - which one you're on by, uh, watching the little bars change.
mn015: So, which is my bar? Mah! Number one.
me011: Yep.
me003: Sibilance. Sibilance.
me011: So, actually, if you guys wanna go ahead and read digits now, as long as you've signed the consent form, that's alright.
me003: Are we supposed to read digits at the same time?
me011: No.
me003: Oh, OK.
me011: No. Each individually. We're talking about doing all at the same time but I think cognitively that would be really difficult. To try to read them while everyone else is.
me003: Everyone would need extreme focus.
me011: So, when you're reading the digit strings, the first thing to do is just say which transcript you're on.
me010: Other way. We m- We may wind up with ver- We - we may need versions of all this garbage.
mn015: For our stuff. Yeah.
me010: Yeah.
me011: Um. So the first thing you'd wanna do is just say which transcript you're on. So.
me010: Yeah.
me011: You can see the transcript? There's two large number strings on the digits? So you would just read that one. And then you read each line with a small pause between the lines. And the pause is just so the person transcribing it can tell where one line ends and the other begins. And I'll give - I'll read the digit strings first, so can see how that goes. Um. Again, I'm not sure how much I should talk about stuff before everyone's here.
me010: Mmm. Well, we have one more coming.
me011: OK. Well, why don't I go ahead and read digit strings and then we can go on from there.
me010: OK. Well, we can start doing it.
me011: Thanks. So, uh, just also a note on wearing the microphones. All of you look like you're doing it reasonably correctly, but you want it about two thumb widths away from your mouth, and then, at the corner. And that's so that you minimize breath sounds, so that when you're breathing, you don't breathe into the mike. Um. Yeah, that's good. And uh - So, everyone needs to fill out, only once, the speaker form and the consent form. And the short form - I mean, you should read the consent form, but uh, the thing to notice is that we will give you an opportunity to edit a- all the transcripts. So, if you say things and you don't want them to be released to the general public, which, these will be available at some point to anyone who wants them, uh, you'll be given an opportunity by email, uh, to bleep out any portions you don't like. Um. On the speaker form just fill out as much of the information as you can. If you're not exactly sure about the region, we're not exactly sure either. So, don't worry too much about it. The - It's just self rating. Um. And I think that's about it. I mean , should I - Do you want me to talk at all about why we're doing this and what this project is? or - ?
me010: Um, yeah. No. There was - there was - Let's see.
me003: Does Nancy know that we're meeting in here?
me010: Oh - She got an emai- she was notified.
mn015: I sent an email.
me003: Oh yeah, she got an e- Yeah, yeah.
me010: Whether she knows is another question. Um. So are the people going to be identified by name?
me011: Well, what we're gonna - we'll anonymize it in the transcript.
me010: Right.
me011: Um, but not in the audio.
me010: OK. So, then in terms of people worrying about,
me011: So the-
me010: uh, excising things from the transcript, it's unlikely. Since it - it does- isn't attributed. Oh, I see, but the a- but the - but the -
me011: Right, so if I said, "Oh, hi Jerry, how are you?", we're not gonna go through and cancel out the "Jerry"s.
me010: Yeah. Sure.
me011: Um, so we will go through and, in the speaker ID tags there'll be, you know, Mone O seven, Mone O eight.
me010: Right. Right.
me011: Um, but uh, um, it w- uh, I don't know a good way of doing it on the audio, and still have people who are doing discourse research be able to use the data.
me010: OK. Mm-hmm. No, I - I wasn't complaining, I just wanted to understand.
me011: Yep. Right.
me010: OK.
mn015: Well, we can make up aliases for each of us.
me011: Yeah, I mean, whatever you wanna do is fine, but we find that - We want the meeting to be as natural as possible.
me010: Right.
me012: OK.
me010: OK.
me011: So, we're trying to do real meetings.
me010: Right.
me011: And so we don't wanna have to do aliases and we don't want people to be editing what they say.
mn015: Right.
me010: Right.
me011: So I think that it's better just as a pro- post-process to edit out every time you bash Microsoft. You know?
mn015: Mm-hmm.
me010: Right. Um, OK. So why don't you tell us briefly your - give - give your e- normal schpiel.
me011: OK. So th- Um. So this is - The project is called Meeting Recorder and there are lots of different aspects of the project. Um. So my particular interest is in the PDA of the future. This is a mock-up of one. Yes, we do believe the PDA of the future will be made of wood. Um. The idea is that you'd be able to put a PDA at the table at an impromptu meeting, and record it, and then be able to do querying and retrieval later on, on the meeting. So that's my particular interest, is a portable device to do m- uh, information retrieval on meetings. Other people are interested in other aspects of meetings. Um. So the first step on that, in any of these, is to collect some data. And so what we wanted is a room that's instrumented with both the table top microphones, and these are very high quality pressure zone mikes, as well as the close talking mikes. What the close talk- ng- talking mikes gives us is some ground truth, gives us, um, high quality audio, um, especially for people who aren't interested in the acoustic parts of this corpus. So, for people who are more interested in language, we didn't want to penalize them by having only the far field mikes available. And then also, um, it's a very, very hard task in terms of speech recognition. Um. And so, uh, on the far field mikes we can expect very low recognition results. So we wanted the near field mikes to at least isolate the difference between the two. So that's why we're recording in parallel with the close talking and the far field at the same time. And then, all these channels are recorded simultaneously and framed synchronously so that you can also do things like, um, beam-forming on all the microphones and do research like that. Our intention is to release this data to the public, um, probably through f- through a body like the LDC. And, uh, just make it as a generally available corpus. Um. There's other work going on in meeting recording. So, we're - we're working with SRI, with UW, Um. NIST has started an effort which will include video. We're not including video, obviously. And uh - and then also, um, a small amount of assistance from IBM. Is also involved. Um. Oh, and the digit strings, this is just a more constrained task. Um. So because the general environment is so challenging, we decided to - to do at least one set of digit strings to give ourselves something easier. And it's exactly the same digit strings as in TI-digits, which is a common connected digits corpus. So we'll have some, um, comparison to be able to be made.
me010: OK.
me011: Anything else?
me010: No.
me011: OK, so when the l- last person comes in, just have them wear a wireless. It should be on already. Um. Either one of those. And uh, read the digit strings and - and fill out the forms. So, the most important form is the consent form, so just be s- be sure everyone signs that, if they consent.
mn015: I'm sure it's pretty usual for meetings that people come late, so you will have to leave what you set .
me011: Yeah. Right. And uh, just give me a call, which, my number's up there when your meeting is over.
me010: Yep.
me011: And - I'm going to leave the mike here but it's n- Uh, but I'm not gonna be on so don't have them use this one. It'll just be sitting here. Thank you.
mn015: Input? Yeah. There we go.
me010: By the way, Adam, we will be using the, uh,
mn015: Yep.
me010: screen as well. So, you know. Wow! Organization. So you guys who got email about this oh f- uh, Friday or something about what we're up to.
me003: No.
me012: No.
mn015: I got it.
me003: What was the nature of the email?
me010: Oh, this was about um, inferring intentions from features in context, and the words, like "s- go to see", or "visit", or some-
mn015: Wel- we- I - uh - I - I - @@
me010: You didn't get it?
me003: I don't think I did.
me010: I guess these g- have got better filters. Cuz I sent it to everybody. You just blew it off. OK.
me003: Ah.
mn015: It's really simple though. So this is the idea. Um. We could pursue, um, if we thought it's - it's worth it but, uh, I think we - we will agree on that, um, to come up with a - with a sort of very, very first crude prototype, and do some implementation work, and do some - some research, and some modeling. So the idea is if you want to go somewhere, um, and focus on that object down - Oh, I can actually walk with this. This is nice. down here. That's the Powder-Tower. Now, um, we found in our, uh, data and from experiments, that there's three things you can do. Um, you can walk this way, and come really, really close to it. And touch it. But you cannot enter or do anything else. Unless you're interested in rock climbing, it won't do you no good standing there. It's just a dark alley. But you can touch it. If you want to actually go up or into the tower, you have to go this way, and then through some buildings and up some stairs and so forth. If you actually want to see the tower, and that's what actually most people want to do, is just have a good look of it, take a picture for the family, you have to go this way, and go up here. And there you have a vre- really view - It exploded, the - during the Thirty -years-war. Really uh, interesting sight.
me003: Mmm.
mn015: And um, these uh - these lines are, um, paths, or so- That's ab- er, i- the street network of our geographic information system. And you can tell that we deliberately cut out this part. Because otherwise we couldn't get our GIS system to take - to lead people this way. It would always use the closest point to the object, and then the tourists would be faced, you know, in front of a wall, but it would do them absolutely no good. So, what we found interesting is, first of all, intentions differ. Maybe you want to enter a building. Maybe you want to see it, take a picture of it. Or maybe you actually want to come as close as possible to the building. For whatever reason that may be.
me003: What's it - what's it made out of?
mn015: Um, r- red limestone.
me003: So maybe you would wanna touch it.
mn015: Yeah, maybe you would want to touch it. Um. Okay, I - This, um - These intentions, we - w- w- we could, if we want to, call it the - the Vista mode, where we just want to - eh - s- get the overview or look at it, the Enter mode, and the, well, Tango mode. I always come up with - with silly names. So this "Tango" means, literally translated, "to touch". So - But sometimes the - the Tango mode is really relevant in the - in the sense that, um, if you want to, uh - If you don't have the intention of entering your building, but you know that something is really close to it, and you just want to approach it, or get to that building. Consider, for example, the Post Office in Chicago, a building so large that it has its own zip code. So the entrance could be miles away from the closest point. So sometimes it m- m- m- makes sense maybe to d- to distinguish there. So, um, I've looked, uh, through twenty some - Uh, I didn't look through all the data. um, and there - there's uh, a lot more different ways in people - uh, the ways people phrase how to g- get - if they want to get to a certain place. And sometimes here it's b- it's a little bit more obvious - Um. Maybe I should go back a couple of steps and go through the -
me010: No, OK come in, sit down. If you grab yourself a microphone.
fe004: OK.
mn015: You need to sign some stuff and read some digits.
me010: Well, you can sign afterwards.
mn015: O- or later.
fe004: OK.
me003: You have to al- also have to read some digits.
me010: Afterwards.
fe004: OK. Afterwards is fine. OK, go ahead.
mn015: They are uncomfortable.
fe004: @@ Small?
mn015: Mm-hmm.
fe004: Really small? OK. I see. OK.
mn015: Yep.
fe004: Thank you.
mn015: OK, but that was our idea. Is -
me010: And it - it - it - it- it also has to be switched on, Nance.
me003: No, that one's already on, I thought he said. Yeah.
mn015: I - I think -
me010: It's on? OK, good.
fe004: OK. It's on.
mn015: OK. That was the idea. Um, people, when they w- when they want to go to a building, sometimes they just want to look at it. Sometimes they want to enter it. And sometimes they want to get really close to it. That's something we found. It's just a truism. And the places where you will lead them for these intentions are sometimes ex- in- incredibly different. I - I gave an example where the point where you end up if you want to look at it is completely different from where - if you want to enter it. So, this is sort of how people may, uh - may phrase those requests to a - a - a mock-up system at least that's the way they did it. And we get tons of - of these "how do I get to", "I want to go to", but also, "give me directions to", and "I would like to see". And um, what we can sort of do, if we look closer a- closer at the - the data - That was the wrong one. um, we can look at some factors that may make a difference. First of all, very important, and um, that - I've completely forgot that when we talked. This is of course a crucial factor, "what type of object is it?" So, some buildings you just don't want to take pictures of. Or very rarely. But you usually want to enter them. Some objects are more picturesque, and you - more f- more highly photographed. Then of course the - the actual phrases may give us some idea of what the person wants. Um. Sometimes I found in the - Uh, looking at the data, in a superficial way, I found some s- sort of modifiers that - that m- may also give us a hint, um, "I'm trying to get to" Nuh? "I need to get to". Sort of hints to the fact that you're not really sightseeing and - and just f- there for pleasure and so forth and so on. And this leads us straight to the context which also should be considered. That whatever it is you're doing at the moment may also inter- influence the interpretation of - of a phrase. So, this is, uh, really uh, uh, uh - My suggestion is really simple. We start with, um - Now, Let me, uh, say one more thing. What we do know, is that the parser we use in the SmartKom system will never differentiate between any of these. So, basically all of these things will result in the same XML M-three-L structure. Sort of action "go", and then an object. Yeah? and a source. So it's - it's - it's way too crude to d-
fe004: Mm-hmm.
mn015: capture those differences in intentions. So, I thought, "Mmm! Maybe for a deep understanding task, that's a nice sort of playground or first little thing." Where we can start it and n- sort of look - "OK, we need, we gonna get those M-three-L structures. The crude, undifferentiated parse. Interpreted input. We may need additional part of speech, or maybe just some information on the verb, and modifiers, auxiliaries. We'll see. And I will try to - to sort of come up with a list of factors that we need to get out of there, and maybe we want to get a g- switch for the context. So this is not something which we can actually monitor, now, but just is something we can set. And then you can all imagine sort of a - a constrained satisfaction program, depending on - on what, um, comes out. We want to have an - a structure resulting if we feed it through a belief-net or - or something along those lines. We'd get an inferred intention, we - we produce a structure that differentiates between the Vista, the Enter, and the, um, Tango mode. Which I think we maybe want to ignore. But. That's my idea. It's up for discussion. We can change all of it, any bit of it. Throw it all away.
me012: Now @@ this email that you sent, actually.
me010: What?
me012: Now I remember the email.
me010: OK.
me003: Huh. Still, I have no recollection whatsoever of the email. I'll have to go back and check.
me010: Not important. So, what is important is that we understand what the proposed task is. And, the - the i- uh, Robert and I talked about this some on Friday. And we think it's well-formed. So we think it's a well-formed, uh, starter task for this, uh, deeper understanding in the tourist domain.
me012: So, where exactly is the, uh, deeper understanding being done? Like I mean, s- is it before the Bayes-net? Is it, uh -
me010: Well, it's the - it's - it's always all of it. So, in general it's always going to be, the answer is, everywhere. Uh, so the notion is that, uh, this isn't real deep. But it's deep enough that you can distinguish between these th- three quite different kinds of, uh, going to see some tourist thing. And, so that's - that's the quote "deep" that we're trying to get at. And, Robert's point is that the current front-end doesn't give you any way to - Not only doesn't it do it, but it also doesn't give you enough information to do it. It isn't like, if you just took what the front-end gives you, and used some clever inference algorithm on it, you would be able to figure out which of these is going on. So, uh, and this is - Bu- I- in general it's gonna be true of any kind of deep understanding, there's gonna be contextual things, there're gonna be linguistic things, there're gonna be discourse things, and they gotta be combined. And, my idea on how to combine them is with a belief-net, although it may turn out that t- some totally different thing is gonna work better. Um, the idea would be that you, uh, take your - You're editing your slide?
mn015: Yeah. As i- a- sort of, as I get ideas, uh w- uh.
me010: Oh.
mn015: So, discourse - I - I - I thought about that. Of course that needs to sort of go in there.
me010: Oh. I'm sorry. OK. So. This is minutes - taking minutes as we go,
mn015: Yep.
me010: in his - in his own way. Um, but the p- the - Anyway. So the thing is, i- uh, d- naively speaking, you've - you've got a - for this little task, a belief-net, which is going to have as output, the conditional pr- probability of one of three things, that the person wants to - uh, to View it, to Enter it, or to Tango with it. Um. So that - the - the output of the belief-net is pretty well formed. And, then the inputs are going to be these kinds of things. And, then the question is - there are two questions - is, uh, one, where do you get this i- information from, and two, what's the structure of the belief-net? So what are the conditional probabilities of this, that, and the other, given these things? And you probably need intermediate nodes. I - we don't know what they are yet. So it may well be that, uh, for example, that, uh, knowing whether - Oh, another thing you want is some information abou- I think, about the time of day. Now, they may wanna call that part of context. But the time of day matters a lot.
mn015: Mm-hmm.
me010: And, if things are obviously closed, then, you -
mn015: People won't want to enter it.
me010: Pe- people don't wanna enter them. And, if it's not obvious, you may want to actually
mn015: s- b-
me010: uh, point out to people that it's closed - you know, what they're g- going to is closed and they don't have the option of entering it. So another thing that can come up, and will come up as soon as you get serious about this is, that another option of course is to have a - more of a dialogue. So if someone says something you could ask them.
me003: Yeah.
me010: OK. And - Now, one thing you could do is always ask them, but that's boring. And it also w- it also be a pain for the person using it. So one thing you could do is build a little system that, said, " whenever you got a question like that I've got one of three answers. Ask them which one you want." OK. But that's, um, not what we're gonna do.
mn015: But maybe that's a false state of the system, that it's too close to call.
me010: Oh yeah. You want the - you want the ability to a- You want the ability to ask, but what you don't wanna do is onl- build a system that always asks every time, and i- That's not getting at the scientific problem, and it's -
mn015: Mm-hmm.
me010: In general you're - you know, it's gonna be much more complex than that. a- This is purposely a really simple case.
mn015: Yeah.
me010: So, uh - Yeah.
mn015: I have one more point to - to Bhaskara's question. Um, I think also the - the - the deep understanding part of it is - is going to be in there to the extent that we um, want it in terms of our modeling. We can start, you know, basic from human beings, model that, its motions, going, walking, seeing, we can mem- model all of that and then compose whatever inferences o- we make out of these really conceptual primitives. That will be extremely deep in the - in - in - in my understanding.
me010: Yeah. S- so - so the way that might come up, if you wanna - Suppose you wanted to do that, you might say, "Um, as an intermediate step in your belief-net, is there a Source-Path-Goal schema involved?" OK? And if so, uh, is there a focus on the goal? Or is there a focus on the path? or something. And that could be, uh, one of the conditiona- you know, th- the - In some piece of the belief-net, that could be the - the appropriate thing to enter.
me012: So, where would we extract that information from? From the M-three-L?
me010: No. No. See, the M-three-L is not gonna give th- What he was saying is, the M-three-L does not have any of that. All it has is some really crude stuff saying,
me012: Right.
me010: "A person wants to go to a place."
me003: The M-three-L is the old SmartKom output? OK.
me010: Right. M-three- well, M-three-L itself refers to Multimedia Mark-up Language.
me003: It's just a language. Right, yeah.
me010: So we have th- w- we- we we have to have a better w- way of referring to -
mn015: The parser output?
me010: Mm-hmm. Yeah. The -
mn015: " Analyzed speech" I think it's what they call it, really, oder -
me010: Well, OK. Yeah.
mn015: o- th- No, actually, intention lattices is what we're gonna get.
me010: Is- i- but they c- they call it intention lattice, but tha- Anyway.
mn015: In- in- a- intention lattice k- Hypothesis. They call it intention hypotheses.
me010: Right. So, th- they're gonna give us some cr- uh - or - We can assume that y- you get this crude information. About intention, and that's all they're going to provide. And they don't give you the kind of object, they don't give you any discourse history, if you want to keep that you have to keep it somewhere else.
mn015: Well, they keep it. We have to request it.
me010: Right.
mn015: Nuh? But it's not in there.
me010: Well, they - they kee- they keep it by their lights. It may - it may or may not
mn015: Hmm. Yeah, or i-
me010: be what - what we want. Yeah.
me003: So, if someone says, "I wanna touch the side of the Powder-Tower", that would - basically, we need to pop up Tango mode and the - and the directions?
me010: If i- if - Yeah, if it got as simple as that, yeah. But it wouldn't.
me003: Yeah. OK. But that doesn't necessarily - But we'd have to infer a Source-Path-Goal to some degree for touching the side, right?
mn015: Well - Uh, th- the- there is a p- a point there if I understand you. Correct? Um, because um, sometimes people just say things - This you find very often. "Where is the city hall?" And this do- they don't wanna sh- see it on a map, or they don't wanna know it's five hundred yards away from you, or that it's to the - your north. They wanna go there. That's what they say, is, "Where is it?". Where is that damn thing?
me003: And the parser would output -
mn015: Well, that's a - a question mark. sh- A lot of parsers, um, just, uh - That's way beyond their scope, is - of interpreting that. You know? But um, still outcome w- the outcome will be some form of structure, with the town hall and maybe saying it's a WH focus on the town hall. But to interpret it,
fe004: Mm-hmm.
mn015: you know? somebody else has to do that job later.
me010: Yeah.
me003: I'm just trying to figure out what the SmartKom system would output, depending on these things.
mn015: Um, it will probably tell you how far away it is, at least that's - That's even what Deep Map does. It tells you how far away it is, and - and shows it to you on a map. Because i- we can not differentiate, at the moment, between, you know, the intention of wanting to go there or the intention of just know- wanting to know where - where it is.
fe004: People no- might not be able to infer that either, right? Like the fact - Like, I could imagine if someone came up to me and asked, "Where's the city hall?", I might say, g- ar- "Are you trying to get there?" Because how I describe um, t- its location - uh, p- probably depend on whether I think I should give them, you know, directions now, or
mn015: Mm-hmm. @@
fe004: say, you know, whatever, "It's half a mile away" or something like that.
mn015: It's a granularity factor, because where people ask you, "Where is New York? ", you will tell them it's on the East Coast.
me010: Yeah .
fe004: Uh-huh. Yeah. Exactly. Right. Right.
mn015: Y- y- eh - you won't tell them how to get there, ft- you know, take that bus to the airport and blah-blah-blah.
fe004: Yeah. Right.
mn015: But if it's the post office, you will tell them how to get there.
fe004: Mm-hmm.
mn015: So th- They have done some interesting experiments on that in Hamburg as well. So.
fe004: Right. Right.
me010: But - i- Go - go back to the - the uh, th- Yeah, that slide.
mn015: So I w- this is - "onto" is - is knowledge about buildings, their opening times, and then t- coupled with time of day, um, this should - You know .
fe004: So that context was like, um, their presumed purpose context, i- like business or travel, as well as the utterance context, like, "I'm now standing at this place at this time".
me010: Yeah, well I think we ought to d- a- As we have all along, d- We - we've been distu- distinguishing between situational context, which is what you have as context, and discourse context, which you have as DH, I don't know what the H means.
mn015: Mm-hmm. Nuh. History. Discourse history.
me010: OK.
mn015: Yeah.
me010: Whatever. So we can work out terminology later.
mn015: Yep.
me010: So, they're - they're quite distinct. I mean, you need them both, but they're quite distinct. And, so what we were talking about doing, a- a- as a first shot, is not doing any of the linguistics. Except to find out what seems to be useful. So, the - the - the reason the belief-net is in blue, is the notion would be - Uh, this may be a bad dis- bad idea, but the idea is to take as a first goal, see if we could actually build a belief-net that would make this three way distinction uh, in a plausible way, given these - We have all these transcripts and we're able to, by hand, extract the features to put in the belief-net. Saying, "Aha! here're the things which, if you get them out of - out of the language and discourse, and put them into the belief-net, it would tell you which of these three uh, intentions is most likely. " And if - to actually do that, build it, um - you know, run it - y- y- run it on the data where you hand-transcribe the parameters. And see how that goes. If that goes well, then we can start worrying about how we would extract them. So - where would you get this information? And, expand it to - to other things like this. But if we can't do that, then we're in trouble. I mean th- th- i- i- if you can't do this task, um -
mn015: We need a different, uh, engine. Machine, I mean.
me010: Uh, uh , yeah, or something. Well it - i- I- if it - if it's the belief-nets, we- we'll switch to you know, logic or some terrible thing, but I don't think that's gonna be the case. I think that, uh, if we can get the information, a belief-net is a perfectly good way of doing the inferential combination of it. The real issue is, do- what are the factors involved in determining this? And I don't know.
mn015: Hmm. But, only w-
me010: Hold on a s- Hold on a second.
mn015: Muh .
me010: So, I know . Uh, uh, is it clear what's going on here?
me012: Yep.
fe004: Um, I missed the beginning, but, um I guess - could you back to the slide, the previous one? So, is it that it's, um - These are all factors that uh, a- These are the ones that you said that we are going to ignore now? or that we want to take into account? You were saying n-
me010: Take them into account.
fe004: Take the - the linguistic factors too.
me010: But - but you don't worry about - h-
fe004: Oh, how to extract these features. OK.
me010: how to extract them. So, f- let's find out which ones we need first,
fe004: Got it. OK. And - and it's clear from the data, um, like, sorta the correct answer in each case.
me010: and -
fe004: But l-
me010: No.
fe004: OK. That's - that's the thing I'm curious ab-
mn015: No. But -
me010: Let's go back to th- Let's go back to the - the - the slide of data.
fe004: Like do we know from the data wh- which -
mn015: Um -
fe004: OK. So -
mn015: Not from that data. But, um, since we are designing
fe004: Mm-hmm.
mn015: a - a - a - an, compared to this, even bigger data collection effort,
fe004: Mm-hmm.
mn015: um, we will definitely take care to put it in there,
fe004: Mm-hmm.
mn015: in some
me010: Yeah.
mn015: shape, way, form over the other,
fe004: Right.
mn015: to see whether we can, then, get sort of empirically validated data. Um, from this, we can sometimes, you know - an- and that's - that - but that - isn't that what we need for a belief-net anyhow? is sort of - s- sometimes when people want to just see it, they phrase it more like this?
fe004: Mm-hmm.
mn015: But it doesn't exclude anybody from phrasing it totally differently, even if they still - you know?
fe004: Right. Right.
mn015: But then other factors may come into play that change the outcome of their belief-net.
fe004: Right.
mn015: So, um, this is exactly what - Because y- you can never be sure. And I'm sure even i- the most, sort of, deliberate data collection experiment will never give you data that say, "Well, if it's phrased like that,
fe004: Sure.
mn015: the intention is this." You know, because then, uh, you -
fe004: u- u- I mean, the only way you could get that is if you were to give th- the x- subjects a task. Right? Where you have - where your, uh, current goal is to -
mn015: We- Yeah! That's what we're doing. But - but we will still get the phrasing all over the place. I'm sure that, you know -
fe004: @@ So that's what you want? OK. So you will know. Mm-hmm.
me010: Yeah.
fe004: The - No, that's fine. I guess, it's just knowing the intention from
me010: Yeah.
mn015: Mm-hmm.
me010: From that task, yeah. So,
fe004: the experimental subject. @@
me010: uh, I think you all know this, but we are going to actually use this little room and start recording subjects probably within a month or something. So, this is not any - lo- any of you guys' worry, except that we may want to push that effort to get information we need. So our job is to figure out how to solve these problems. If it turns out that we need data of a certain sort, then the sort of data collection branch can be, uh, asked to do that. And one of the reasons why we're recording the meeting for these guys is cuz we want their help when we d- we start doing uh, recording of subjects. So, yeah - y- you're absolutely right, though. No, you - you will not have, and there it is, and, uh - But you know, y- y- the, um -
fe004: And I think the other concern that has come up before, too, is if it's - um - I don't know if this was collected - what situation this data was collected in. Was it - is it the one that you showed in your talk? Like people -
mn015: No, no. No.
fe004: But OK. So was this, like, someone actually mobile, like - s- using a device?
mn015: Uh, N- no, no- not - i- it was mobile but not - not with a w- a real wizard system. So there were never answers.
fe004: Uh-huh. OK. OK. But, is it - I guess I don't know - The situation of - of collecting th- the data of, like - Here you could imagine them being - walking around the city. as like one situation. And then you have all sorts of other c- situational context factors that would influence w- how to interpret, like you said, the scope and things like that.
mn015: Mm-hmm.
fe004: If they're doing it in a - you know, "I'm sitting here with a map and asking questions", I - I would imagine that the data would be really different. Um, so it's just -
mn015: Yeah. But - It was never th- th- the goal of that data collection to - to serve for sat- for such a purpose. So that's why for example the tasks were not
fe004: Mm-hmm.
mn015: differentiated by intentionality, there was n- there was no label, you know, intention A, intention B, intention C. Or task A, B, C.
fe004: Mm-hmm. Right.
mn015: Um I'm sure we can produce some if we need it, um, that -
fe004: Mm-hmm.
mn015: that will help us along those lines. But, you know, you gotta leave something for other people to model. So, to - Finding out what, you know,
fe004: Mm-hmm.
mn015: situational con- what the contextual factors of the situation really are, you know is an interesting s- interesting thing.
fe004: Mm-hmm.
mn015: u- u- Sort of I'm, at the moment, curious and I'm - I'm - s- w- want to approach it from the end where we can s- sort of start with this toy system that we can play around with,
fe004: Mm-hmm.
mn015: so that we get a clearer notion of what input we need
fe004: Mm-hmm.
mn015: for that, what suffices and what doesn't. And then we can start worrying about where to get this input, what - what do we need, you know - Ultimately once we are all experts in changing that parser, for example, maybe, there's just a couple three things we need to do and then we get more whatever, part of speech and more construction-type-like
fe004: Mm-hmm. Hmm.
mn015: stuff out of it. It's a m- pragmatic approach, uh, at the moment.
me003: How exactly does the data collection work? Do they have a map, and then you give them a scenario of some sort?
mn015: OK. Imagine you're the - the subject. You're gonna be in here, and somebody - And - and you see, uh, either th- the three-D model, or uh, a QuickTime animation of standing u- in a square in Heidelberg. So you actually see that. Um. The uh, um, first thing is you have to read a text about Heidelberg. So, just off a textbook, uh, tourist guide, to familiarize, uh, yourself with that sort of odd-sounding German street names, like Fischergasse and so forth. So that's part one. Part two is, you're told that this huge new, wonderful computer system exists, that can y- tell you everything you want to know, and it understands you completely. And so you're gonna pick up that phone, dial a number, and you get a certain amount of tasks that you have to solve. First you have to know - find out how to get to that place, maybe with the intention of buying stamps in there. Maybe - So, the next task is to get to a certain place and take a picture for your grandchild. The third one is to get information on the history of an object. The fourth one - And then the g- system breaks down. It crashes,
fe004: a- At the third? Right then?
mn015: And - After the third task.
fe004: OK.
mn015: And then - Or after the fourth. Some find - @@ Forget that for now. And then, a human operator comes on, and - and exp- apologizes that the system has crashed, but, you know, urges you to continue, you know? now with a human operator. And so, you have basically the same tasks again, just with different objects, and you go through it again, and that was it. Oh, and one - one little bit - w- And uh, the computer you are - you are being told the computer system knows exactly where you are, via GPS. When the human operator comes on, um, that person does not know. So the GPS is crashed as well. So the person first has to ask you "Where are you?". And so you have to do some - s- tell the person sort of where you are, depending on what you see there. Um, this is a - a - a - a - a bit that I d- I don't think we - Did we discuss that bit? Uh, I just sort of squeezed that in now. But it's something, uh, that would provide some very interesting data for some people I know. So.
fe004: So, in the display you can - Oh, you said that you cou- you might have a display that shows, like, the -
mn015: Yeah. a- Additionally, y- you have a - a - a sort of a map type display.
fe004: a w- your perspective? sort of? And so, as you -
mn015: Uh, two-D. n-
fe004: Oh, two-D. OK. So as you move through it that's- they just track it on the -
mn015: Two-D. Yeah. b- y-
fe004: for themselves
mn015: You don't -
fe004: @@ there.
mn015: That's - I don't know. I but y- I don't think you really move,
fe004: OK. So
mn015: sort of. Yeah? I mean that would be an - an - an enormous technical effort, unless we would - We can show it walks to , you know. We can have movies of walking, you walking through - through Heidelberg, and u- ultimately arriving there.
fe004: Mm-hmm.
mn015: Maybe we wanna do that. Yeah.
fe004: Uh, I was just trying to figure out how - how ambitious the system is.
mn015: The map was sort of intended to - You want to go to that place. You know, and it's sort of there. And you see the label of the name -
fe004: Mm-hmm.
mn015: So we get those names, pronunciation stuff, and so forth, and we can change that.
fe004: Mm-hmm. Mm-hmm. So your tasks don't require you to - I mean, uh - yo- you're told - So when your task is, I don't know, "Go buy stamps" or something like that? So, do you have to respond? or does your - Uh, what are you ste- what are you supposed to be telling the system? Like, w- what you're doing now? or -
mn015: Well, we'll see what people do.
fe004: There's no - OK, so it's just like, "Let's figure out what they would say
mn015: Yeah, and - and we will record both sides. I mean, we will record the Wi- the Wizard -
fe004: under the circumstances". Uh-huh. Uh-huh.
mn015: I mean, in both cases it's gonna be a human, in the computer, and in the operator case. And we will re- there will be some dialogue, you know? So, you first have to do this, and that, and - and -
fe004: Yep. Mm-hmm.
mn015: see wh- what they say. We can ins- instruct the, uh, wizard in how expressive and talkative he should be. But um, maybe the - maybe what you're suggesting - Is what you're suggesting that it might be too poor, the data, if we sort of limit it to this ping pong one t- uh, task results in a question and then there's an answer and that's the end of the task? You wanna m- have it more - more steps, sort of?
fe004: Yeah, I - I don't know how much direction is given to the subject about what their interaction - I mean, th- they're unfamiliar w- with interacting with the system. All they know is it's this great system that could do
mn015: Mm-hmm.
fe004: s- stuff. Right? So -
mn015: Mm-hmm.
me010: Oh yeah, but - to some extent this is a different discussion. OK? So. Uh, we - we have to have this discussion of th- the experiment, and the data collection, and all that sorta stuff
fe004: Uh-huh.
me010: and we do have, um, a student who is a candidate for wizard. Uh, she's gonna get in touch with me. It's a student of Eve's. FEY, Fey? Spelled FEY. Do you - do you -
fe004: Oh, Fey Parrill. Yeah. Uh-huh.
me010: You know her? OK. Sh- Is sh-
fe004: She started taking the class last year and then didn't - um, you know, didn't continue. I g- She's a g- Is she an undergradua- She is a graduate, OK.
me010: She's graduated. Yeah.
fe004: Yeah, I m- I know her very, very briefly. I know she was inter- you know, interested in
me010: OK.
fe004: aspect and stuff like that .
me010: So, anyway, she's looking for some more part time work w- while she's waiting actually for graduate school. And she'll be in touch. So we may have someone, uh, to do this, and she's got you know, some background in - in all this stuff. And is a linguist st- and, so So. That's - So, Nancy, we'll have an- At some point we'll have another discussion on
fe004: Mm-hmm.
me010: exactly wha- t- t- you know, how that's gonna go. And um, Jane, but also, uh, Liz
fe004: Mm-hmm.
me010: have offered to help us do this,
fe004: Mmm.
me010: uh, data collection and design and stuff. So, when we get to that we'll have some people doing it that know what they're doing.
fe004: OK. I guess the reason I was asking about the sort of the de- the details of this kind of thing is that, um, it's one thing to collect data for, I don't know, speech recognition or various other tasks that have pretty c- clear correct answers, but with intention um, obviously, as you point out, there's a lot of di- other factors and - I'm not really sure, um, how - how - e- the question of how to make it a t- appropriate toy version of that - Um, it's ju- it's just hard. So, I mean, obviously it's a -
me003: Yeah, uh, actually I guess that was my question. Is the intention implicit in the scenario that's given? Like, do the -
fe004: It is, if they have these tasks that they're supposed to -
me003: Yeah, I just wasn't sure to what level of detail the task was.
fe004: to - to give - Yeah, uh -
mn015: Mm-hmm. n- No one is, at the moment.
fe004: Right. Right.
me003: OK.
me010: So, we- that's part of what we'll have to figure out.
fe004: Right. Mm-hmm.
me010: But, uh, the - The problem that I was tr- gonna try to focus on today was, let's suppose by magic you could collect dialogues in which, one way or the other, you were able to, uh, figure out both the intention, and set the context, and know what language was used. So let's suppose that we can get that kind of data. Um. The issue is, can we find a way to, basically, featurize it so that we get some discrete number of features so that, uh, when we know the values to all those features, or as many as possible, we can w- come up with the best estimate of which of the, in this case three little intentions, are most likely.
fe004: w- What are the t- three intentions? Is it to go there, to see it, and -
mn015: To come as close as possible to it.
me010: Th- the terminology we're using is to -
fe004: Yeah, it's @@ .
me010: Go back. To v-
fe004: OK.
me010: to View it. OK? To Enter it. Now those - It seems to me those are cl- you c- you have no trouble with those being distinct. "Take a picture of it"
fe004: Mm-hmm.
me010: you - you might well want to be a really rather different place than
fe004: Mm-hmm.
me010: entering it. And, for an object that's at all big,
fe004: Mm-hmm.
me010: uh, sort of getting to the nearest part of it
fe004: Mm-hmm.
me010: uh, could be quite different than either of those.
fe004: Mm-hmm.
me010: Just sort of -
fe004: OK, so now I understand the referent of Tango mode.
me003: See, I would have thought it was more of a waltz.
fe004: I didn't get that before.
mn015: S- To "Waltz" it?
fe004: Yeah, like, how close are you gonna be? Like, Tango's really close.
me010: Well.
me003: Yeah, cuz a tango - Yeah.
me010: Well, anyway. So -
me012: All these So, like, the question is how what features can - like, do you wanna try to extract from, say, the parse or whatever?
me010: Right.
me012: Like, the presence of a word or the presence of a certain uh, stem, or -
me010: Right.
me012: certain construction or whatever.
me010: Is there a construction, or the kind of object, or w- uh, anything else that's in the si- It's either in the - in the s- the discourse itself or in the context. So if it turns out that, whatever it is, you want to know whether the person's uh, a tourist or not, OK? that becomes a feature. Now, how you determine that is another issue. But fo- for the current problem, it would just be, "OK, if you can be sure that it's a tourist, versus a businessman, versus a native, " or something, uh, that would give you a lot of discriminatory power and then just have a little section in your belief-net that said, "pppt!" Though sin- f- in the short run, you'd set them,
me012: Mm-hmm.
me010: and see ho- how it worked, and then in the longer run, you would figure out how you could derive them.
me012: Right.
me010: From previous discourse or w- any- anything else you knew.
me012: So, how should - What's the uh, plan? Like, how should we go about figuring out these -
me010: OK. So, first of all is, uh, do e- either of you guys, you got a favorite belief-net that you've, you know, played with? JavaBayes or something?
me012: Oh. No, not really.
me010: OK. Well, anyway. f- Get one. OK? So - y- so one of th- one of the things we wanna do is actually, uh, pick a package, doesn't matter which one, uh, presumably one that's got good interactive abilities, cuz a lot of what we're gonna be d- You know, we don't need the one that'll solve massive, uh, belief-nets quickly. d- w- These are not gonna get big in - in the foreseeable future. But we do want one in which it's easy to interact with and, uh, modify. Because i- that's - A lot of what it's gonna be, is, um, playing with this. And probably one in which it's easy to have, um, what amounts to transcript files. So that if - if we have all these cases - OK? So we make up cases that have these features, OK, and then you'd like to be able to say, "OK, here's a bunch of cases" - There're even ones tha- that you can do learning OK? So you have all their cases and - and their results and you have a - algorithms to go through and run around trying to set the - the probabilities for you. Um, probably that's not worth it. I mean, my guess is we aren't gonna have enough data that's good enough to make the - these data fitting ones worth it, but I don't know. So I would say you guy- the first task for you two guys is to um, pick a package. OK, and you wanna it s- You know, the standard things you want it stable, you want it - yeah, @@ . And, as soon as we have one, we can start
mn015: An- Nuh.
me010: trying to, uh, make a first cut at what's going on. But it - what I like about it is it's very concrete. OK? We - we have a - we know what the outcomes are gonna be, and we have some - some data that's loose, we can use our own intuition, and see how hard it is, and, importantly, what intermediate nodes we think we need. So it - if it turns out that just, thinking about the problem, you come up with things you really need to - You know, this is the kind of thing that is, you know, an intermediate little piece in your belief-net. That'd be really interesting.
me003: Mm-hmm.
mn015: And it - and it may serve as a platform for a person, maybe me, or whoever, who is interested in doing some linguistic analysis. I mean, w- we have the For- FrameNet group here, and we can see what they have found out about those concepts already, that are contained in the data, um, you know, to come up with a nice little set of features and um, maybe even means of s- uh, extracting them. And - and that altogether could also be - uh, become a nice paper that's going to be published somewhere, if we sit down and write it. And um - When you said JavaBayes belief-net you were talking about ones that run on coffee? or that are in the program language Java?
me010: No, th- It turns out that there is a, uh - The new end of Java libraries. OK, and it turns out one called JavaBayes. Which is
mn015: Mmm. OK.
me010: one that fair - people around here use a fair amount. I have no idea whether that's - @@ The obvious advantage of that is that you can then, relatively easily, get all the other Java packages for GUIs or whatever else you might want to do. So that i- that's I think why
mn015: Mm-hmm.
me010: a lot of people doing research use that. But it may not be - I have no idea whether that's the best choice an- and there're plenty of people around, students in the department who, you know, live and breathe Bayes-nets. So, uh,
fe004: There's the m- tool kit that um, Kevin Murphy has developed,
me010: Right.
fe004: which might be useful too. And it's available Matlab code.
me010: It's OK.
me012: Right.
me010: So, yeah, Kevin would be a good person to start with. Nancy knows him well. I don't know I don't know whether you guys have met Kevin yet or not, but, uh -
mn015: Mm-hmm. But i-
me012: Yeah, I know him.
me010: Yeah.
mn015: But since we all probably are pretty sure that, um, the - For example, this th- th- the dialogue history is - is um, producing XML documents. M-three-L of course is XML. And the ontology that um, uh the student is - is constructing for me back in - in EML is in OIL and that's also in XML. And so that's where a lot of knowledge about bakeries, about hotels, about castles and stuff is gonna come from.
me010: Mm-hmm. Yeah.
mn015: Um, so, if it has that IO capability and if it's a Java package, it will definitely be able - We can couple.
me010: Yeah. So, yeah, we're sort of committed to XML as the kind of, uh, interchange. But that's, you know, not a big deal.
mn015: Who isn't, nuh?
me010: So, in terms of - of - interchanging in and out of any module we build, It 'll be XML. And if you're going off to queries to the ontology, for example, you'll have to deal with its interface. But that's - that's fine an- and um, all of these things have been built with much bigger projects than this in mind. So they - they have worked very hard. It's kind of blackboards and multi-wave blackboards and ways of interchanging and registering your a- And so forth. So, that I don't think is even worth us worrying about just yet. I mean if we can get the core of the thing to work, in a way that we're comfortable with, then we ca- we can get in and out of it with, uh, XML, um, little descriptors. I believe. I don't - I don't see -
mn015: Hmm. Yeah. Yeah, I like, for example, the - what you said about the getting input from - from just files about where you h- where you have the data, have specified the features and so forth. That's, of course, easy also to do with, you know, XML.
me010: Uh, you could have an X - yeah, you could make and XML format for that. Sure.
mn015: So r-
me010: That - that - um, you know, feature value XML format is probably as good a way as any. So it's als- Yeah, I guess it's also worth, um, while you're poking around, poke around for XML packages that um, do things you'd like.
me012: Doesn't - does SmartKom system have such packages?
me010: Sure.
mn015: Yeah. The - the lib- M-three-L library does that. It's also -
me010: And the question is, d- you c- you - you'll have to l- We'll have to l- That should be - ay- We should be able to look at that -
mn015: No, u- u- y- um- the - What I - What sort of came to my mind i- is - was the notion of an idea that
me010: Yeah.
mn015: if - if there are l- nets that can actually lear- try to set their own, um, probability factors based on - on - on - on input - which is in file format, if we, um, get really w- wild on this, we may actually want to use some - some corpora that other people made and, for example, if - if they are in - in MATE, then we get XM L documents with discourse annotations, t- you know, t- from the discourse act down to the phonetic level.
me012: Mm-hmm.
mn015: Um, Michael has a project where - you know, recognizing discourse acts and he does it all in MATE, and so they're actually annotating data and data and data. So if we w- if we think it's worth it one of these days, not - not with this first prototype but maybe with a second, and we have the possibility of - of taking input that's generated elsewhere and learn from that,
me012: Right.
mn015: that'd be nice.
me010: It'd be nice, but - but I - I - I do- I don't wanna count on it. I mean, you can't - you can't run your project based on the speculation that -
mn015: No, no, uh, just for -
me010: that the data will come, and you don't have to actually design the nets.
mn015: Nuh. Just a back door that - I - I think we should devote m-
me010: Could happen. Yeah. So in terms of - of the, um - the - what the SmartKom gives us for M-three-L packages, it could be that they're fine, or it could be eeh. You don't - You know, you don't really like it. So we're not - we're not abs- we're not required to use their packages. We are required at the end to give them stuff in their format, but hey.
me012: Right.
me010: Um, it's, uh - It doesn't control what you do in- you know, internally.
mn015: @@
me003: What's the time frame for this?
mn015: Two days?
me010: Huh?
mn015: Two, three days?
me010: Yeah bu- w- I'd like that this - y- yeah, this week, to ha- to n- to have y- guys, uh, you know, pick the - y- you know, belief-net package and tell us what it is, and give us a pointer so we can play with it or something.
mn015: No.
me012: Sure.
me010: And, then as soon as we have it, I think we should start trying to populate it for this problem. Make a first cut at, you know, what's going on, and probably the ea- easiest way to do that is some on-line way. I mean, you can f- figure out whether you wanna make it a web site or - You know, how-
mn015: Uh - I - I - I - um, OK, I - t- Yeah. I was actually more joking. With the two or three days. So this was - was a usual jo-
me010: OK, I wasn't.
mn015: Um, it will take as long as y- y- yo- you guys need for that. But um,
me010: Yeah. Right.
mn015: maybe it might be interesting if - if the two of you can agree on who's gonna be the speaker next Monday, to tell us something about the net you picked, and what it does, and how it does that.
me010: Well, y- Well, or both of them speak. We don't care.
me012: Sure.
mn015: Yeah, or you can split it up. So, y-
me012: Hmm.
mn015: So that will be sort of the assignment for next week, is to - to - for slides and whatever net you picked and what it can do and - and how far you've gotten. Pppt!
me010: Well, I'd like to also, though, uh, ha- have a first cut at what the belief-net looks like. Even if it's really crude. OK? So, you know, here a- here are -
me003: So we're supposed to @@ about features and whatnot, and -
me010: Right. Yeah.
me012: Mm-hmm.
me010: And, as I said, what I'd like to do is, I mean, what would be really great is you bring it in - If - if - if we could, uh, in the meeting, say, you know, "Here's the package, here's the current one we have," uh, you know, "What other ideas do you have?" and then we can think about this idea of making up the data file. Of, uh, you know, get a - t- a p- tentative format for it, let's say XML, that says, l- you know, "These are the various scenarios we've experienced." We can just add to that and there'll be this - this file of them and when you think you've got a better belief-net, You just run it against this, um - this data file.
me012: So we'll be like, hand, uh, doing all the probabilities. OK.
me010: Oh, yeah, unt- until we know more.
me003: And what's the relation to this with - Changing the table so that the system works in English?
mn015: OK. So this is - Whi- while you were doing this, I received two lovely emails. The - the full NT and the full Linux version are there. I've downloaded them both, and I started to unpack the Linux one - Uh, the NT one worked fine. and I started unta- pack the Linux one, it told me that I can't really unpack it because it contains a future date. So this is the time difference between Germany. I had to wait until one o'clock this afternoon before I was able to unpack it. Now, um - Then it will be my job to get this whole thing running both on Swede and on this machine. And so that we have it. And then um - Hopefully that - hoping that my urgent message will now come through to Ralph and Tilman that it will send some more documentation along, we - I control p- Maybe that's what I will do next Monday is show the state and show the system and show
me010: Yeah.
mn015: that.
me010: Yeah. So the answer, Johno, is that these are, at the moment, separate. Uh, what one hopes is that when we understand how the analyzer works, we can both worry about converting it to English and worry about how it could ex- extract the parameters we need for the belief-net.
me003: I guess my question was more about time frame. So we're gonna do belief-nets this week, and then -
me010: Oh, yeah. I don't know. n- None of this is i- n- Neither of these projects has got a real tight time-line, in the sense that over the next month there's a - there's a deliverable.
me003: OK.
me010: OK. S- so uh, it's opportu- in that sense it's opportunistic. If - if - you know, if we don't get any information for these guys f- for several weeks then we aren't gonna sit around, you know, wasting time, trying to do the problem or guess what they - You know, just pppt! go on and do other things.
me003: OK.
mn015: Yeah, but uh - but the uh - This point is really - I think very, very valid that ultimately we hope that - that both will merge into a harmonious and, um, wonderful, um, state where we can not only do the bare necessities, IE, changing the table so it does exactly in English what it does in German, but also that we can sort of have the system where we can say, "OK, this is what it usually does, and now we add this little thing to it", you know? whatever, Johno's and Bhaskara's great belief-net, and we plug it in, and then for these certain tasks, and we know that navigational tasks are gonna be a core domain of the new system, it all - all of a sudden it does much better. Nuh? Because it can produce better answers, tell the person, as I s- showed you on this map, n- you know, produce either you know, a red line that goes to the Vista point or a red line that goes to the Tango point or red line that goes to the door, which would be great. So not only can you show that you know something sensible but ultimately, if you produce a system like this, it takes the person where it wants to go. Rather than taking him always to the geometric center of a building, which is what they do now.
me012: Mmm.
mn015: And we even had to take out a bit. Nancy, you missed that part. We had to take out a bit of the road work. So that it doesn't take you to the wall every time. So. Um -
fe004: Oh, really?
mn015: So this was actually an actual problem that we encountered, which nobody have - has - because car navigation systems don't really care. You know, they get you to the beginning of the street, some now do the house number.
fe004: Hmm. Mm-hmm.
mn015: But even that is problematic. If you go d- If you wanna drive to the SAP in Waldorf, I'm sure the same is true of Microsoft, it takes you to the - the address, whatever, street number blah-blah-blah, you are miles away from the entrance.
me010: Yep.
mn015: Because the s- postal address is maybe a mailbox somewhere.
fe004: Mm-hmm.
mn015: Nuh? but the entrance where you actually wanna go is somewhere completely different. So unless you're a mail person you really don't wanna go there.
fe004: Right, yeah.
me010: Probably not then, cuz y- you probably can't drop the mail there anyway.
mn015: Probably neither - e- not even that.
me010: Yeah. Clear?
me012: OK. Sounds good.
me003: The Powder-Tower is made of red limestone.
fe004: I was wondering. OK.
mn015: Do you wanna see a picture?
fe004: Sure!
me003: Sure!
mn015: Have to reboot for that though.
fe004: Um. So, you two, who'll be working on this, li- are - are you gl- will you be doing - Well, I mean are you supposed to just do it by thinking about the situation? Can you use the sample data? Is it like - Yeah, I mean, ho- is there more than -
me010: Of course they use the sample data.
fe004: Is there a lot s- of sample data that is beyond what you - what you have there?
mn015: There - there's more than I showed, but um, um, I think this is sort of um, in part my job to look at that and - and to see whether there are features in there that can be extracted, and to come up with some
fe004: Yeah. Right.
mn015: features that are not you know, empirically based on - on a real experiment or on - on - on reality but sort of on your intuition of you know, "Aha!
fe004: Mm-hmm.
me012: Mm-hmm .
fe004: Mm-hmm.
mn015: This is maybe a sign for that, and this is maybe a sign for this."
fe004: Mm-hmm.
me003: Mm-hmm.
me012: So, yeah. Later this week we should sort of get together, and sort of
mn015: Talk features.
me012: start thinking about that, hopefully.
mn015: Yep.
me010: OK. We can end the meeting and call Adam, and then we wanna s- look at some filthy pictures of Heidelberg. We can do that as well. Uh, is that OK?
mn015: Well they had - they used the ammunition - They stored the ammunition in that tower.
me010: Alright.
mn015: And that's why, when it was hit by uh, a cannon ball, it exploded.
me003: It exploded.
me010: Oh. Ni-
me003: That's why they call it the Powder-Tower.
mn015: Ahh.
me003: OK. I first thought it had something to do with the material that it - w- that's why I asked.
fe004: That's right, OK.
mn015: Mmm.