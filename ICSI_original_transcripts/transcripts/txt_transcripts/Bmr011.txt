me013: Are we on? We're on. OK.
me018: Is it on?
mn005: Yeah.
me013: Yeah. OK, so, uh, we haven't sent around the agenda. So,
mn005: One, two - u- OK .
fe016: Why is it so cold in here?
me013: i- uh, any agenda items anybody has, wants to talk about, what's going on?
fe008: I c- I could talk about the meeting.
me011: Does everyone - has everyone met Don?
fe008: Yeah.
me011: Yeah? OK.
mn005: Yeah.
mn014: Now, yeah.
me013: It's on?
me001: Hello.
mn005: Yeah.
me001: Yeah.
me013: OK, agenda item one, introduce Don. OK, we did that. Uh -
mn005: We went -
fe016: Well, I had a - just a quick question but I know there was discussion of it at a previous meeting that I missed, but just about the - the wish list item of getting good quality close-talking mikes on every speaker.
me013: OK, so let's - let's - So let's just do agenda building right now. OK, so let's talk about that a bit.
fe016: I mean, that was -
me013: Uh, @@ tuss- close talking mikes, better quality. OK, uh, we can talk about that. You were gonna - starting to say something?
fe008: Well, you - you, um, already know about the meeting that's coming up and I don't know if - if this is appropriate for this. I don't know. I mean, maybe - maybe it's something we should handle outside of the meeting.
me018: What meeting?
me013: No, no, that's OK. We can - so - we can ta- so n- NIST is - NIST folks are coming by next week and so we can talk about that.
fe008: OK. Yeah.
me018: Who's coming?
me013: I think Uh, uh, John Fiscus and, uh, I think George Doddington will be
fe008: Mm-hmm.
me013: around as well. Uh, OK, so we can talk about that. Uh, I guess just hear about how things are going with, uh, uh, the transcriptions. That's right. That would sorta be an obvious thing to discuss.
fe008: Sure. Mm-hmm.
me013: Um, An- anything else, uh, strike anybody?
fe016: Uh, we started running recognition on one conversation but it's the r- isn't working yet. So,
me013: OK.
fe016: But if anyone has -
me018: Wha-
fe016: uh, the main thing would be if anyone has, um, knowledge about ways to, uh, post-process the wave forms that would give us better recognition, that would be helpful to know about.
me013: Um,
me011: Dome yeah, it sounds like a topic of conversation.
me013: Yeah, so, uh -
me018: What about, uh, is there anything new with the speech, nonspeech
mn014: Yeah , we're working more on it but, it's not finished.
me018: stuff?
me013: OK. Alright, that seems like a - a good collection of things. And we'll undoubtedly think of other things.
fe008: I had thought under my topic that I would mention the, uh, four items that I - I, uh, put out for being on the agenda f- on that meeting, which includes like the pre-segmentation and the - and the developments in multitrans.
me013: Oh, under the NIST meeting.
fe008: Yeah, under the NIST thing. Yeah.
me013: OK. Alright, why don't we start off with this, u- u- I guess the order we brought them up seems fine. Um,
fe008: Yeah.
me013: so, better quality close talking mikes. So the one issue was that the - the, uh, lapel mike, uh, isn't as good as you would like. And so, uh, it - it'd be better if we had close talking mikes for everybody. Right? Is that - is that basically the point?
fe016: Ri- um, yeah, the - And actually in addition to that, that the - the close talking mikes are worn in such a way as to best capture the signal. And the reason here is just that for the people doing work not on microphones but on sort of like dialogue and so forth, uh - or and even on prosody, which Don is gonna be working on soon, it adds this extra, you know, vari- variable for each speaker to - to deal with when the microphones aren't similar.
me011: Right.
me013: Mm-hmm.
fe016: So - And I also talked to Mari this morning and she also had a strong preference for doing that. And in fact she said that that's useful for them to know in starting to collect their data too.
me013: Mm-hmm. Right, so one th-
me011: Well, so -
me013: uh, well one thing I was gonna say was that, um, i- we could get more, uh, of the head mounted microphones even beyond the number of radio channels we have because I think whether it's radio or wire is probably second-order. And the main thing is having the microphone close to you, u- although, not too close.
fe016: Mm-hmm.
me011: Right, so, uh, actually the way Jose is wearing his is - is c- correct. The good way. So you want to -
mn005: Yeah. Is -
me013: Yeah.
mn005: I- it's not cor- it's correct?
me013: Is.
me011: Yeah, th- that's good. So it's towards the corner of your mouth so that breath sounds don't get on it. And then just sort of
mn005: Yeah.
me013: Yes.
mn005: Yeah. Yeah. Yeah.
me011: about, uh, a thumb or - a thumb and a half away from your - from your mouth.
mn005: Yeah. Uh, yeah.
me013: Right. How am I d-
fe016: But we have more than one type of - I mean, for instance, you're -
mn014: Yeah.
me011: And this one isn't very adjustable, so this about as good as I can get cuz it's a fixed boom.
mn005: Yeah.
fe016: Right.
mn005: Yeah. Is fixed. Yeah.
me013: Yeah.
fe016: But if we could actually standardize, you know, the - the microphones, uh, as much as possible that would be really helpful.
me018: Mm-hmm.
mn005: Yeah.
me011: Mm-hmm.
me013: Well, I mean it doesn't hurt to have a few extra microphones around, so why don't we just go out and - and get an order of - of if this microphone seems OK to people,
mn005: Yeah.
me013: uh, I'd just get a half dozen of these things.
me011: Well the onl- the only problem with that is right now, um, some of the Jimlets aren't working. The little - the boxes under the table.
me013: Yeah.
me011: And so, w- Uh, I've only been able to find three jacks that are working.
me013: Yeah.
me018: Can we get these, wireless?
me011: So -
me013: No, but my point is -
fe016: But y- we could just record these signals separately and time align them with the start of the meeting.
me013: R- r- right -
me011: I - I'm not sure I'm follow. Say that again?
me013: Right now, we've got, uh, two microphones in the room, that are not quote-unquote standard. So why don't we replace those -
me011: OK, just two.
me013: Well, however many we can plug in. You know, if we can plug in three, let's plug in three. Also what we've talked before about getting another, uh, radio,
me011: OK.
mn005: Mm-yeah.
me011: Right.
me013: and so then that would be, you know, three more.
me011: Right. OK.
mn005: Mm-hmm.
me013: So, uh - so we should go out to our full complement of whatever we can do, but have them all be the same mike. I think the original reason that it was done the other way was because, it w- it was sort of an experimental thing and I don't think anybody knew whether people would rather have more variety or -
fe016: Right.
me013: or, uh, more uniformity, but - @@ but uh, sounds - sounds fine.
me011: Sounds like uniformity wins.
mn005: Right .
me013: Yeah.
fe016: Well, for short term research it's just - there's just so much effort that would have to be done up front n- uh, so - yeah, uniformity would be great.
me011: Well - Yeah.
me018: Is it because - You - you're saying the - for dialogue purposes, so that means that the transcribers are having trouble with those mikes? Is that what you mean? Or - ?
fe016: Well Jane would know more about the transcribers.
fe008: And that's true. I mean, I - we did discuss this. Uh, and - and -
me011: Yep. Couple times.
fe008: a couple times, so, um, yeah, the transcribers notice - And in fact there're some where, um - ugh well, I mean there's - it's the double thing. It's the equipment and also how it's worn. And he's always - they always - they just rave about how wonderful Adam's - Adam's channel is.
fe016: Right.
me011: What can I say.
fe008: And then,
fe016: So does the recognizer.
me013: Yeah.
me011: Oh, really? Yeah, I'm not surprised. I mean, "Baaah!"
fe008: Yeah. Yeah, but I mean it's not just that, it's also you know you-
fe016: Even if - if you're talking on someone else's mike it's still you w-
me013: Yeah.
fe008: It's also like n- no breathing, no - You know, it's like it's -
mn014: Yeah.
fe008: it's um, it's really - it makes a big difference from the transcribers' point of view and also from the research s- point of view.
me013: Yeah.
me011: Yeah, it's an advantage when you don't breath. Yeah, I think that the point of doing the close talking mike is to get a good quality signal. We're not doing research on close talking mikes.
fe016: Right.
me013: When we're doing -
fe008: Yeah.
me011: So we might as well get it as uniform as we can.
me013: Yeah.
fe016: Right.
me013: Now, this is locking the barn door after the horse was stolen. We do have thirty hours, of - of speech, which is done this way. But -
me011: Yeah.
fe016: That's OK.
me013: but, uh, yeah, for future ones we can get it a bit more uniform.
fe016: Great, great.
me011: So I think just do a field trip at some point.
me013: Yeah, probably - yeah, to the store we talked about and that -
me011: Yep.
fe008: And there was some talk about, uh, maybe the h- headphones that are uncomfortable for people, to -
me011: Yep. So, as - as I said, we'll do a field trip and see if we can get all of the same mike that's more comfortable than - than these things, which I think are horrible.
fe008: OK.
me011: So.
fe008: Good.
fe016: Great, thank you very much. It's makes our job a lot easier.
me018: Especially for people with big heads.
me013: OK.
me011: And, you know, we're researchers, so we all have big heads.
me013: OK.
me018: Yeah.
me013: OK. Yeah. Uh, OK, second item was the, uh, NIST visit, and what's going on there.
fe008: Yeah. OK, so, um, uh, Jonathan Fiscus is coming on the second of February and I've spoken with, uh, u- u- a lot of people here, not everyone. Um, and, um, he expressed an interest in seeing the room and in, um, seeing a demonstration of the modified multitrans, which I'll mention in a second, and also, um, he was interested in the pre-segmentation and then he's also interested in the transcription conventions.
me011: Mm-hmm.
fe008: And, um - So, um, it seems to me in terms of like, um, i- i- it wou- You know, OK. So the room, it's things like the audio and c- and audi- audio and acoustic - acoustic properties of the room and how it - how the recordings are done, and that kind of thing. And, um. OK, in terms of the multi-trans, well that - that's being modified by Dave Gelbart to, uh, handle multi-channel recording.
me011: Oh, I should've - I was just thinking I should have invited him to this meeting. I forgot to do it.
fe008: Yeah, OK.
me011: So.
mn014: Yeah.
me011: Sorry.
fe008: Yeah. Well that's OK, I mean we'll - Yeah, and it's t- and it looks really great. He - he has a prototype. I - I, uh, @@ didn't - didn't see it, uh, yesterday but I'm going to see it today. And, uh, that's - that will enable us to do nice um, tight time marking of the beginning and ending of overlapping segments. At present it's not possible with limitations of - of the, uh, original design of the software. And um. So, I don't know. In terms of, like, pre-segmentation, that - that continues to be, um, a terrific asset to the - to the transcribers. Do you - I know that you're al- also supplementing it further. Do you want to mention something about that c- Thilo, or - ?
mn014: Um, yeah. What - what I'm doing right now is I'm trying to include some information about which channel, uh, there's some speech in. But that's not working at the moment. I'm just trying to do this by comparing energies, uh -
fe008: OK.
mn014: normalizing energies and comparing energies of the different channels. And so to - to give the transcribers some information in which channel there's - there's speech in addition to - to the thing we - we did now which is just, uh, speech-nonspeech detection on the mixed file.
fe008: This is good. Mm-hmm.
mn014: So I'm - I'm relying on - on the segmentation of the mixed file but I'm - I'm trying to subdivide the speech portions into different portions if there is some activity in - in different channels.
fe008: Excellent, so this'd be like w- e- providing also speaker ID potentially. Wonderful.
mn014: But - Yeah. Yeah.
fe008: Wonderful.
me013: Um, something I guess I didn't put in the list but, uh, on that, uh, same day later on in - or maybe it's - No, actually it's this week, uh, Dave Gelbart and I will be, uh, visiting with John Canny who i- you know, is a CS professor,
fe008: Oh.
me011: HCC .
me013: who's interested in ar- in array microphones.
me011: Oh, he's doing array mikes.
me013: Yeah. And so we wanna see what commonality there is here. You know, maybe they'd wanna stick an array mike here when we're doing things or - or maybe
me018: That would be cool.
me011: Yeah, that would be neat.
mn005: Yeah.
me018: That would be really neat.
me013: it's - it's not a specific array microphone they want but they might wanna just, - uh, you know, you could imagine them taking the four signals from these - these table mikes and trying to do something with them - Um, I also had a discussion - So, w- uh, we'll be over - over there talking with him, um, after class on Friday. Um, we'll let you know what - what goes with that. Also had a completely unrelated thing. I had a, uh, discussion today with, uh, Birger Kollmeier who's a, uh, a German, uh, scientist who's got a fair sized group doing a range of things. It's sort of auditory related, largely for hearing aids and so on. But - but, uh, he does stuff with auditory models and he's very interested in directionality, and location, and - and, uh, head models and microphone things. And so, uh, he's - he and possibly a student, there w- there's, uh, a student of his who gave a talk here last year, uh, may come here, uh, in the fall for, uh, sort of a five month, uh, sabbatical. So he might be around. Get him to give some talks and so on. But anyway, he might be interested in this stuff.
mn005: Mm-hmm.
me018: That - that reminds me, I had a - a thought of an interesting project that somebody could try to do with the data from here, either using, you know, the - the mikes on the table or
mn005: Mm-hmm.
me018: using signal energies from the head worn mikes, and that is to try to construct a map of where people were sitting,
me013: Right.
mn005: Uh-huh.
me011: Well Dan - Dan had worked on that. Dan Ellis, yeah.
me018: uh, based on -
mn005: Uh-huh.
me018: Oh, did he? Oh, that's interesting.
me011: So that - that's the cross-correlation stuff, was -
mn005: Yeah.
me011: was doing b- beam-forming.
me018: And so you could plot out who was sitting next to who and -
me013: A little bit, I mean, he didn't do a very extreme thing but just - it was just sort of
mn005: Yeah, yeah.
me011: No, he did start on it.
me013: e- e- given that, the - the - the block of wood with the - the - the two mikes on either side,
me011: Mm-hmm.
me013: if I'm speaking, or if you're speaking, or someone over there is speaking, it - if you look at cross-correlation functions, you end up with a -
mn005: Yeah.
me013: if - if someone who was on the axis between the two is talking, then you - you get a big peak there. And if - if someone's talking on - on - on, uh, one side or the other, it goes the other way. And then,
me018: Mm-hmm.
me013: uh, it - it - it even looks different if th- t- if the two - two people on either side are talking than if one in the middle. It - it actually looks somewhat different, so.
me018: Hmm. Well I was just thinking, you know, as I was sitting here next to Thilo that
mn014: Yeah.
me018: um, when he's talking, my mike probably picks it up better than your guys's mikes. So if you just looked at -
mn005: Yeah.
me011: Oh, that's another cl- cue, that's true.
mn005: Yeah.
me018: yeah, looked at the energy on my mike and you could get an idea about who's closest to who.
mn005: Yeah.
me013: Mm-hmm.
mn005: Yeah.
me013: Right.
mn005: Yeah.
me018: And -
me011: Or who talks the loudest.
mn005: Yeah.
mn014: Yeah.
me013: Yeah, well you have to - the appropriate normalizations are tricky, and - and - and are probably the key.
me011: Yeah.
mn014: Yeah.
fe016: You just search for Adam's voice on each individual microphone, you pretty much know where everybody's sitting.
mn005: Yeah.
mn014: Yeah.
me013: Yeah. We've switched positions recently so you can't - Anyway. OK. So those are just a little couple of news items.
fe008: Can I ask one thing? Uh, so, um, Jonathan Fiscus expressed an interest in, uh, microphone arrays.
me013: Yes.
fe008: Um, is there - I mean - b- And I also want to say, his - he can't stay all day. He needs to uh, leave for - uh, from here to make a two forty-five flight
me011: Oh, so just morning.
fe008: from - from Oakland.
me013: Right.
fe008: So it makes the scheduling a little bit tight but do you think that, um - that, uh, i- John Canny should be involved in this somehow or not. I have no idea.
me013: Probably not but I - I'll - I'll - I'll know better after I see him this Friday what - what kind of level he wants to get involved.
fe008: It's premature. Fine. Good.
me013: Uh, he might be excited to and it might be very appropriate for him to, uh, or he might have no interest whatsoever. I - I just really don't know.
fe008: OK.
me011: Is he involved in - Ach! I'm blanking on the name of the project. NIST has - has done a big meeting room - instrumented meeting room with video and microphone arrays, and very elaborate software. Is - is he the one working on that?
me013: Well that's what they're starting up.
me011: OK.
me013: Yeah. No, I mean, that's what all this is about. They - they haven't done it yet.
me011: OK. I had read some papers that looked like they had already done some work.
me013: They wanted to do it - Uh, well I think they've instrumented a room but I don't think they - they haven't started recordings yet. They don't have the t- the transcription standards. They don't have the -
me018: Are they going to do video as well?
me011: Hmm.
me013: Yeah.
me018: Hmm.
me013: I think. I think they are.
me011: Oh, cuz what - what I had read was, uh, they had a uh very large amount of software infrastructure for coordinating all this, both in terms of recording and also live room where you're interacting - the participants are interacting with the computer, and with the video, and lots of other stuff.
me013: Well, I'm - I'm - I'm not sure. All - all I know is that they've been talking to me about a project that they're going to start up
me011: So. OK. Well -
me013: recording people meet- in meetings. And, uh, it is related to ours. They were interested in ours. They wanted to get some uniformity with us, uh, about the transcriptions and so on.
me011: Alright.
me013: And one - one notable difference - u- u- actually I can't remember whether they were going to routinely collect video or not, but one - one, uh, difference from the audio side was that they are interested in using array mikes. So, um, I mean, I'll just tell you the party line on that. The reason I didn't go for that here was because, uh, the focus, uh, both of my interest and of Adam's interest was uh, in impromptu situations. And we're not recording a bunch of impromptu situations but that's because it's different to get data for research than to actually apply it. And so, uh, for scientific reasons we thought it was good to instrument this room as we wanted it.
mn005: Hmm.
me013: But the thing we ultimately wanted to aim at was a situation where you were talking with, uh, one or more other people i- uh, in - in an p- impromptu way, where you didn't - didn't actually know what the situation was going to be. And therefore it would not - it'd be highly unlikely that room would be outfitted with - with some very carefully designed array of microphones. Um, so it was only for that reason. It was just, you know, yet another piece of research and it seemed like we had enough troubles just -
me018: So there's no like portable array of mikes?
me013: No. So there's - there's -
mn005: Hmm.
me013: uh, there's a whole range of things - there's a whole array of things, that people do on this. So, um, the, uh - the big arrays, uh, places, uh, like uh, Rutgers, and Brown, and other - other places, uh, they have, uh, big arrays with, I don't know, a hundred - hundred mikes or something. And so there's a wall of mikes. And you get
me011: Xerox.
me018: Wow.
me013: really, really good beam-forming with that sort of thing. And it's - and, um, in fact at one point we had a - a proposal in with Rutgers where we were gonna do some of the sort of per channel signal-processing and they were gonna do the multi-channel stuff, but it d- it d- we ended up not doing it. But -
me018: I've seen demonstrations of the microphone arrays. It's amazing
me013: Yeah, it's r-
me018: how - how they can cut out noise.
me013: It's really neat stuff. And then they had the little ones, yeah.
me011: And then they have little ones too but I mean - but they don't have our block of wood, right?
me013: Yeah, our block of wood is unique. But the- But the- No, there are these commercial things now you can buy that have four mikes or something and - and, uh,
mn005: Yeah.
fe016: Mm-hmm.
me013: um - So, yeah, there's - there's - there's a range of things that people do.
me018: Huh.
me013: Um, so if we connected up with somebody who was interested in doing that sort of thing that's - that's a good thing to do. I mean, whenever I've described this to other people who are interested on the - with the acoustic side that's invariably the question they ask. Just like someone who is interested in the general dialogue thing will always ask "um, are you recording video? "
fe016: Right, right.
me013: Um, right? And - and the acoustic people will always say, "well are you doing, uh, uh, array microphones?" So it's - it's a good thing to do, but it doesn't solve the problem of how do you solve things when there's one mike or at best two mikes in - in this imagined PDA that we have. So maybe - maybe we'll do some more of it.
fe008: Well one thing I - I mean, I don't know. I mean, I know that having an array of - I mean, I would imagine it would be more expensive to have a - an array of microphones. But couldn't you kind of approximate the natural sis- situation by just shutting off uh, channels when you're - later on? I mean, it seems like if the microphones don't effect each other then couldn't you just, you know, record them with an array and then just not use all the data?
me011: It's - it's just a lot of infrastructure that
fe008: I see. Fine.
me011: for our particular purpose we felt we didn't need to set up.
fe016: Yeah.
fe008: OK.
me013: Yeah, if ninety-nine percent of what you're doing is c- is shutting off most of the mikes, then going through the - But if you get somebody who's - who - who has that as a primary interest then that put - then that drives it in that direction.
me011: That's right, I mean if someone - if someone came in and said we really want to do it,
fe016: Right.
me011: I mean, we don't care. That would be fine, Buy more disk space.
me018: So to save that data you - You have to have one channel recording per mike in the array? Is that -
me013: Well, uh, at some level - at some level. But then, you know, there's - it -
me011: I usually do a mix.
me013: there's -
me018: What you save, I mean, if you're going to do research with it. yeah
me013: There's - I - I don't know what they're going to do and I don't know how big their array is. Obviously if you were gonna save all of those channels for later research you'd use up a lot of space.
me018: Yeah. Hmm.
me013: And, th-
me011: Well their software infrastructure had a very elaborate design for plugging in filters, and mixers, and all sorts of processing. So that they can do stuff in real time and not save out each channel individually.
me013: Yeah.
me018: Mmm.
me013: Yeah.
me011: So it was, uh -
mn005: Yeah.
me013: But I mean, uh, for optimum flexibility later you'd want to save each channel. But I think in practical situations you would have some engine of some sort doing some processing to reduce this to some - to the equivalent of a single microphone that was very directional.
me018: Uh, oh, OK, I see.
me013: Right? So -
me018: Sort of saving the result of the beam-forming.
fe016: I mean, it seems -
mn005: Yeah.
fe016: it seems to me that there's - you know, there are good political reasons for - for doing this, just getting the data, because there's a number of sites - like right now SRI is probably gonna invest a lot of internal funding into recording meetings also, which is good, um, but they'll be recording with video and they'll be - You know, it'd be nice if we can have at least, uh, make use of the data that we're recording as we go since it's sort of - this is the first site that has really collected these really impromptu meetings, um, and just have this other information available. So, if we can get the investment in just for the infra- infrastructure and then, I don't know, save it out or have whoever's interested save that data out, transfer it there, it'd be g- it'd be good to have - have the recording.
me011: You mean to - to actually get a microphone array and
fe016: I think. Well, if -
me011: do that? And video and -
fe016: Even if we're not - I'm not sure about video. That's sort of an - video has a little different nature since right n- right now we're all being recorded but we're not being taped. Um, but it - definitely in the case of microphone arrays, since if there was a community interested in this,
me011: Well, but I think we need a researcher here who's interested in it.
fe016: then -
me011: To push it along.
me013: See the problem is it - it took, uh, uh, it took at least six months for Dan to get together the hardware and the software, and debug stuff in - in the microphones, and in the boxes. And it was a really big deal. And so I think we could get a microphone array in here pretty easily and, uh, have it mixed to - to one channel of some sort. But,
fe016: Mm-hmm.
me013: e- I think for @@ I mean, how we're gonna decide - For - for maximum flexibility later you really don't want to end up with just one channel that's pointed in the direction of the - the - the p- the person with the maximum energy or something like that. I mean, you - you want actually to - you want actually to have multiple channels being recorded so that you can - And to do that, it - we're going to end up greatly increasing the disk space that we use up, we also only have boards that will take up to sixteen channels and in this meeting, we've got eight people and - and six mikes. And there we're already using fourteen.
me011: And we actually only have fifteen. One of them's -
me013: E-
mn005: Yeah.
me011: Details. But fifteen, not sixteen.
fe016: Mm-hmm.
me013: Yeah. Yeah.
fe016: Well if there's a way to say time - to sort of solve each of these f- those - So suppose you can get an array in because there's some person at Berkeley who's interested and has some equipment, uh, and suppose we can - as we save it we can, you know, transfer it off to some other place that - that holds this - this data, who's interested, and even if ICSI it- itself isn't. Um, and it - it seems like as long as we can time align the beginning, do we need to mix it with the rest? I don't know. You know? The- So -
me013: Yeah. So I think you'd need a separate - a separate set up and the assumption that you could time align the two.
fe016: Yeah.
me011: And y- it'd certainly gets skew.
fe016: I mean it's just - it's worth considering as sort of once you make the up front investment and can sort of save it out each time, and - and not have to worry about the disk space factor, then it mi- it might be worth having the data.
me013: I'm not so much worried about disk space actually. I mentioned that, b- as a practical matter, but the real issue is
me011: Just -
me013: that, uh, there is no way to do a recording extended to what we have now with low skew. So you would have a t- completely separate set up, which would mean that the sampling times and so forth would be all over the place compared to this.
fe016: Right.
me013: So it would depend on the level of pr- processing you were doing later, but if you're d- i- the kind of person who's doing array processing you actually care about funny little times. And - and so you actually wou- would want to have a completely different set up than we have, one that would go up to thirty- two channels or something.
fe016: I see. Mmm.
me013: So basically - or a hun- Yeah. So,
me011: Or a hundred thirty-two.
me013: I'm kinda skeptical, but um I think that -
fe016: Mmm.
me013: So, uh, I don't think we can share the resource in that way. But what we could do is if there was someone else who's interested they could have a separate set up which they wouldn't be trying to synch with ours which might be useful for - for them.
fe016: Right, I mean at least they'd have the data and the transcripts, and -
me013: And then we can offer up the room, Yeah, we can o- offer the meetings, and the physical space, and - and - yeah, the transcripts, and so on.
fe016: Right. OK. Right, I mean, just - it'd be nice if we have more information on the same data. You know, and -
me013: Yeah.
fe016: But it's - if it's impossible or if it's a lot of effort then you have to just balance the two,
me013: Well I thi- yeah, the thing will be, u- u- in - in - again, in talking to these other people to see what - you know, what - what we can do.
fe016: so - Right.
me013: Uh, we'll see.
me018: Is there an interest in getting video recordings for these meetings?
me013: Right, so we have - we -
me018: I mean t-
me011: Yes, absolutely. But it's exactly the same problem, that you have an infrastructure problem, you have a problem with people not wanting to be video taped, and you have the problem that no one who's currently involved in the project is really hot to do it.
me018: Hmm. So there's not enough interest to overcome all of -
me011: Mm-hmm.
fe016: Right. Internally, but I know there is interest from other places that are interested in looking at meeting data and having the video. So it's just -
fe008: Yeah, w- although I - m- I - I have to u- u- mention the human subjects problems, that i- increase with video.
fe016: Right, that's true.
me013: Yeah, so it's, uh, people - people getting shy about it. There's this human subjects problem.
fe008: Yeah.
me013: There's the fact that then um, if - i- I- I've heard comments about this before, "why don't you just put on a video camera?" But you know, it's sort of like saying, "uh, well we're primarily interested in - in some dialogue things, uh, but, uh, why don't we just throw a microphone out there." I mean, the thing is, once you actually have serious interest in any of these things then you actually have to put a lot of effort in.
me018: Mmm.
me013: And, uh, you really want to do it right. So I think
me011: I know . Yep.
me013: NIST or LDC, or somebody like that I think is much better shape to do all that. We - there will be other meeting recordings. We won't be the only place doing meeting recordings. We are doing what we're doing.
fe008: Mm-hmm.
me013: And, uh, hopefully it'll be useful.
fe008: I - it - it occurred to me, has Don signed a human subject's form?
me011: Oh! Probably not. Has Don - have you s- did you si- I thought you did actually. Didn't you read a digit string?
fe008: A permission form?
me001: I was - Yeah, I was - I was here - I was here before once.
me018: You were here at a meeting before.
fe008: You were here at a meeting before.
me018: Yeah.
me011: Yeah, and you - and you signed a form.
me001: So.
fe008: Did you sign a form?
me001: Oh, I think so. Did I? I don't know.
me011: I'm pretty sure. Well I'll - I'll get another one before the end of the meeting. Thank you.
fe008: OK.
me013: Yeah.
fe008: OK.
me001: Yeah.
me013: Yeah.
fe008: You don't - you don't have to leave for it. But I just - you know.
me013: Yeah, we - we -
me011: Well I can't, I'm wired in.
me001: Can I verbally consent?
fe016: Yeah.
me013: We - we - we - we don't, uh -
fe008: o-
fe016: You're on recor- you're being recorded and -
me001: Yeah.
me013: we don't - we don't perform electro-shock during these meetings, and -
me001: I don't care. You can do whatever you want with it . That's fine.
me018: Usually.
me013: Yeah. OK. Uh, transcriptions.
fe008: Transcriptions, OK. Um, I thought about - there are maybe three aspects of this. So first of all, um, I've got eight transcribers. Uh, seven of them are linguists. One of them is a graduate student in psychology. Um, Each - I gave each of them, uh, their own data set. Two of them have already finished the data sets. And the meetings run, you know, let's say an hour. Sometimes as man- much as an hour and a half.
me018: How big is the data set?
fe008: Oh, it's - what I mean is one meeting. Each - each person got their own meeting. I didn't want to have any conflicts of, you know, of - of
me018: Ah, OK.
fe008: when to stop transcribing this one or - So I wanted to keep it clear whose data were whose, and - and -
me018: Uh-huh.
fe008: and so - And, uh, meetings, you know, I think that they're - they go as long as a - almost two hours in some - in some cases. So, you know, that means - you know, if we've got two already finished and they're working on - Uh, right now all eight of them have differe- uh, uh, additional data sets. That means potentially as many as ten might be finished by the end of the month. Hope so. But the pre-segmentation really helps a huge amount. And, uh, also Dan Ellis's innovation of the, uh - the multi-channel to here really helped a r- a lot
me018: Wow.
mn014: OK.
fe008: in terms of clearing - clearing up h- hearings that involve overlaps. But, um, just out of curiosity I asked one of them how long it was taking her, one of these two who has already finished her data set. She said it takes about, uh, sixty minutes transcription for every five minutes of real time. So it's about twelve to one, which is what we were thinking.
me011: or Yep. It's pretty good.
fe008: It's well in the range. OK. Uh, these still, when they're finished, um, that means that they're finished with their pass through. They still need to be edited and all but - But it's word level, speaker change, the things that were mentioned. OK, now I wanted to mention the, um, teleconference I had with, uh, Jonathan Fiscus. We spoke for an hour and a half
me011: Hmm.
fe008: and, um, had an awful lot of things in common. He, um, um, he in- indicated to me that they've - that he's been, uh, looking, uh, uh, spending a lot of time with - I'm not quite sure the connection, but spending a lot of time with the ATLAS system. And I guess that - I mean, I - I need to read up on that. And there's a web site that has lots of papers. But it looks to me like that's the name that has developed for the system that Bird and Liberman developed for the annotated graphs approach.
me011: Mm-hmm.
fe008: So what he wants me to do and what we - what we will do and - uh, is to provide them with the u- already transcribed meeting for him to be able to experiment with in this ATLAS System. And they do have some sort of software, at least that's my impression, related to ATLAS and that he wants to experiment with taking our data and putting them in that format, and see how that works out. I - I - I explained to him in - in detail the, uh, conventions that we're using here in this - in this word level transcript. And, um, you know, I - I explained, you know, the reasons that - that we were not coding more elaborately and - and the focus on reliability. He expressed a lot of interest in reliability. It's like he's - he's really up on these things. He's - he's very - Um, independently he asked, "well what about reliability?" So, he's interested in the consistency of the encoding and that sort of thing. OK, um -
fe016: Sorry, can you explain what the ATLAS - I'm not familiar with this ATLAS system.
fe008: Well, you know, at this point I think - Uh, well Adam's read more - in more detail than I have on this. I need to acquaint myself more with it. But, um, there - there is a way of viewing - Uh, whenever you have coding categories, um, and you're dealing with uh, a taxonomy, then you can have branches that - that have alternative, uh, choices that you could use for each - each of them. And it just ends up looking like a graphical representation.
me011: Is - is - Is ATLAS the - his annotated transcription graph stuff? I don't remember the acronym. The - the one - the - what I think you're referring to, they - they have this concept of an an- annotated transcription graph representation.
fe008: Yeah.
me011: And that's basically what I based the format that I did -
fe016: Oh. Oh.
me011: I based it on their work almost directly, in combination with the TEI stuff. And so it's very, very similar. And so it's - it's a data representation and a set of tools for manipulating transcription graphs of various types.
me018: Is this the project that's sort of, uh, between, uh, NIST and - and, uh, a couple of other places? The - the -
fe008: Mm-hmm. Including LDC. I think so.
me011: Yep.
me018: Yeah, y- right, OK.
fe008: Mm-hmm. Then there's their web site that has lots of papers. And I looked through them and they mainly had to do with this, um, this, uh, tree structure, uh, annotated tree diagram thing.
fe016: Mmm.
fe008: So, um, um - and, you know, in terms of like the conventions that I'm a- that I've adopted, it - there - there's no conflict at all.
me011: Right.
fe008: And he was, you know, very interested. And, "oh, and how'd you handle this?" And I said, "well, you know, this way" and - And - and we had a really nice conversation. Um, OK, now I also wanted to say in a different - a different direction is, Brian Kingsbury. So, um, I corresponded briefly with him. I, uh, c- I - He still has an account here. I told him he could SSH on and use multi-trans, and have a look at the already done, uh, transcription. And he - and he did. And what he said was that, um, what they'll be providing is - will not be as fine grained in terms of the time information. And, um, that's, uh - You know, I need to get back to him and - and, uh, you know, explore that a little bit more and see what they'll be giving us in specific, but I just haven't had time yet.
fe016: Hmm.
me018: The p- the people -
fe008: Sorry, what?
me018: The - the folks that they're, uh, subcontracting out the transcription to, are they like court reporters or -
fe008: Yes. Apparently - Well, I get the sense they're kind of like that. Like it's like a pool of - of somewhat uh, secretarial - I don't think that they're court reporters. I don't think they have the special keyboards and that - and that type of training. I - I get the sense they're more secretarial. And that, um,
me018: Mm-hmm. Hmm.
fe008: uh, what they're doing is giving them -
me018: Like medical transcriptionist type people -
me011: Nu- it's mostly - it's for their speech recognition products,
fe008: Yep.
me011: that they've hired these people to do.
me018: But aren't - they're - Oh, so they're hiring them, they're coming. It's not a service they send the tapes out to.
me011: Well they - they do send it out but my understanding is that that's all this company does is transcriptions for IBM for their speech product.
me018: Ah! Oh. OK. I gotcha.
me011: So most of it's ViaVoice, people reading their training material for that.
me018: I see.
fe008: Mm-hmm.
me018: I see.
fe008: Up to now it's been monologues, uh, as far my understood. And - and what they're doing is Brian himself downloaded - So -
me011: Yep, exactly. Yep.
me018: Mm-hmm.
fe008: So, um, Adam sent them a CD and Brian himself downloaded - uh, cuz, you know, I mean, we wanted to have it so that they were in familiar f- terms with what they wanted to do. He downloaded from the CD onto audio tapes. And apparently he did it one channel per audio tape. So each of these people is transcribing from one channel.
me011: Right.
fe008: And then what he's going to do is check it,
me018: Oh.
fe008: a- before they go be- beyond the first one. Check it and, you know, adjust it, and all that.
me018: So each person gets one of these channels -
me011: Right.
me018: OK.
me013: So if they hear something off in the distance they don't - they just go -
me011: Well, but that's OK, because, you know, you'll do all them and then combine them.
fe008: I - I don't know. I have t- I, you know I -
me018: But there could be problems, right? with that.
mn014: Yep.
fe008: I think it would be difficult to do it that way. I really d- uh, in my case -
fe016: Yeah.
me018: Well if you're tran- if you got that channel right there -
me011: No, no. We're talking about close talking, not the - not the desktop.
mn014: Yeah.
mn005: No, close talk.
me013: Are you?
fe008: Yes.
me011: I sure hope so. It'd be really foolish to do otherwise.
fe008: Well I th- I think so. Yeah, I - I would think that it would be kind of hard to come out with - Yeah.
fe016: I - I think it's sort of hard just playing the - you know, just having played the individual files. And I - I mean, I know you. I know what your voice sounds like. I'm sort of familiar with -
mn014: Yeah.
fe016: Uh, it's pretty hard to follow, especially
me011: One side.
fe008: I agree.
fe016: there are a lot of words that are so reduced phonetically that make sense when you know what the person was saying before.
me018: Yeah, that's -
mn014: Yeah.
fe008: And especially since a lot of these -
fe016: Uh, it sort of depends where you are in -
mn005: Yeah.
me011: But I mean we had this - we've had this discussion many times. And the answer is we don't actually know the answer because we haven't tried both ways.
fe008: Yeah, we have. Well, except I can say that my transcribers use the mixed signal mostly
me011: So. Mm-hmm.
fe008: unless there's a huge disparity in terms of the volume on - on the mix.
fe016: Mm-hmm.
me018: Right.
fe008: In which case, you know, they - they wouldn't be able to catch anything except the prominent channel, then they'll switch between. But - but really -
me011: Right. Well I think that - that might change if you wanted really fine time markings.
mn014: Yeah.
fe008: Well, OK. Yeah, well -
me011: So.
me013: But they're not giving f- really fine time markings.
me011: Right.
fe016: Actually, are th- so are they giving any time markings? In other words, if -
fe008: Well, I have to ask him. And that's - that's my email to him. That needs to be forthcoming. But - but the, uh - I did want to say that
fe016: Yeah. Cuz - OK.
fe008: it's hard to follow one channel of a conversation even if you know the people, and if you're dealing furthermore with highly abstract network concepts you've never heard of - So, you know, one of these people was - was transcribing the, uh, networks group talk and she said, "I don't really know what a lot of these abbreviations are," "but I just put them in parentheses cuz that's the - that's the convention and I just" - Cuz you know, if you don't know -
me011: Oh, I'd be curious to - to look at that.
me018: Just out of curiosity, I mean -
me011: They also all have h- heavy accents. The networks group meetings are all -
mn014: Yeah.
fe008: Yeah.
mn005: Yeah.
me018: Given all of the effort that is going on here in transcribing why do we have IB M doing it? Why not just do it all ourselves?
me013: Um, it's historical. I mean, uh, some point ago we thought that
mn005: No, just -
mn014: Uh-huh.
me013: uh, it - "boy, we'd really have to ramp up to do that", you know, like we just did,
me018: Mm-hmm.
me013: and, um, here's, uh, a - a, uh, collaborating institution that's volunteered to do it.
me018: Mm-hmm.
me013: So, that was a contribution they could make. Uh
me018: Mm-hmm.
me013: in terms of time, money, you know? And it still might be a good thing but -
me018: I'm just wondering now - Well, I'm - I'm wondering now if it's -
fe016: Actu- yeah, Mar- Mari asked me the same question as sort of -
me011: Well we can talk about more details later.
fe016: um, you know, yeah,
me013: Yeah.
fe016: whether to -
me013: Yeah. Yeah, so.
me018: Hmm.
me013: We'll see. I mean, I think, th- you know, they - they - they've proceeded along a bit. Let's see what comes out of it, and - and, uh, you know, have some more discussions with them.
fe008: Mm-hmm. It's very - a real benefit having Brian involved because of his knowledge of what the - how the data need to be used and so what's useful to have in the format.
me011: Yeah.
me013: Mm-hmm. Yeah.
me011: So, um, Liz, with - with the SRI recognizer, can it make use of some time marks?
fe016: OK, so this is a, um,
me011: I - I guess I don't know what that means.
fe016: and actually I should say this is what Don has b- uh, he's already been really helpful in, uh, chopping up these - So - so first of all you - um, I mean, for the SRI front-end, we really need to chop things up into pieces that are f- not too huge. Um, but second of all, uh - in general because some of these channels, I'd say, like, I don't know, at least half of them probably on average are g- are ha- are - have a lot of cross-ta- sorry, some of the segments have a lot of cross-talk. Um, it's good to get sort of short segments if you're gonna do recognition, especially forced alignment. So, uh, Don has been taking a first stab actually using Jane's first - the fir- the meeting that Jane transcribed which we did have some problems with, and Thilo, uh, I think told me why this was, but that people were switching microphones around in the very beginning, so - the SRI re-
mn014: No, th- Yeah. No. They - they were not switching them but what they were - they were adjusting them, so.
fe016: and they - They were not -
me001: Mmm.
me011: Adjusting. Oh.
fe016: @@ Yeah.
mn014: And aft- after a minute or so it's - it's way better. So -
fe016: So we have to sort of normalize the front-end and so forth, and have these small segments. So
mn014: Yep.
fe016: we've taken that and chopped it into pieces based always on your - your, um, cuts that you made on the mixed signal. And so that every - every speaker has the same cuts. And if they have speech in it we run it through. And if they don't have speech in it we don't run it through. And we base that knowledge on the transcription.
me011: On - Just on the marks. Right?
fe016: Um, the problem is if we have no time marks, then for forced alignment we actually don't know where - you know, in the signal the transcriber heard that word. And so -
me011: Oh, I see, it's for the length. I see.
fe016: I mean, if - if it's a whole conversation and we get a long, uh, you know, par- paragraph of - of talk, uh, I don't know how they do this. Um, we actually don't know which piece goes
me011: I understand.
fe016: where. And, um, I think with -
me018: Well you would need to - like a forced alignment before you did the chopping, right?
fe016: No, we used the fact that - So when Jane transcribes them the way she has transcribers doing this, whether it's with the pre-segmentation or not,
me011: It's already chunked.
fe016: they have a chunk and then they transcribes the words in the chunk. And maybe they choose the chunk or now they use a pre-segmentation and then correct it if necessary. But there's first a chunk and then a transcription. Then a chunk, then a transcription. That's great,
fe008: Mm-hmm.
fe016: cuz the recognizer can -
me011: Uh, it's all pretty good sized for the recognizer also.
fe016: Right, and it - it helps that it's made based on
fe008: Good. Oh good.
fe016: sort of heuristics and human ear I think . Th- but there's going to be a real problem, uh, even if we chop up based on speech silence these, uh, the transcripts from IB M, we don't actually know where the words were, which segment they belonged to. So that's sort of what I'm worried about
me011: Right.
me018: Why not do a - a - a forced alignment?
fe016: right now.
me011: That's what she's saying, is that you can't.
fe016: If you do a forced alignment on something really - well even if you do it on something really long you need to know -
me011: Got uh six- sixty minutes of -
fe016: you can always chop it up but you need to have a reference of which words went with which, uh, chop. So -
fe008: Now wasn't - I thought that one of the proposals was that IBM was going to do an initial forced alignment, after they -
me011: Yeah, but -
me013: I - I think that they are, um,
me011: We'll have to talk to Brian.
me013: yeah, I'm sure they will and so we - we have to have a dialogue with them about it. I mean, it sounds like
fe016: Yeah. Maybe they have some - you know, maybe actually there is some, even if they're not fine grained, maybe the transcribers -
fe008: OK.
me013: Liz has some concerns and -
fe016: uh, I don't know, maybe it's saved out in pieces or - or something. That would help. But,
fe008: Yeah.
fe016: uh, it's just an unknown right now.
fe008: Yeah. I - I need to - to write to him. I just - you know, it's like I got over-taxed with the timing.
fe016: So. Right. But the - it is true that the segments - I haven't tried the segments that Thilo gave you but the segments that in your first meeting are great. I mean, that's - that's a good length.
fe008: Mm-hmm. A good size. Good. Well, I - I was thinking it would be fun to - to - uh, uh, if - if you - wouldn't mind, to give us a pre-segmentation. Uh, maybe you have one already of that first m- of the meeting that
fe016: Right, cuz - y- yeah.
mn014: Yeah.
fe008: uh, the first transcribed meeting, the one that I transcribed. Do you have a - could you generate a pre-segmentation?
mn014: Um, I'm sure I have some but - but that's the one where we're, um, trai- training on, so that's a little bit -
me011: February sixteenth I think. Oh.
fe008: Oh, I see. Oh, darn. Of course, of course, of course. Yeah, OK.
mn014: It's a little bit at odd to - Yeah.
fe016: And actually as you get transcripts just, um, for new meetings,
fe008: Uh-huh.
fe016: um, we can try - I mean, the - the more data we have to try the - the alignments on, um, the better. So it'd be good for - just to know as transcriptions are coming through the pipeline from the transcribers, just to sort of - we're playing around with sort of uh, parameters f- on the recognizer, cuz that would be helpful.
fe008: Mm-hmm. Excellent, good.
fe016: Especially as you get, en- more voices. The first meeting had I think just four people, yeah.
mn014: Four speakers, yeah.
fe008: Mm-hmm. Yeah, Liz and I spoke d- w- at some length on Tuesday and - and I - and I was planning to do just a - a preliminary look over of the two that are finished and then give them to you.
fe016: Oh, great, great.
fe008: Yeah.
fe016: So.
me013: That's great. I guess the other thing, I - I can't remember if we discussed this in the meeting but, uh, I know you and I talked about this a little bit, there was an issue of, uh, suppose we get in the, uh, I guess it's enviable position although maybe it's just saying where the weak link is in the chain, uh, where we - we, uh - uh, we have all the data transcribed and we have these transcribers and we were - we're - the - we're still a bit slow on feeding - at that point we've caught up and the - the - the, uh, the weak link is - is recording meetings. OK, um, two questions come, is you know what - how - how do we - uh, it's not really a problem at the moment cuz we haven't reached that point but how do we step out the recorded meetings? And the other one is, um, uh, is there some good use that we can make of the transcribers to do other things? So, um, I - I can't remember how much we talked about this in this meeting but there was -
me011: We had spoken with them about it.
fe008: And there is one use that - that also we discussed which was when, uh, Dave finishes the - and maybe it's already finished - the - the modification to multi-trans which will allow fine grained encoding of overlaps. Uh, then it would be very - these people would be very good to shift over to finer grain encoding of overlaps. It's just a matter of, you know, providing - So if right now you have two overlapping segments in the same time bin, well with - with the improvement in the database - in - in the, uh, sorry, in the interface, it'd be possible to, um, you know, just do a click and drag thing, and get the - uh, the specific place of each of those, the time tag associated with the beginning and end of - of each segment.
me013: Right, so I think we talking about three level - three things. One - one was
fe016: Mm-hmm.
fe008: Yeah.
me013: uh, we had s- had some discussion in the past about some very high level
fe008: The types of overlaps -
me013: labelings, types of overlaps, and so forth that - that someone could do.
fe008: Mm-hmm.
me013: Second was, uh, somewhat lower level just doing these more precise timings. And the third one is - is, uh, just a completely wild hair brained idea that I have which is that, um, if, uh - if we have time and people are able to do it, to take some subset of the data and do some very fine grained analysis of the speech. For instance, uh, marking in some overlapping - potentially overlapping fashion, uh, the value of, uh, ar- articulatory features.
fe008: Yeah.
me013: You know, just sort of say, OK, it's voiced from here to here, there's - it's nasal from here to here, and so forth. Um, as opposed to doing
me011: Hmm!
me013: phonetic - uh, you know, phonemic and the phonetic analysis, and, uh, assuming, uh, articulatory feature values for those - those things. Um, obviously that's extremely time-consuming. Uh -
me018: That would be really valuable I think.
me013: but, uh, we could do it on some small subset.
fe008: Also if you're dealing with consonants that would be easier than vowels, wouldn't it? I mean, I would think that - that, uh, being able to code that there's a - a fricative extending from here to here would be a lot easier than classifying precisely which vowel that was.
me011: Which one.
fe016: Mmm.
fe008: I think vowels - vowels are I think harder.
me013: Mm-hmm.
mn014: Yeah .
me013: Well, yeah, but I think also it's just the issue that - that when you look at the - u- w- u- u- when you look at Switchboard for instance
fe008: Mm-hmm.
me013: very close up there are places where whether it's a consonant or a vowel you still have trouble calling it a particular phone
fe008: Mm-hmm, OK. Yeah, I'm sure. Uh, yeah, I - I know.
me011: Yeah, but - but just saying what the -
me013: at that point because it's - you know, there's this movement from here to here and - and - and it's -
fe016: Right.
me018: You're saying r- sort of remove the high level constraints and go bottom-up.
me013: so I-
me011: Yep, just features.
me013: Yeah, describe - describe it. Now I'm suggesting articulatory features. Maybe there's - there's even a better way to do it but it - but -
me018: Then just say -
fe016: Mmm.
me013: but that's, you know, sort of a traditional way of describing these things,
me018: Mm-hmm.
me013: um, and - uh, I mean, actually this might be a g- neat thing to talk to -
fe008: That's nice.
me018: Acoustic features versus psychological categories. Yeah.
me013: Sort of. I mean, it's still -
fe008: Yeah.
me013: some sort of categories but - but something that allows for overlapping change of these things and then this would give some more ground work for people who were building statistical models that allowed for overlapping changes, different timing changes as opposed to just "click, you're now in this state, which corresponds to this speech sound" and so on.
me018: Mm-hmm. Mm-hmm.
fe016: So this is like gestural - uh, these g- Right.
me013: Yeah, something like that. I mean, actually if we get into that it might be good to, uh, uh, haul
fe016: OK.
me013: John Ohala into this and ask his - his views on it I think.
me011: Yeah.
fe016: Right. But is - is the goal there to have this on meeting data, like
fe008: Excellent.
fe016: so that you can do far field studies of those gestures or - um, or is it because you think there's a different kind of actual production in meetings that people use? Or - ?
me013: No, I think - I think it's - for - for - for that purpose I'm just viewing meetings as being a - a neat way to get people talking naturally. And then you have i- and then - and then it's natural in all senses, in the sense that you have microphones that are at a distance that
me018: Just a source of data?
fe016: I see.
me013: you know, one might have, and you have the close mikes, and you have people talking naturally. And the overlap is just indicative of the fact that people are talking naturally, right? So -
fe016: Uh-huh.
mn005: Yeah.
fe016: Right.
mn005: Yeah.
me013: so I think that given that it's that kind of corpus, if it's gonna be a very useful corpus um, if you say w- OK, we've limited the use by some of our, uh, uh, censored choices, we don't have the video, we don't - and so forth, but there's a lot of use that we could make of it by expanding the annotation choices.
fe016: Mm-hmm.
me013: And, uh, most of the things we've talked about have been fairly high level, and being kind of a bottom-up person I thought maybe we'd, do some of the others. Yeah.
me011: Hmm.
fe008: It's a nice balance. That would be really nice to offer those things with that wide range. Really nice.
fe016: Right. Yeah, that would be good. Right.
me013: Yeah and hopefully someone would make use of it. I mean, people didn't -
fe008: Yeah.
me013: uh, I mean, people have made a lot of use of - of TIMIT and, uh w- due to its markings, and then the Switchboard transcription thing, well I think has been very useful for a lot of people. So -
me011: Right.
fe016: That's true. I guess I wanted to, um,
fe008: Cool.
fe016: sort of make a pitch for trying to collect more meetings. Um,
me013: Yeah.
fe016: I- actually I talked to Chuck Fillmore and I think they've what, vehemently said no before but this time he wasn't vehement and he said
me013: Yeah.
fe016: you know, "well, Liz, come to the meeting tomorrow and try to convince people". So I'm gonna try. Go to their meeting tomorrow and see
fe008: Mm-hmm.
fe016: if we can try, uh, to convince them because they have -
fe008: Good.
me013: Cuz they have something like three or four different meetings, right?
fe016: And they have very interesting meetings from the point of view of
fe008: Mm-hmm.
fe016: a very different type of - of talk than we have here and definitely than the front end meeting, probably.
mn005: Talk -
fe016: Um -
me018: You mean in terms of the topic - topics?
fe016: Well, yes and in terms of the - the fact that they're describing abstract things and, uh, just dialogue-wise, right.
me013: Mm-hmm.
me018: Mm-hmm.
fe016: Um, so I'll try. And then the other thing is, I don't know if this is at all useful, but I asked Lila if I can maybe go around and talk to the different departments in this building
me013: Yes.
fe016: to see if there's any groups that, for a free lunch, if we can still offer that, might be willing -
me011: You mean non-ICSI?
me013: Great.
fe016: non-ICSI, non-academic, you know, like government people, I don't know. So.
me011: Yeah, I guess you - you can try but - The problem is so much of their stuff is confidential. It would be very hard for them.
fe008: Yeah.
mn005: Yeah.
fe008: Also it does seem like it takes us way out of the demographic. I mean, it seems like we - we had this idea before of having like linguistics students brought down for free lunches and that's a nice idea.
mn005: Yeah.
fe016: Is - is it in these departments?
me011: Well, tha- I think that's her point.
fe016: Right, and then we could also - we might try advertising again because I think it'd be good if - if we can get a few different
fe008: Yeah.
fe016: sort of non-internal types of meetings and just also more data.
me013: Yeah.
me011: And I think, uh, if we could get -
fe008: Mm-hmm.
me018: Does - does John Ohala have weekly phonetics lab meetings?
fe016: So. So I actually wrote to him and he answered, "great, that sounds really interesting". But I never heard back because we didn't actually advertise openly. We a- I mean w- I told - I d- asked him privately. Um, and it is a little bit of a trek for campus folks.
me011: Yeah.
fe008: Mm-hmm.
me011: You might give them a free lunch. But, um,
fe016: Um, so it's still worthwhile.
me011: it would be nice if we got someone other than me who knew how to set it up and could do the recording so u- I didn't have to
fe016: So - Exactly, and - and -
me011: do it each time.
fe008: Yeah. That's right.
fe016: and I was thinking -
me013: He- he's supposed - he's supposed to be trained to do it.
fe016: Yeah. Plus we could also get
me011: OK, next week you're going to do it all.
mn005: Yeah.
fe016: you know, a s- a student. And I'm willing to try to learn. I mean, I'm - I would do my best. Um, the other thing is that -
me011: It's not that hard.
fe016: there was a number of things at the transcription side that, um, transcribers can do, like dialogue act tagging, disfluency tagging, um, things that are in the speech that are actually something we're y- working on for language modeling. And Mari's also interested in it, Andreas as well. So if you wanna process a utterance and the first thing they say is, "well", and that "well" is coded as some kind of interrupt u- tag. Uh, and things like that, um,
fe008: Of course some of that can be li- done lexically. And I also - they are doing disfluency tagging
fe016: th- A lot of it can be done -
fe008: to some degree already. Yeah.
fe016: Great. So a - a lot of this kind of - I think there's a second pass and I don't really know what would exist in it. But there's definitely a second pass worth
fe008: Mm-hmm.
fe016: doing to maybe encode some kinds of, you know, is it a question or not, or - um, that maybe these transcribers could do. So -
fe008: They'd be really good. They're - they're very - they're very consistent. Uh, I wanted to - whi- while we're - Uh, so, to return just briefly to this question of more meeting data, um -
fe016: Yeah.
me013: Mm-hmm.
fe016: That'd be great.
fe008: I have two questions. One of them is, um, Jerry Feldman's group, they - they, uh, are they - I know that they recorded one meeting. Are they willing?
me013: I think they're open to it. I think, you know, all these things are - I think there's -
fe016: Oh, yeah.
me013: we should go beyond, uh, ICSI but, I mean, there's a lot of stuff happening at ICSI that we're not getting now that we could.
fe008: Mm-hmm.
me013: So it's just - Yeah. So the -
fe016: Oh, that we could. OK. I thought that all these people had sort of said "no" twice already. If that's not the case then -
me013: No, no. No. So th- there was the thing in Fillmore's group but even there he hadn't - What he'd said " no " to was for the main meeting. But they have several smaller meetings a week,
me011: So.
me013: and, uh, the notion was raised before that that could happen. And it just, you know - it just didn't come together but -
fe016: Just - OK.
me018: Well, and - and the other thing too is when they originally said "no" they didn't know about this post-editing capability thing.
fe008: Oh.
fe016: Right.
me013: Yeah. Yeah.
fe016: Right. That was a big
fe008: That's important.
me018: So.
fe016: fear.
me013: Yeah, so I mean there's possibilities there. I think Jerry's group, yes. Uh, there's - there's, uh, the networks group, uh, I don't - Do they still meeting regularly or - ?
fe016: OK.
me011: Well, I don't know if they meet regularly or not but they are no longer recording.
me013: But I mean, ha- ha- have they said they don't want to anymore or - ?
me011: Um, ugh, what was his name?
me013: Uh, i- i-
fe008: Joe Sokol?
me011: Yeah.
me013: Yeah.
me011: When - with him gone, it sorta trickled off. They - and they stopped -
me013: OK, so they're down to three or four people but the thing is three or four people is OK.
me011: Yeah.
fe016: Mm-hmm.
me011: Yep.
fe008: We might be able to get the administration -
me011: Well he was sort of my contact, so I just need to find out who's running it now. So.
me013: OK.
fe008: I see that Lila has a luncheon meeting in here periodically. I don't know -
fe016: Yeah, I mean, it - One thing that would be nice and this - it sounds bizarre but, I'd really like to look at - to get some meetings where there's a little bit of heated discussion, like ar- arguments and - or emotion, and things like that. And so I was thinking if there's any like Berkeley political groups or something. I mean, that'd be perfect. Some group, "yes, we must -"
me011: Who's willing to get recorded and distributed?
fe016: Well, you know, something - Um -
me001: Yeah, I don't think the more political argumentative ones would be willing to -
mn014: Yeah.
me013: Yeah, with - with - with potential use from the defense department. Yeah.
mn005: Yeah.
fe016: Well, OK. No, but maybe stu- student, uh, groups or, um, film-makers, or som- Something a little bit
me011: Yeah.
me001: Yeah. Exactly.
fe008: Yeah.
mn014: Yeah.
mn005: Yeah.
fe008: Yeah, of course there is this problem though, that if we give them the chance to excise later we e- might end up with like five minutes out of a f-
me013: Yeah.
mn005: Film-maker.
fe016: colorful.
me011: Of beeps, yeah.
fe008: of m- one hour of -
mn014: Yeah. Yeah.
mn005: Is -
fe008: Yes. Really.
fe016: And I don't mean that they're angry but just something with some more variation in prosodic contours and so forth would be neat. So if anyone has ideas, I'm willing to do the leg work to go try to talk to people but I don't really know which groups are worth
fe008: Well there was this KPF A idea, but -
fe016: pursuing.
me011: No that's -
me013: Yeah, th- there's a problem there in terms of, uh, the
fe008: OK.
me011: Legal.
me013: um commercial value of - of st- uh, it - it - it - it turned out to be a bit of a problem.
fe008: OK, OK. And I had one other - one other aspect of this which is, um, uh, uh, Jonathan Fiscus expressed
fe016: Or -
fe008: primar- uh y- a major interest in having meetings which were all English speakers. Now he wasn't trying to shape us in terms of what we gather but
me013: Mm-hmm.
fe008: that's what he wanted me to show him. So I'm giving him our, um - our initial meeting because he asked for all English. And I think we don't have a lot of all English meetings right now.
me018: Did he mean, uh - did he mean and non-British?
me013: Of all - all nat- all native speakers.
me011: Well -
mn014: The all native.
fe008: That's what I mean, yeah.
me011: Well if he meant and non- British I think we have zero.
fe008: He doesn't care. No. Eh, well, British is OK. But - but -
me018: He said British was OK?
fe008: Sure, sure, sure. Yeah.
me011: British is English?
me013: Why?
fe008: Different varieties of English.
mn014: Ooo, ooo.
me013: Well, I don't - I don't - I don't think - if he didn't say that -
fe008: Native speaking. Native speaking English.
me011: I bet he meant native speaking American.
fe008: Yes.
me013: I bet he did.
mn014: American English?
fe008: Oh, really.
me011: So, why would he care?
me018: Knowing the application -
me013: I remember wh- I- I remember a study -
fe016: That's -
mn005: English,
fe016: I was thinking, knowing the, uh, n- National Institute of Standards, it is all -
me013: I remember a study that BBN did where they trained on - this was in Wall Street Journal days or something, they trained on American English and then they tested on, uh, different native speakers from different areas. And, uh, uh, the worst match was people whose native tongue was Mandarin Chinese. The second worst was British English.
fe008: That's funny.
me013: So h- it's, you know, t-
fe008: Alright. And so that would make sense. I didn't have the context of that.
me013: the - the - the - German was much better, it was Swiss w- Yeah, so it's - so I think, you know, if he's - if he's thinking in terms of recognition kind of technology I - I - I think he would probably want, uh
mn014: Ooo, ooo.
me013: American English, yeah. It - it - yeah, unless we're gonna train with a whole bunch of -
me011: I wonder if we have any.
fe008: All America, OK. I think that the - Feldman's meetings tend to be more that way, aren't they? I mean, I sort of feel like they have -
me011: Maybe. Maybe.
me013: I think so, yeah.
fe016: Yeah, mm-hmm.
me013: Yeah.
mn005: Mmm.
me011: And maybe there are a few of - with us where it was - you know, Dan wasn't there and before Jose started coming, and -
me013: Yeah. Yeah.
mn005: Yeah.
me013: It's pretty tough, uh, this group. Yeah. So, uh, what about - what about people who involved in some artistic endeavor? I mean, film-making or something like that. You'd think like they would be -
me001: God.
me011: Yeah.
mn014: Mmm.
mn005: Yeah. A film-maker.
fe016: Exactly, that's what I was - something where there - there is actually discussion where there's no right or wrong answer but - but it's a matter of opinion kind of thing.
fe008: It's be fun.
fe016: Uh, anyway, if you - if you have ideas -
me011: RASTA. PLP. RASTA. PLP.
me001: We can just discu- we can just have a political discussion one day.
mn005: Yes.
me018: A- any department that calls itself science ri-
fe016: Yeah, we could -
mn005: Department. Yeah.
me001: Uh, I could make that pretty -
me011: Well, like computer science. That -
mn005: Computer sci-
fe008: We could get Julia Child. I know.
me011: That's -
fe016: I'm - I'm actually serious because, uh, you know, we have the set up here and - and that - that has
me011: Got a ticket.
me013: Yeah, I know you are.
fe016: a chance to give us some very interesting fun data. So if anyone has ideas,
mn005: Yeah.
me013: Yeah.
fe016: if you know any groups that are m- you know,
me011: Well I had asked some - some of the students at the business school. I could -
mn005: Yeah.
me001: I know -
fe016: student groups c- like clubs, things like that. Not - not -
me013: Put a little ad up saying, "come here and argue".
fe016: Yeah. "If you're really angry at someone use our conference room."
me011: The Business school. Uh, the business school might be good. I actually spoke with some students up there and they - they - they expressed willingness back when they thought they would be doing more stuff with speech.
fe016: Oh, OK. Really.
me011: But when they lost interest in speech they also stopped answering my email about other stuff, so.
mn005: Hmm.
me001: I -
fe016: Or people who are really h-
me013: They could have a discussion about te-
me011: We should probably bleep that out.
me013: about - about tax cuts or something.
me001: I heard that at Cal Tech they have a special room - someone said that they had a special room to get all your frustrations out that you can go to and like throw things and break things. So we can like post a -
me013: Yeah, now that is not actually what we -
me011: Th- that's not what we want.
me001: No, not to that extent but, um.
fe016: Well, far field mikes can pick up where they threw stuff on the wall.
me001: Yeah.
me013: Yeah, but we don't want them to throw the far field mikes is the thing.
me011: That's right.
me001: Yeah.
fe016: Oh. Yeah, right.
mn005: The fa-
me011: " Please throw everything in that direction."
mn005: b- b-
me013: Yeah. Anyway.
me011: Padded cell.
fe008: It'd be fun to get like a - a p- visit from the -
me011: There was a dorm room at Tech that, uh, someone had coated the walls and the ceiling, and, uh, the floor with mattresses.
me001: Mmm.
me011: The entire room.
me013: I had as my fourth thing here processing of wave forms. What did we mean by that? Remember @@ ?
fe008: Yeah.
me011: Uh, Liz wanted to talk about
fe008: Pre-processing.
me011: methods of improving accuracy by doing pre-processing.
fe016: Well I think that - that was just sort of - I- I already asked Thilo but
me013: Oh, you already did that.
fe016: that, um, it would be helpful if I can stay in the loop somehow with, um, people who are doing any kind of post-processing, whether it's to separate speakers or to improve the signal-to-noise ratio, or both, um, that we can sort of try out as we're running recognition. Um, so, i- is that - Who else is work- I guess Dan Ellis and you
mn014: Dan, yeah.
me011: Yep.
me013: Yeah, and Dave uh Gel- Gelbart again, he's - he's interested in - in fact we're look- starting to look at some echo cancellation kind of things.
fe016: and Dave.
mn014: Yep.
mn005: Yeah.
fe016: OK. OK. Right .
me013: Which uh -
me011: I am not sure how much that's an issue with the close talking mikes, but who knows?
me013: Hmm? Well, let's - w- i- isn't that what - what you want - t-
fe016: I don't know. I'm bad - It's like - like -
me013: No, so - No, i- w- wha- what you - what you want - when you're saying improving the wave form you want the close talking microphone to be better. Right?
me011: Right.
me013: And the question is to w- to what extent is it getting hurt by, uh - by any room acoustics or is it just - uh, given that it's close it's not a problem? Uh -
fe016: It doesn't seem like big room acoustics problems to my ear but I'm not an expert. It seems like a problem with cross-talk.
me013: OK, so it's -
me011: e- I bet with the lapel mike there's plenty, uh, room acoustic but I-
mn014: Yeah .
fe016: That - that may be true. But I don't know how good it can get either by those - the - those methods - That's true.
me011: I think the rest is cross-talk. Yeah.
me013: OK.
me011: So I - I think it's just,
fe016: Oh, I don't know.
me011: yeah, what you said, cross-talk.
fe016: All I meant is just that as sort of - as this pipeline of research is going on we're also experimenting with different ASR, uh, techniques. And so it'd be w- good to know about it.
me011: Mm-hmm.
me018: So the problem is like, uh, on the microphone of somebody who's not talking they're picking up signals from other people and that's
fe016: R- right, although if they're not talking, using the -
me018: causing problems?
fe016: the inhouse transcriptions, were sort of O K because the t- no one transcribed any words there and we throw it out.
me018: Mm-hmm.
fe016: But if they're talking at all and they're not talking the whole time, so you get some speech and then a "mm-hmm", and some more speech, so that whole thing is one chunk. And the person in the middle who said only a little bit is picking up the speech around it, that's where it's a big problem.
fe008: You know, this does like seem like it would relate to some of what Jose's been working on as well, the encoding of the - And - and he also, he was -
mn005: Yeah.
fe016: The energy, right. Exactly.
mn005: Yeah, energy.
fe008: I was t- I was trying to remember, you have this interface where you - i- you ha- you showed us one time on your laptop that you - you had different visual displays as speech and nonspeech events.
mn005: Yeah, c- Yeah. May - I - I only display the different colors for the different situation. But, eh, for me and for my problems, is uh - is enough. Because, eh, it's possible, eh, eh, in a simp- sample view, uh, to, nnn, to compare with c- with the segment, the - the kind of assessment what happened with the - the different parameters. And only with a different bands of color for the, uh, few situation, eh, I consider for acoustic event is enough to @@ . I -
fe008: Mm-hmm.
mn005: I - I see that, eh, you are considering now, eh, a very sophisticated, eh, ehm, eh, @@ set of, eh, graphic s- eh, eh, ehm, si- symbols to - to transcribe. No?
fe008: Oh, I w- Uh-huh.
mn005: Because, uh, before, you - you are talking about the - the possibility to include in the Transcriber program eh, um, a set of symbols, of graphic symbol to - t- to mark the different situations during the transcription - during the transcription . No?
fe008: Well, you're saying - So, uh, symbols for differences between laugh, and sigh, and - and - and slam the door and stuff? Or some other kind of thing?
mn005: Yeah. Yeah, yeah. The s- the symbols, you - you talk of before. No? To - to mark -
fe008: Well, I wouldn't say symbols so much. The - the main change that I - that I see in the interface is - is just that we'll be able to more finely c- uh,
mn005: Yeah.
fe008: time things. But I - I also st- there was another aspect of your work that I was thinking about when I was talking to you which is that it sounded
mn005: Yeah.
fe016: Hmm.
fe008: to me, Liz, as though you - and, uh, maybe I didn't q- understand this, but it sounded to me as though part of the analysis that you're doing involves taking segments which are of a particular type and putting them together. And th- so if you have like a p- a s- you know, speech from one speaker, then you cut out the part that's not that speaker, and you
mn005: Yeah.
fe016: Mm-hmm.
fe008: combine segments from that same speaker to - and run them through the recognizer. Is that right?
fe016: Well we try to find as close of start and end time of - as we can to the speech from an individual speaker,
fe008: Mm-hmm.
fe016: because then we - we're more guaranteed that the recognizer will - for the forced alignment which is just to give us the time boundaries, because from those time boundaries then the plan is to compute prosodic features.
fe008: Mm-hmm.
fe016: And the sort of more space you have that isn't the thing you're trying to align the more errors we have.
fe008: Mm-hmm.
fe016: Um, so, you know, that - that - it would help to have
fe008: Cuz i- OK.
fe016: either pre-processing of a signal that creates very good signal-to-noise ratio, which I don't know how possible this is for the lapel, um, or to have very - to have closer, um, time - you know, synch times, basically, around the speech that gets transcribed in it, or both. And it's just sort of a open world right now of exploring that. So I just wanted to see, you know, on the transcribing end from here things look good. Uh, the IBM one is more - it's an open question right now. And then the issue of like global processing of some signal and then, you know, before we chop it up is - is yet another way we can improve things in that.
me018: What about increasing the flexibility of the alignment?
fe008: OK.
me018: Do you remember that thing that Michael Finka did? that experiment he did a while back?
fe016: Mm-hmm. Right. You can, um - Hhh. The problem is just that the acoustic - when the signal-to-noise ratio is too low, um, you - you'll get, a- uh - an alignment with the wrong duration pattern or it -
me018: Oh, so that's the problem, is the - the signal-to-noise ratio.
fe016: Yeah. It's not the fact that you have like - I mean, what he did is allow you to have, uh, words that were in another segment move over to the - at the edges of - of segmentations.
me018: Mm-hmm. Or even words inserted that weren't - weren't there.
fe016: Right, things - things near the boundaries where if you got your alignment wrong - cuz what they had done there is align and then chop.
me018: Mm-hmm. Mm-hmm.
fe016: Um, and this problem is a little bit j- more global. It's that there are problems even in- inside the alignments, uh, because of the fact that there's enough acoustic signal there t- for the recognizer to - to eat, as part of a word. And it tends to do that. S-
mn005: Yeah.
fe016: So, uh, but we probably will have to do something like that in addition. Anyway. So, yeah, bottom - bottom line is just I wanted to make sure I can be aware of whoever's working on these signal-processing techniques for,
mn005: Yeah.
fe016: uh, detecting energies, because that - that'll really help us.
me013: O K, uh tea has started out there I suggest we c- run through our digits and,
fe008: OK.
me013: Uh, So, OK, we're done.