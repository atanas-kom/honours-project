mn017: There're some words that weren't -
me011: OK. We're on.
mn017: See, there're some stretches that weren't even in one or the other, so -
fe016: Right. It would have to be hand - Right.
me001: Yeah.
mn017: What are you gonna do about those, though? You're never -
fe016: It would have to be -
fe008: Hello? OK.
fe016: Well, a h- a person would - would check it over and then give a final -
fe008: Should we close the door?
me011: Oh, we'll wait for Chuck. Close the door behind him.
me001: I mean, if recognition's better on the channelized segmentations, then -
fe016: I'm - Well, it's more
me013: We're - we're recording by the way, just for -
fe016: you didn't - Oh, sorry.
me013: I mean, uh u-
me011: Y- you can keep talking, but you should be aware.
me013: You can keep talking. I just - I just - g- guess you were gonna -
fe016: You were saying that we were waiting for Chuck, so I just - OK.
me013: Well -
me011: Well, and then, uh - then Morgan said "why don't we start?" and I said "O K ".
me013: So the compromise is we're - we're starting but we're leaving the door open. So we'll have a little more background noise and - Uh.
fe016: OK.
me011: Or we can close the door and make Chuck knock when he comes.
fe008: Well, I tend to - th- there're a couple meetings where there are a lot of preambles like this, in which case the transcription doesn't start until someone actually says "OK." So, we're starting right now.
me013: Really?
fe016: Well, that's good.
me013: Yeah. Oh, yeah. The meeting's started. This is - this is the real thing.
fe008: This is the -
me013: This is the real thing. Oh well, never mind, it wasn't. There goes Chuck. Just kidding, it was. OK, so.
me011: And Chuck gets stuck with the ear-plug mike. @@
me013: OK. Last guy in gets the -
fe008: Yeah. u- Didn't get the door.
me013: Oh, you just get the door now. Yeah.
me011: But he didn't shut the door. I got it since -
me013: Yeah. So I - I - @@ Adam sent around this thing about what we were going to talk about and - and th- we had had this discussion of, uh, flipping back and forth between an emphasis on - on the technology, particularly recognition, versus, uh, the recordings and transcriptions and so on. Um, but, um, I was asking, if we could, to uh, kind of make it just whatever is happening rather than one or the other because, uh, next weekend - next week I'll be at a meeting on campus and after that I'll be Europe for,
mn017: Sure.
me013: uh, several meetings' worth. Uh, you folks'll be gone for a couple of the meetings' worth in - in Europe also, right?
mn017: Mm-hmm.
fe016: I overlap exactly with the times you're gone. I mean -
me013: Really? OK. Yeah.
fe016: Yeah.
me013: So. So, uh, you didn't - you didn't get an agenda, I guess. We've got the usual -
me011: Well, because no one - no one ever rep- responded with any items. So I have a couple of minor ones. Uh,
me013: Yeah.
me011: our normal transcription status, just so that we can make some - some plans. So wha- what's up with IBM, Chuck? Do you know?
me018: Um, I think Brian is on vacation now but, uh, before he left we gave him, uh, another set of meetings to give to the transcribers. And -
me001: How many?
me018: Uh, what is it? Four?
me011: Is - is yours working there, Chuck?
mn014: Four.
me001: Oh.
me018: Four.
me011: Can you - ? You're b- you're B?
me018: Test. What am I?
fe008: Is it turned on?
me011: There's no on.
me018: Test.
fe008: OK.
me018: Yeah.
me011: Oh. It's just - I'll - Let me raise the gain on that a little bit
fe008: Channel B.
me018: OK.
fe008: Channel B.
me011: since it's so far from your mouth. Sorry.
me013: OK. So we sent them -
me018: So we gave them four meetings before he left and, um, that's it. So, um, I don't think we'll hear from him before he gets back.
me011: OK.
me013: And the-
fe008: Do they know about your pie chart?
me018: I don't know.
fe008: OK.
me018: I don't know.
me013: What pie chart?
me011: Pie? Oh.
fe008: He has a nice pie chart on the, uh, s- the current status page,
fe016: Pie.
fe008: which shows the amount of transc- amount of data that had been transcribed and the amount - out of the entire - and
mn017: Mm-hmm.
fe008: at this point it's not quite half. Wouldn't - Is that what you'd say, with the pie chart?
me018: Yeah.
fe008: And then of that, there's, uh, a little sliver - I could try and draw it but it's probably better to describe. So -
me013: Half the data that's been recorded has been transcribed?
fe008: Roughly. Almost. Not quite. And I haven't actually caught up with, uh - since I got back so recently from my vacation.
me013: Wow! That's getting pretty good.
fe008: Um, I know that the transcribers finished, um, uh, several meetings while I was gone.
me018: Oh.
fe008: And I haven't told you cuz I haven't - I haven't figured out which ones they are y- are yet. But when that happens, then that pie will get even closer to the midline. It's not quite -
me018: Right.
me013: Mm-hmm.
me018: Mm-hmm.
fe008: not quite fifty percent but really getting close.
me013: Hmm.
me011: OK. So also, um -
fe008: I think it will be.
mn017: You mean, pi will be close to one half? That's new.
fe008: Well, not mathematically. n-
me011: Now, that's a strange -
me013: Well, if we can have three point one four times as much tr- transcribed as we recorded, we really would be doing well.
me011: Yep.
mn017: Right.
me011: Um. So -
fe008: But it's a nice - it's - I recommend his - his - his graphic, cuz it's - it's a really nice graphic.
mn017: You know, this - this raises some -
me011: How much -
mn017: Mm-hmm. How do you transcribe that?
me011: How much do we need transcribed before it's worth doing some trainings?
mn017: Oh. B- uh -
fe016: Mmm.
me011: I mean, it seems like probably we have enough now. Right? Because, like - like Macrophone wasn't that much data. Right? And it helped.
mn017: We can -
fe016: You mean -
mn017: Well, we already use it for digit training.
fe016: But - but that was read speech.
me011: You only used that for digits? Right.
mn017: I mean - Well, we did do some training on digits - uh, rather adaptation on digits - digits. I mean, supervised adaptation. So.
me011: That's right. Mm-hmm.
mn017: Yeah. I mean, uh -
fe016: Maybe like twenty hours. We could try, but - Maybe not counting the non-native speech, cuz if - That - that just doesn't translate very well.
mn017: Well, I would - I would love to do some, um - you know, with adaptation you can use fairly small amount of data to improve your performance. Um,
me011: Right.
mn017: and n- you know, it's just basically, uh - uh You know, I - I don't have to time to - to do too much these days except what I'm already doing. So -
me011: Mm-hmm.
mn017: um, but if there's some - someone has some free time, I'm - I'll be happy to show them how it works and you can play with it.
me011: Cool. Um.
me013: Uh, I thought you - you were already using adaptation
mn017: No, supervised adaptation. So, we're doing s- unsupervised speaker adaptation.
me013: w- on the test set.
me011: Supervised.
me013: I see.
mn017: But you could build a test set which you sort of take your models and ada-
me013: Oh, OK. Got it.
mn017: do supervised adaptation. And then you start with the speaker adaptation from sort of channel-adapted or room-adapted or whatever.
me013: Right. Right. Yeah, yeah. Yeah, whatever this is.
me011: H- how would you imagine doing a test set on this corpus? A test set, training set division? I mean, it- it's really weird. Right? Because it's - it would be hard to get speaker disjoint sets.
mn017: Right.
me011: Do y- do we just give up on that?
fe016: Right. And actually the - I was thinking about this - the original application doesn't really appl- I mean, if you're using this over and over again, you're gonna be testing on the same - the same speakers.
me011: Well, but then you have the supervised versus unsupervised question.
fe016: I just mean that it's not a terrible thing to assume that you don't - that you don't have disjoint sets,
me011: Right.
me013: Mm-hmm.
me011: So.
fe016: for this particular kind of application.
me013: Right. Yeah.
fe016: I mean -
me011: Yeah.
me013: I mean, you could have some parts of it that are disjoint and some that aren't, and see what the difference is, you know,
mn017: It's - it's sort of like in, um, Broadcast News because you have those people who re-occur
fe016: Yeah.
me013: on the others. Yeah. Yeah.
mn017: over and over. I mean, the anchor speakers tend typically. So, um -
me011: Right.
mn017: m- m- m- m- Yeah. As long as you're aware that you're doing that, that's - I don't see that as a problem.
me013: You can separate it out and see how - if they're - Yeah.
me011: And then s- s- similarly with subject matter. That, you know, if you're training your language model on this meeting only and testing on this meeting only, you're gonna do a lot better than if you start crossing them.
mn017: Mm-hmm.
fe016: Somewhat. Although what's interesting is that the majority of the words in the language model are actually -
me013: Mm-hmm.
me011: Are the same.
fe016: Yeah. They're actually these, like, function words and "Yeah!" and s- stuff like that. And there there's a lot of speaker dependence there.
me011: Sure.
me013: Mm-hmm. Mm-hmm. Yeah.
fe016: Even the transcribers will say they know who the speaker is after a while just from their
me011: Just from word choice? Yeah.
fe016: backchannels and - Right. So y- So, I don't think you're talking the way you write, in - in other words.
me011: Most certainly. So it's just, uh, if we're gonna do that we should give some thought to how we wanna divide it up.
me013: Yeah. Yeah, so, you know, maybe someone else would do a lot of the work where probably your advice
mn017: Yeah.
me011: Yeah. And similarly with digits. We now have a lot of digits but most of them aren't transcribed.
me013: would be helpful.
me011: So if we wanted to do a forced alignment on them, we could start collecting ourselves up a fairly large digit corpus.
me013: Yeah. Well, we'd -
me011: And so, same issue. You know we just need to get
me013: We want that for sure. Yeah.
me011: someone who's interested in that to start looking at it. So who's working on digits currently?
me013: Uh, Dave Gelbart.
me011: OK, maybe I'll talk to him and see if he's interested.
me013: Not right away. He's got prelims and - Yeah. Yeah.
me011: Yeah, certainly. He wants to pass the prelims.
mn017: Hmm.
me013: Um, one thing, uh, uh, just a e- uh, uh, an announcement of sorts is that, um, Chuck is gonna be going to a meeting at NIST, in, uh, about a month and a half, I guess. They're still working out the date. cuz they want to gather together sort of one person from each site who is involved in the meeting stuff since they're going to be doing a bunch of meeting recordings there. And so, uh.
me011: Mm-hmm. Is, uh - ? Are the CMU folks gonna be there?
me013: Somebody - you know, it's like one person - at the moment it's one person from each site. So there'll be somebody from the CMU, and somebody from here, and somebody from, uh, a - a number of places. Probably somebody from UW. Um. So. Yeah, it's possible they'll open it up to more people. But - but I think, you know, the main thing is just to, uh - uh - uh - uh, it's not a - it's not a conference. It's not a workshop, really. It's just connecting with them.
me011: Right.
me013: So. Um. So, then if they start a bunch of recordings then ultimately they'll - they'll have training sets and test sets, and - and all that - all that stuff, and - But.
mn017: But it would be interesting to hear what they intend to do about the speaker overlap, for instance.
me011: Right.
me013: Yeah.
fe016: What's the plan if - were we still going to be like a center for transcribing data? What happens if th- they don't deliver things until next year or something when we have less resources or - ?
me013: I- Well, again the hope is that, uh - I mean, it's - it's looking - I mean, I have to ask these folks but, uh, my impression is that the, um, IBM
me011: Yep.
me013: path is looking, you know, more promising.
me011: It - it - pretty good. Yeah.
fe016: Hmm.
me013: And if that's the case and if it turns out that, uh, it's really a relatively small amount of time for our transcribers to process things before and after, if they really have taken out enough of the - of the, uh, uh, work that - that it's f- feasible, then maybe we can do it with a smaller staff next year.
fe016: Mm-hmm.
me013: I mean, next - next year, uh, in which he's - you're referring to is, uh, next year we - we don't have a whole lot of guaranteed funding for this - this work. Um, other funding may come. You know that's - But - but if we wanna just count on, uh, uh, what we know about, it's - it's more modest than this year. Uh, it's still - there'll still be money, but it's just more modest. So - um, so I would see us as probably not doing more recordings at least for - for - for meetings or - or digits or anything. But, uh, if - if we feel that we need to, probably still doing some recordings for SmartKom or something. Um, but otherwise just, you know, stop that and just take whatever comes from the other places, which,
mn014: Yeah.
me013: uh, I guess we have an u- unknown rate. If it - if it starts being - if they're generating this huge amount and we can't handle it then, you know, we'll tell them. But. Uh, although it would have been nice if that - their stuff had come earlier, it- it's in some ways a good thing, because we've been ironing out this path. So.
me011: Um. Well, I got a email from one of the UW guys. They want to record the meetings at higher, uh, sampling rate than sixteen kilohertz. Uh, I didn't ask why. But it seems to me that really doesn't matter. If they have the disk space to do it, it seems that that is not a big deal. I was just wondering if anyone had an opinion
me013: Well, it's just if that they're sending it to us, then we have to have the disk space to do it too.
me011: about mismatched rates.
fe008: Can't we downsample and, uh, transcribe on that basis?
me013: That would be the hope. Yeah. d- Are they doing some nice integer multiple or - ?
me011: Yep. Excuse me?
me013: Are they doing some nice integer multiple of th- of sixteen?
me011: No.
fe016: Are they - they're doing, like, twenty-two or s- ?
me011: No. No, no, it was like forty something. Forty-four, forty-two.
fe016: Could - Forty-eight? Forty - forty-four? Yeah. CD-ROM. Yeah.
me001: F- So, CD.
mn014: CD. Yeah.
me011: Yeah.
me013: Oh, forty-four point one.
fe016: Forty-four.
me001: Forty-four one.
mn014: Yeah.
fe016: S-
me011: Something like that.
me013: Yeah. Oh, so that's - Well, you know, we record here at for- at forty-eight or something and then we downsample.
me011: And then we downsample. Yep.
me001: But forty-eight's a nice multiple of eight.
fe016: But - but it - but forty-four and sixteen are not
me013: Yeah. Well you can do it.
me001: You can do it, I think.
fe016: easy? Yeah? It's not lossy?
me013: Oh, absolutely you can do it. Yeah. You can do - you can go from anything to anything else.
me001: You c- y-
me013: But - but it's - it's just - it's - it's just a little more complicated.
me011: You get aliasing.
fe016: As long as you're - Yeah. As long as you're not doing the processing on the downsampled - I mean -
me001: There's probably some -
me013: It's just like -
fe016: Just for transcribing it, you mean?
me013: Yeah. So - u- u- u- Yeah. I mean, it's just slightly more complicated, but it's - but i- you can - you can go from any frequency to anyth- any other frequency. So it's -
me011: Well, the - the only thought was if we're gonna do a combined corpus, does it really matter if some's sampled at one rate and some's sampled at the other? My feeling is no, it doesn't. Your audio, u- these days audio tools tend to take care of all of that. But I just wanted to double check with other people before I told them "yeah, no problem".
fe008: Also seems like the corpus could all be standardized on s- on this - the, uh - Yeah.
me011: That's what I was saying. So - so -
me018: Why are - why are they asking us?
me011: I don't know. Why are they asking us? Because, you know, we're sort of doing the corpus, so they want to be as similar as possible.
me013: A- and, so I gue-
mn017: It could be interesting.
me011: So. But I think the answer is, if - if we tell him "no, that's not alright", what he'll probably say is "well, we're gonna do it anyway". But, uh,
me018: Well that's - that's why I'm asking.
mn017: Well, it will be interesting to find out why they are choosing a higher sampling -
me001: Yeah.
me011: Uh. Yep.
me013: Well, I would suspect it's because it's what the hardware does.
me001: It's kind of a s-
fe016: For -
me011: Oh, and they just don't want to downsample?
fe016: Yeah.
me013: Yeah.
me001: Well, someone's gonna have to downsample.
mn017: But then they're just - they're just - there's just deferring the problem to later and they might save themselves a lot of disk space problems by doing it right away.
me001: Yeah.
fe016: They're taking up more disk space.
me001: Yeah. It -
mn014: Yeah.
me013: I - I- I think it's the sort of thing that's deserving of discussion
me011: OK.
me013: with them. I d- I don't think it's like, i- uh, they'll ask us, we'll give a simple answer and come back. It needs some back and forth because it's -
mn017: I mean that's wha-
fe016: Yeah.
me013: it- it's a little gnarly to have parts of the database with different things. And it's,
mn017: That's like three times - three times as much disk space.
me001: Yeah. It's four or five times.
mn014: Yeah.
me001: Depends what you save.
me013: um, i- You know, part of the arguments for the higher sampling rate is that maybe there's something, you know, say, in six to ten kilohertz that you might use for - for some purposes somewhere. If people are doing a wide range of things, doing location, uh, you know, doing a bunch of things, maybe, you know, why - why throw it away if you don't need to? Um, on the other hand, um, I mean, it's @@ - sixty kilohertz is plenty. So - so -
me011: Yep. That's wh- that's what I thought.
me001: Yeah.
me013: So, uh, I th- I - I think it's - it's, uh - And they are gonna be using up a lot of disk, both for th- them and for us when we're pr- processing their stuff, uh, if they
me011: Mm-hmm.
mn017: We should warn them that these disk space issues are gonna creep up on them very fast.
me011: Yep. Yep.
fe016: They'll have to start kicking people out of the meetings, like -
me013: Well, i- w- wa- if - if they're going at forty-four, they won't even creep. They'll just pounce.
me011: Yeah, but -
mn017: Right.
mn014: Yeah.
me001: Yeah.
fe016: As long as they have only, like, three people per meeting.
me018: How many channels?
fe016: I mean, they can just limit the number of people .
me011: Um, I don't remember what their hardware set-up was but it was smaller than ours.
me013: Well, that might help a bit.
me011: Yeah.
me013: Yeah, actually I think at NIST they were ta- there were - there was some discussion of fairly high sampling rates too, so.
me011: Well, with NIST I think they're - they're in a different situation cuz they're doing video. And so compared to the video, the audio is just noise in terms of disk space, literally.
me001: Hmm.
me013: I don't think that's true.
me011: Really?
me013: They're recording fifty channels of mikes.
me011: They're not recording all fifty of the array. They're - they're cooking it down, aren't they?
me013: Yeah, they are.
fe016: Yeah. They were g- they said they were gonna record @@ - I don't know if there were fifty, but there were definitely above, like, twenty.
me013: They're recording all of them.
me011: Whew.
me013: Yeah.
me011: That's funny. I thought that they were cooking down that data in some way before they were storing it.
fe016: It was - it was high.
me013: I don't believe so. No. I don't think so. No. So I think they - they have actually a very large audio data rate. I think it is comparable to a video data rate.
me001: OK.
me013: So.
me018: How in the world are they gonna ever distribute this?
me011: Yeah, distributing - They're not going to.
me013: Uh.
me018: You're gonna have to just get -
me013: Interesting question.
me018: Because our -
me011: You'll have to just work on little subsets of it. There's just no way you could get it all.
me018: We're - we're estimating that ours - if we collect say a hundred meetings and each meeting is just the audio, compressed audio's half a gig, so there's fifty gigs just for our corpus.
me011: Yep.
me018: For a hundred meetings. And, uh, you know -
me001: That's eight kilohertz?
me013: And that's - and that's - and that's no video.
me011: Sixteen.
mn014: Sixteen.
me018: That's sixteen.
fe016: Sixteen.
me001: Sixteen.
me018: And so,
me013: Sample rate, yeah.
fe016: You just get, like,
me001: Oh, it's shortened. Oh, OK.
me018: even - even a distribution of fifty gigs, you know, it's - if you use DVDs or something, that's -
fe016: one backchannel at a time or something.
mn014: Yeah. It's shortened.
me001: And then shortened.
mn014: Yeah.
me011: A lot.
me018: It's still, yeah, two or three DVDs but -
me013: Yeah, not if you have to distribute the video also.
me011: Two or three?
me018: If you use both sides and the two layer and all that.
me011: It's a lot more than that. Right? DVD is eight gig?
me013: Well, I think you'll have some interesting discussions next month when you go out there. I mean, how are they gonna - you know, what's - what's the distribution plan?
me018: S- seventeen. @@ Yeah. Yeah. Mm-hmm.
me013: If they have something really smart in mind, you know, maybe we can use it. I mean - I mean, w- we talked about sending around a disk or a computer.
me011: I think that's definitely the right way to do it. Someone sends us disk. We - we load it with data and send it back. It's gonna be easier than any other method.
mn017: Mmm - Huh.
me013: Maybe a compu- maybe -
me011: Well, if not - if you want to burn the CDs, you're welcome to it.
me018: I say we give it to LDC and let them do it.
me011: Well, yeah.
fe016: Hmm.
me011: Yeah, absolutely. If they have a way of doing it. I'm thinking prior to that.
fe016: And there's never any talk - ?
me001: What's LDC?
fe016: Was there ever any talk of taking the, um,
mn017: Linguistic Data Consortium.
me001: Mmm.
fe016: close-talking mikes when people aren't talking and deleting those portions? Or is the breathing and things - ?
me011: We already do that. Shorten does that automatically.
fe016: Yeah? OK.
me011: That's why you - why - that's why Shorten - that's why Shorten reduces the size so much.
fe016: And if they're still that big - I see. Yeah, that's true.
me013: That's why it's only fifty gigs.
me011: Right.
fe016: OK. So it's still really big even if you're - only one person or two people at most are actually talking all the time.
me011: Yep.
fe016: Wow.
mn017: We should just talk less.
me011: Well, if you talk less it does in fact use less me- d- m- data.
fe016: Have shorter meetings!
mn014: Yeah.
me013: Hey, it's - it's the first time I've ever heard you ask for less data.
me011: So, the channels -
mn014: Yeah.
me011: Hmm.
fe016: Sorry.
me011: It's actually one way to tell if a microphone is dead in a meeting is if the shortened file is too short.
fe016: Thanks, Morgan.
mn014: It's really short, yeah. Yeah.
me011: Then you can be pretty sure that the mike was off.
fe008: Oh.
mn014: Yeah.
mn017: Uh, OK.
me011: And, the t- unfortunately the tabletop ones - the six tabletop which we record all the time no matter how many people are there, uh, don't compress nearly as well because they're almost always have signal on them.
me013: Yeah, that's probably a lot of it. And they're gonna have mikes like that too. In fact, their array - their array will be - Yeah.
mn014: Yeah. Yeah.
me001: Yeah.
me011: Yep. Most of them.
me001: All of them are like that.
me011: Yep. So they won't shorten nearly as well.
me013: @@
mn017: So f- so for dis-
fe016: Wow. Yeah. So - so they're really going to have a huge -
me011: And I assume they're gonna do it lossless.
mn017: for distribution purposes it might make sense to split it by channel,
me011: Yeah.
mn017: uh, rather than by meetings. So, you could distribute, like, only the near-field signals, uh, uh, uh, together for a bunch of meetings and then have a second row .
me011: Yep. Absolutely. And then maybe one far-field. You know?
mn017: Yeah.
me011: It's things - or the mixed channel. Yeah, I think there are a lot of ways to do it, but -
mn017: Mmm.
me011: Let's not worry about that now.
me013: Yeah.
mn017: Right.
me013: Yeah.
me011: How are we on disk space, Chuck?
me018: Um, we're OK. We've got - for the, uh, compressed meetings we've still got about, I think it was four gigs, uh, on the one disk that we're using.
me011: Mm-hmm.
me018: And we've got several - we'v- we've still got, uh, quite a bit of space on the, uh, un-backed-up. So. But I - I think it's probably - we should start thinking about where to go next, especially on the backed-up disk space.
me011: Good.
me013: Now we bought - a little - not all that long ago we brought three uh, thirty-six gigabyte disks.
me018: That's the un-backed-up. Yeah. Those are the u-
me011: Yeah, we're using those for the - for the expanded.
me018: So, for example, the, uh - Guenter's Wall Street Journal data went onto one of those, uh, some other experiment things that people are doing are on there, and -
me013: Uh-huh.
me018: So. If you put it there people will use it. Yeah. So.
me013: So I think after that we need another, uh, rack or something. Right?
me018: Have to change servers, actually.
me013: Change servers?
me018: Well, we could - we could - There are a bunch of disks that we have, uh, that are s- s- smaller. And they're, like, seventeen. We could go to thirty-five. So we could get some extra space out of that. But the s- right now the server's full. We couldn't add any more disks. We could change a smaller disk for a larger one.
me013: We should probably do that while we have the space left on the - on the th- the existing thirty-sixes, so that we can
me018: Yeah.
mn014: Yeah.
me018: Yeah.
me011: Yeah. The problem with that for backed-up media is, uh, the sysadmins wanna keep them at eighteen meg - eighteen gig partitions
me013: shuffle it around.
fe008: Mm-hmm.
me011: because that takes about a day to get off back-up tape.
me013: Oh.
me018: Well, then there's the other issue is that to g- to g-
me011: So.
me018: add more disk now, um, David says we really need to go to new servers. But he wants to go to new servers not just for us but for other groups too. So there's this sort of coordination issue, and
me011: For u- the whole institute. Yeah.
me018: I guess I need to talk to him more about -
me011: Actually, going to bigger disks we can do even, and just maintain the eighteen gig partitions. You just partition them into multiple.
mn014: Yeah.
me018: Yeah.
me011: So that's probably the next step, is to get
me013: That's right.
me011: the eighty or ninety gig drives to replace the thirty gig or an eighteen gig that we have now.
me013: There are eighty gig drives now that you can get for that?
me011: Yeah. Yeah.
me013: See, and that's probably what we should send around for these - to d- for distribution of this corpus. This s- s- isn't any -
me011: A whole handful of microdrives.
me013: Yeah.
me018: Well, when they come out with an-
me011: Is - is the areal density of the microdrive higher than of a w- normal drive? It must be.
me018: When they come out with the eighty gig microdrive then we'll just send one of those little things around with all the meeting data.
me011: Yep.
mn014: Yeah.
me013: Yeah. That's what I meant, yeah.
me011: Well, they have the two gig already. And I'm - I'm just thinking forty of them is probably still smaller in area than, uh, one normal-sized drive.
me013: Actually, what - I think what - what, uh - was it - was it Dave who was suggesting that, uh, you just get, uh, uh, a - a computer
me011: Yep.
me013: that has one of these drives in it and just send the computer around to the different sites. And you can just get it off the computer and press the - Yeah.
me001: Oh, God. Y- Put the computer on tour?
me011: Yeah. A laptop.
fe008: Hmm.
me013: Laptop? Yeah, send the laptop.
mn014: Yeah.
me011: Eighty gig laptop.
me013: And, of course you don't want - y- we don't want to trust the shippers necessarily, so you send a person too. And they just kind of go from site to site, and
me011: I'll - I'll do that.
me013: download their data kind of -
me011: It - uh, uh, unfortunately it takes me a week at each site.
me013: Johnny Appleseed. Yeah. What?
me011: It does take a week at each site. So.
me013: Does it?
me011: Yeah, a- absolutely. If it's a nice site.
fe016: Especially Hawaii.
me013: Yeah. There's a - there's a - they really need it in Novosibirsk.
me011: Yeah, right. Th- that only takes a day or so.
me013: R- r-
me011: Anyway.
me013: I'm probably pr- mispronouncing it. Well.
mn017: But the University of Hawaii has issued a request.
me011: Yep.
me013: Yeah. Mm-hmm. That - that needs a month, yeah, to download. Things are slower there.
mn017: Yeah.
me011: Definitely true.
me013: Yeah. OK.
me011: Any other items?
me013: So. OK, so that's the meeting stuff. Uh, transcrip- So you're - we're - you said it was almost half, so that means that we have, like, eighty or so hours and out of that maybe thirty-five or something are transcribed?
me018: Yeah. The - the pie chart shows actually m- meetings that are, uh - it combines the categories of, you know, "currently in -" Oh! Well, I've got it right there, I think.
me011: I - I saw the pie chart sticking out, so.
me018: Yeah. There's - there's just a few, uh,
fe008: Do you want to write on the l- on the board?
me018: Um. Yeah, except I - I'm tethered. Uh,
me011: D- d- do we care?
me013: He's tethered, yeah.
fe008: I could write on the board.
me018: OK. It combines categories. So when we say "transcribed", we mean either in the process of being transcribed, either here or at IBM,
me013: Oh. Yeah.
me018: or completed transcription, and it also includes, uh, checked. So it includes a lot of categories together. So.
me013: I see.
me011: We need different color pens, definitely.
me018: And that - I think that that status thing is kinda old actually right now.
me013: Oh, that's - Yeah, that's not half. Yeah.
fe008: Last updated in July.
me018: That one that you have?
fe008: Oh, I'm not sure. The one that I saw on the web when I came back. OK.
me018: Yeah. The -
me011: Rustle, rustle.
me018: the date on this one is July twenty-sixth, so, uh, I have to update it. Yeah.
me013: A couple weeks ago. Yeah.
fe008: OK.
me013: But about how much do we have that's sort of, uh - ?
me018: So we have total number of meetings is seventy-eight meetings and,
me013: Mmm.
me018: uh, uh, the total meeting time is seventy-five hours.
me013: Mm-hmm.
me001: Oh.
me018: And, um - So, the ones that are finished being transcribed, as opposed to in the process of being transcribed - we've got twenty-six hours that are
me011: Oh! Great.
me018: finished being transcribed.
me001: What does that mean, "finished being transcribed"?
me018: Um. So there's, uh, several processes to the transcription. There's, uh - I- it ranges from being assigned to a transcriber, to them finishing transcription, to then being checked, you know, with a double-check.
me001: Mm-hmm.
me018: And so, when we say the total transcribed, that's the one that's gone through being checked, I believe. I think that's what the - I have here.
me001: OK.
mn014: Just not yet approved for - Yeah? OK.
me018: But not yet approved. And then there's, uh - the final one is approved for release. That's after the meeting participants have gone through it.
me011: Oh. So I should probably send those to you, shouldn't I?
me001: Oh.
fe008: Yes. At present there's - n- none of those are on the pie chart.
me018: Yeah, if you know. Yeah, currently that's zero, released - uh, approve-
me011: There are five.
me018: Huh?
me011: There are five. We have five where, uh, everyone has replied.
fe008: There're five? Good.
me018: OK. OK. So we have five that are potentially releasable then .
fe008: So the c- the cross-hatching there is, um - is it's been through the double-check. Right? I mean, it's - this is the - it's- it's been tran-
me018: Yeah. That's approval in progress. Yeah.
me013: Mm-hmm.
fe008: Everything on the - So, I mean, it's - When I add a couple more from - that, uh - that were done in my absence, I think that th- we'll be down to about there. So it's not quite as close to half as I'd thought, but it's, you know - it's more than a - And so these right here have been through the double-check. These haven't.
me013: Mm-hmm.
fe008: Oh, how nice of you, holding - holding the thing so I'm not -
me011: It was falling off, uh.
fe008: Yeah, thank you.
me013: Yeah. OK. Uh. Alright. So we still have a long ways to go but maybe the, uh - the IBM thing will - will help push through the - the rest of it somewhat quicker. OK.
me011: And there's still, uh, two people for whom I have not been able to get in touch - have never gotten a response from - from any of the emails about, uh permission forms. So.
fe008: Are they from one of the foreign-language ones? I mean - OK, good.
me011: Yep. That's so - that's why the NSA ones have still not been approved. Though.
fe008: Those will figure less prominently in things anyway.
me011: Yep.
me013: Yeah. It might - it might partly just be European summer vacation issues.
me011: Possibly. It's been, like, four months, so.
me001: Wow.
me013: Oh.
mn017: Uh, you know those Europeans. They got a lot of vaca-
fe008: Long vacations.
me013: Right. Hmm. OK. Uh, www. What else is going on?
mn014: You -
me013: Why don't we just go around, cuz we only have a few minutes.
mn014: Didn't you wanna say something about the hardware set-up?
me011: Oh, that's right. Uh. Yeah, we have new hardware. So, I want to set it up at some point, so I just wanted to know what meeting schedules were.
me013: What new hardware?
me011: Uh, we have several more wireless channels so that we can set up and get rid of these, uh - the wired stuff completely.
fe016: Huh.
me013: Oh.
me011: And then also we got replacements for these mikes.
fe016: Oh. Really?
mn017: Mm-hmm.
me013: So, wha- what's your question?
me011: Yeah.
me001: Oh.
fe016: Are they like
me011: Yeah, they're like those. Those are the only two choices right now, unfortunately.
fe016: these, right? OK.
me013: So what's your question?
me011: Question is, when are we not recording any meetings for a couple days so that I can do it and if it doesn't work, we won't impact people.
me013: Well, there's a point when a bunch of us are off at Eurospeech.
me011: So.
me013: Um.
me011: So, what's SmartKom?
mn014: Nothing this week. Maybe n- end of next week.
me011: End of next week. And is EDU still recording?
fe016: They usually do Thursdays. I don't get a lot of advance notice, but it's al- always been either Mondays or Thursdays. So.
me018: Thursdays?
fe016: Yeah. They - they often do it after - for a while they were doing it after this meeting.
me011: So if I did it, like, tomorrow that would be alright it sounds like? OK.
me018: Oh!
fe016: Yeah. Wednesdays, Fridays -
me011: So it sounds like no one n-
fe016: Definitely Wed- Definitely Wednesday I'm not here, so I don't record anything.
me011: No one early next week.
mn014: Yeah. Let me check with Robert again, but I - I'm pretty sure that there's nothing this week.
me011: OK.
me013: OK.
me011: And then I'll also re-number so that, uh, the mikes are in order.
fe008: Oh, thank you. Thank you. Mmm.
me013: OK.
me011: Should help with the transcripts.
me013: Right.
me011: They wer- so right now the channel numbers are discontiguous.
me018: Hmm.
me011: Right.
fe008: Yeah. I mean, you know, it's an extra step.
mn014: Yeah.
me013: OK. So, I was just thinking maybe just go around and just brief- briefly look what's other things that are going on, maybe, since we don't - don't have much of a set a- set agenda and we don't have much time. Uh.
fe016: But feel free to overlap.
me011: OK, we'll all say what we're doing at the same time.
fe016: No, I mean - I always get scared when you do these portions where you're not gonna overlap because there's less data points. Sorry.
me013: Well, why don't we d- we - we deliberately pick two people to -
fe016: I mean, people could, like, backchannel and ask questions and stuff.
me013: Yeah. I'll - I'll - I'll keep saying "uh-huh". Yeah.
fe016: OK.
mn017: Mm-hmm.
me013: This is absolutely natural meetings. We have absolutely no effect from our preconceptions.
mn017: So, we had -
fe016: Right.
mn017: the - the transcribers have trouble with your backchannel, because -
me013: With my backchannel?
mn017: Yeah, with your backchannels. Because sometimes you have this sort of -
me013: Uh-huh.
mn017: this - this "uh-huh" that you don't n- So there's "uh- huh " and then there's "aha!". And it's not quite clear always what - what it is you mean. Yeah.
fe016: Uh-huh.
me011: Which "uh-huh"?
me013: Which one it is?
mn014: Yeah.
fe016: But I don't think it's "aha!". It's more like "uh- huh! " rather than "uh-huh".
mn014: I'm - Yeah.
mn017: Yeah.
me001: Yeah.
mn014: I don't like the backchannels at all, as that's really a problem with the speech-nonspeech detection. So -
me001: Yeah. Let's get rid of them.
me011: That's a -
me013: Well, has anybody done anything? Come on. What are we doing?
me011: I mean, I'll start if you want. I've been, uh, most recently rewriting Transcriber in Java for no particular reason.
me013: Yeah. Uh-huh.
fe008: Well, for speed.
me011: Uh. Well, I mean, Trans- What happened was that Transcriber's very slow to load. So when you have a big meeting it c- uh, especially on a slower machine, it can take five minutes before you can start doing anything.
mn017: Mm-hmm.
me011: And so I was thinking about why that was and the data structures I would use, and I found myself unable not to sit down and code it. So I did.
mn017: Mm-hmm.
me011: And so I have a big chunk of Transcriber now written in Java and it comes up, you know, in a couple of seconds. Um.
mn017: u- Do you take - do you take feature requests?
me001: Cool.
fe016: Great. Great. Y- y- yeah. W- we should talk to you off-line about something.
me013: Well, wait a minute , what - ?
me011: I - It's not really -
mn017: That would - th- w-
me011: probably not worth doing. But we can talk about it.
mn017: s- Well, actually, I think it is worth doing because here's the thing. We're sort of - we're starting to move from transcription to annotation.
fe016: Yeah.
me011: Mm-hmm.
mn017: And the Transcriber interface is fine if essentially what you're doing is
me011: Annotating.
mn017: stringing words together to p-
me011: Yep.
mn017: to make transcripts. But, um, in - for instance, what we're doing now w- with, uh, Communicator data, but which we would like to do with Meeting data, is to actually label utterances, or words, or whatever units you want with, uh, you know, basically doing a multiple choice type of labeling.
me011: Mm-hmm.
mn017: And for those type of tasks, it wou- it's much more efficient to present, uh, the - th- p- present a bunch of, uh, clickable buttons or whatever and, um -
me011: Dialogue. Yeah. Buttons.
fe016: Mm-hmm. But it has to be multi-stream. Th- they - In other words, the beginning of something could be one speaker and the end of that unit, like question-answer pair, could be a different speaker. That's why we can't just annotate the transcripts, uh, one - listening to one at a time.
me011: Mm-hmm.
fe016: So - so that's why the Transcriber's nice for sort of listening to it, but you can't actually encode, um -
mn017: Hmm.
me011: Yeah. I un- I understand the problem. So.
fe016: encode someth- Yeah, exactly. So.
mn017: And - and th- that's actually a good model, which is what this current tool that we're using has, is to atta- to associate these labels with, um, attributes of SGML tags.
me011: Mm-hmm.
mn017: So, you know, you have, say, a tag for - I don't know - what type of utterance, whether it's a question or a statement or whatever. And then you have an, uh - you know, an - a tag attribute and the value of that encodes the choice.
me011: Right. Right. So what I don't have with it so far is it doesn't play wavefiles and it display wavefiles. I just haven't done that since that - that part wasn't -
mn017: Oh, you mean display as in showing the waveform? OK.
me011: Yep. Yep. And, uh - and then also a lot of the fancy user-interface stuff that's in Transcriber I haven't done.
mn017: Mm-hmm.
me011: But it works.
me013: What's, uh, the original Transcriber written in?
me011: Tcl-TK.
me013: I see.
me011: So.
me013: So.
me018: Are you using - ?
me011: Which is nice and flexible but very, very slow in comparison.
me013: Yeah, yeah. Right.
me018: Are you using the - ? Oh, you - oh, you are. We already talked about that. The XML -
me011: Yep, SAX.
me018: Reading SAX. Yeah.
me011: Cuz it's much faster than DOM and uses less memory.
me018: Right. Right.
me011: So. And then, uh,
mn017: Mm-hmm.
me011: preparing for quals. Uh, hopefully second week of September if I can ever get Warren Sack to answer my emails. I probably shouldn't say that on the tape.
me013: Beep.
me011: Yeah. Oh, well. I gotta remember to beep that out.
me018: Who was that?
me011: No- So anyway. So I've been preparing for that. And, uh,
me013: Not answering your calls, huh?
me011: actually, I wanted to say off-line with you about any literature reviews I should do beforehand.
me013: "War and Peace."
me011: "War and Peace." That's a good choice. Keep me busy.
me013: Yeah. Yeah.
fe016: It's actually not a bad idea to say "beep" as a word because you can search the transcripts, y- you know, for - for that, to find these places.
me011: For "beep". That's a good idea.
fe016: No, I'm s- I'm totally serious. To have one word, like " beep", especially with a really long "eee" like that.
me011: No, absolutely. I agree.
me013: Yeah.
fe016: Works great.
me013: I'll - I'll take that role anytime you want. I like saying it. So. OK.
mn014: Yeah. I've been doing a bunch of recognition experiments on meeting data with different, uh, segmentations - with different - different automatic segmentations, but it's not yet finished. It's work in progress.
me013: OK. Any sense about how - how it does on - ?
mn014: Yeah. For, uh - for - for the paper I w- I want to submit to ASRU to - to, uh, evaluate the quality of the speech-nonspeech detection by using it for speech recognition.
me013: Right, but I was just asking if you had a sense yet of - of, uh, whether - maybe you already did this experiment, where there's this question of - of how much it hurt you or helped you to use segmented
mn017: Yeah, but we didn't have the exact comparison.
me013: versus -
mn014: It -
mn017: But - you know, there were - i- i- the experiments were based on different segmentations and different transcripts.
mn014: Yeah.
mn017: So we weren't quite sure which - whether the difference came from different transcripts, for instance. And so Thilo's -
mn014: So, it hurts compared to the ideal segmentation, when you have the - the manual segmentations, where you have exact boundaries for each s- utterances. Sometimes there are some - some words are cut off or there's some segments i- are s- uh, assigned to s- to speech which there is nothing in. And so there are more insertions but most of the time there are more - the - the number of deletions is higher when - when you use the automatic segmentation compared to the ideal one.
me011: Hmm!
mn014: And so I'm just in - in progress of, yeah, trying to feed the recognizer with un-segmented data and to see how much worse that is. So that - that I have three things. Un- yeah - un-segmented, the automatic, and the - the ideal one.
me013: Yeah.
mn017: But the recognizer's putting up some resistance because it doesn't like the un-segmented data.
mn014: Yeah.
me013: Uh-huh.
me001: Um. Yeah, I just got back from Chicago. So.
me013: @@
me001: Um, fishing went pretty well.
me011: Oh, yeah. All of us are banging.
me013: Good. Good.
me001: And, um, I was gonna post some results, you know, with, uh,
fe016: Wisconsin fishing.
me011: With fishing. B-
me001: Wisconsin fishing. Yeah.
me013: Yeah.
me001: Uh.
me013: So your - so your results are about the same as Bush's, basically. His -
me011: You should have seen the one that got away.
me001: Y- who - Yeah, right. Whose result?
me013: Bush's. Yeah, you're both, you know, sort of - He's - he's coming back to the heartland and - Right. Yeah.
me001: Yeah, right, exactly. I did my tour of the heartland. Yeah.
me018: Did you build any houses?
me001: Yeah. I built a few - built a few houses. Um, but right now I guess, uh, I'm working on this paper - this ISCA paper for this workshop that Liz and Andreas and I are putting together. So we're just getting, uh, different results for - Um, we fixed up our different, uh, transcripts with different types of, uh, annotations and we re- re-ran ali- re-ran alignments. And we're gonna develop a new feature database based on those alignments and do some trees and analysis. So I'm kind of in the middle of that. And hopefully by the twentieth, the twenty-third.
mn017: Mmm.
fe016: Twentieth.
me001: The twentieth! Yeah. We'll have it all straightened out.
mn017: Yeah.
me001: So. It's gonna be a busy week.
mn017: Yeah. You know, I'll bet - You know, Bush went on this European trip recently and
me001: Hmm.
me013: Yeah.
mn017: they told him there that they get more vacations. So he came back here and thought "oh, I - I can afford some more vacation too".
fe016: Beep.
me013: Yeah. I - I think he's b- he's been - he will have been off, like, two months out of his first seven in office. That's a pretty good deal.
me001: Yeah. It's amazing.
mn017: Yeah. It's hard to keep concentration, you know, and the focus on the -
me018: Don't even really notice, do you?
me013: Anyway.
mn017: Um. So while he's vacationing, um, we've been, uh - Well basically this is like a joint effort. Uh, d- we were just -
me013: Who are you talking about, Bush or Don? Yeah.
mn017: Um, @@ you know, f- apart from getting - preparing the - the da- the data for the, um - for these experiments for the, um, uh - for this prosody workshop, um, we just, um - we just had a phone call with Mari and her students, in fact, and they want to, um, e- m- They're bringing up their own meeting recognizer, which is based on Bill Byrne's, uh, recognizer from Johns Hopkins.
me013: Mm-hmm. Based on Hub-five, or like - like your - ?
mn017: u- Based on their Hub-five recognizer. And,
fe016: Mm-hmm.
me013: Yeah.
mn017: uh, so they've been getting from us the, um - you know, some support in terms of getting the latest transcripts and the - also the - actually the,
me013: Mm-hmm.
mn017: uh, transcripts annotated with events, uh, like sentence boundaries and stuff like that.
me013: Mm-hmm. Yeah.
mn017: Um, because one of Mari's students was to - wants to do some language modeling for, uh, predicting overlaps and, uh, stuff like that.
me013: Yeah.
mn017: Um.
fe016: Yeah. Actually we had this ide- from the last time that they were here, that it'd be nice to have UW do some work on language modeling that would be trying to get at the same detection as what we do acoustically since they can ramp up much ques- quicker in the language modeling and we don-
me011: Can I borrow a piece of paper?
mn017: Hmm.
me011: Thank you.
fe016: you know, we'll do the, uh, prosodic side. And so this is supposed to be a project that we could actually integrate the posteriors that they get from their language model for every word boundary or every frame boundary, and then train up the classifiers.
me013: Yeah.
mn017: Mm-hmm.
fe016: And it's - I guess it's an undergrad, too, that - that's going to be doing this work. So.
me001: Cool.
mn017: Yeah. Um, on the recognition side, actually, um, I think the main person doing that is, uh, Harriet from - Harriet Nock from, uh - formerly of Cambridge.
me013: Yeah.
mn017: Um, and apparently they get reasonable results except in some portions they get very high insertion rates - even higher than we get with - with the, um - like even, you know, on lapel mikes with, uh, background speech. And so they were trying to track that down, and - It could be that our recognizer's actually doing relatively well because it has a reject model for, you know, mismatched speech, essentially, or for unspecified speech. And, um, so -
me013: Oh!
mn017: so, uh, they'll - I sent them our recognition output so they can sort of do a line-by-line comparison and see if - if they, um - you know, their insertions correspond to our rejects and stuff like that. So, um, we'll see what that, uh, leads to. Um. Yeah. Other than that, uh, we're - Well, that's pretty m- pretty much it as far as meetings are concerned.
me013: Yeah, I mean we're doing, uh - So I should mention, Dave and I have sort of been pushing through - thinking in terms of an ASRU paper. But I'm still - @@
mn017: Mm-hmm.
me013: I think early next week we'll decide whether we'll - we'll do one or not. Um. But - because, you know, the results are - are still confusing enough that - that, um, we- we gotta be convinced we understand what's going on. But it's starting to look like it - it's almost the opposite of the usual th- situation
me011: Hmm!
me013: where, um, you get some really nice result with, uh - with digits, say, and then you go to a large corpus and the result goes away. Um, we had what looked like a good result in digits but th- but then when we went to more training data that kind of went away.
mn017: Mm-hmm.
me013: So, uh, the digits result right now is kind of equivocal.
mn017: Mm-hmm.
me013: Um, but the conversational speech one, while not huge, is in sort of Hub-five or Meeting kind of terms, actually it's - it's - it's not bad. You know?
mn017: Hmm.
me013: So - So it's - it's - you know, it's like,
mn017: Right.
me013: i- i- w- after he did some adjustments, more like a percent or so that - that i- th- absolute, that it goes - goes down and -
me011: Yeah. It's a PH D.
me013: Sometimes. Yeah.
mn017: But is it still true that basically the s- speaker adaptation, um, sort of negates much of the advantage?
me013: No, I'm talking about with the adaptation.
mn017: With it.
me013: Without the adapt- without the adaptation is a much bigger effect.
mn017: OK.
me013: So it- so it's - it's very reasonable to think of as an alternative way of getting this kind o- kind of improvement.
mn017: Mm-hmm.
me013: But I think what w- ultimately what we have to face with it is that, um - I mean, he gets incredibly good results if you artificially reverberate clean - you know, close - close-miked data. So I think the thing we really have to face is that our model
me011: Right.
me013: for what's going on is - is wrong
me011: Is it wrong?
mn017: Right.
me013: or incomplete, and that in this situation in particular there's a lot of noise.
mn017: Right.
me013: And noise plus reverberation is not at all the same as just reverberation. So, um, uh, there's that one thing that @@ been thinking of doing, is there's a whole lot of work that's been going on in noise suppression in the - in the Aurora, uh, team. And so, uh, they've got some software and I'm think of - of just having us integrate that in, uh, cuz it -
me011: Just combine it see .
me013: Yeah. Cuz it just - I mean, it just subtracts it out. In fact - in fact you can run it in sort of enhancement mode where you get speech out and - and - and, uh, then just run it through the rest of your recognizer. So -
mn017: Mm-hmm.
me013: So, uh um.
mn017: Yeah.
me011: Neat.
me013: So we're working on that.
mn017: OK. There's some work, um, that - Do you remember this paper or poster by, um, some CMU folks at, uh, HLT? They were talking about - and - and they s- they referred to an upcoming ICASSP paper, I think, at the time. Some- someone in Karlsruhe, I think, um, worked on, uh, es- you know, estimating noise from the silent regions and then, uh, doing some explicit - I don't know if it's something akin to parallel model combination or something like that to - to, uh,
me013: I mean, people have done that for a long time. Right?
mn017: Right. Anyway, uh, so I - I - I couldn't judge whether this was original or not, but - but it seemed like they got pretty good results on their meeting data. So we might want to look into that.
me013: Yeah, I don- I don't remember the paper. But I mean, that - th- that's certainly one of the common techniques is to do that.
mn017: Right. Right.
me013: Uh, and in all th- the stuff that our team is doing they certainly look at regions that you think are nonspeech in order to get noise statistics. But,
mn017: Mm-hmm. Right.
me013: uh, I mean, there's a host of thing- different things you could do. In the Aurora thing, we have - we have a little bit of a handicap in that they - they don't let you, uh, adjust the tis- the statistical models. So y- you have to - you have to do everything at the feature level.
mn017: Mm-hmm.
me013: Um. But, um, um - but there's, uh, you know, Wiener filtering and spectral subtraction which are, uh, sort of - i- can be looked at as m- minor modifications of one another. Um. And they- they've now built up a nice piece of software that does - u- um - has this sort of general framework for a - for it so that you can adjust it to sort of an- any - any - any one of a dozen ways that people have done this kind of thing and
mn017: Mm-hmm.
me013: they found a particular set of parameters they liked this week. And we're running with that for a while. But.
mn017: OK.
fe016: So. Well, I'll just really briefly, um -
me013: Anything else?
fe016: So, I've been working with Don and also - and - and Andreas on the - this paper on prosody, and what we're trying to do is predict where people - at - given all information up to whatever point in time you're considering, try to predict if that's a good location for someone else to jump in. So, that's the idea of that paper. And that's the same task that Mari, a- um, a student named Dustin, and also Sarah who was at this last meeting will be looking into doing from the language modeling side. Maybe some kind of clu- you know, clustered class Ngram or something.
me013: Uh-huh.
fe016: Um. And also we're - we're using a couple of the labelers who are doing emotion to help us, um, finalize some transcripts for this. So these undergra- undergrad students are really helping us out a lot,
me001: Yeah.
fe016: under Don's supervision, actually. So that's good. So these offices are being, uh, very busy - Don's and the one across from him.
me001: Right.
fe016: And then also, um, working with Jeremy on Communicator emotion labeling. And most of that up to a few weeks ago was just getting the people labeling these utterances to a computer for emotion and that's going pretty well now. @@
me013: What kind of emotions do you label?
fe016: Um. Well, we're mostly looking for places where the person's frustrated with the system.
me013: So, there's just two categories, frustrated and not, or - ? No.
fe016: There - there are actually - that's how we started it. And we had different levels. Now we have things like "amuse". Like, "oh, you finally got it". And -
me013: Yeah.
fe016: um, and "disappointed-tired". Like, "yeah, no, that's wrong again".
me011: @@
fe016: Which isn't really mad, but, you know. So th- they gave me a lot of feedback. The labelers, after doing this,
me013: Yeah. Uh-huh.
fe016: told me what they wanted as categories. So. And then there's jokes. And - Yeah, right. Um.
me013: Yeah.
fe016: There's not a lot of - enough frustration for us to really go through quickly, cuz we have to label every meeting and also things like repeats for the same information, and so forth. And I've been coordinating a little bit with Katrin at, uh, UW who was doing user correction work that she presented at the - at the meeting. So there's some overlap there in what you m- there's a correlation between corrections and annoyance or frustration.
me013: Yeah.
fe016: Um, but Jeremy's been starting to really work on that project now from the acoustic side. So we have all these waveforms, and he's been with Morgan's help and, uh, Dan Ellis's, I think, looking into spectral tilt a bit, so he can talk about that. It's a feature we haven't used before. Um, and starting to, uh, r- r- take information from alignments and create a database that we can use sort of as a - a large feature vector or table to feed to our decision trees, which will try to give us back an answer from the speech only as to whether the person's frustrated or not.
me013: That reminds me of something. We - we talked about something a ways back and I sort of lost track of it, about having a synthesizer driven with -
fe016: So.
mn014: Yeah.
fe016: Yeah.
mn014: I haven't really had time to do that.
fe016: Actually, I wanted to talk with you about that cuz there's a similar project at SRI where we're using - we want to do something like that to look at whether or not some of the p-
mn014: Yeah.
fe016: stylized pitch stuff is,
mn014: Yeah.
fe016: um, sort of perceptually similar to the kinds of things that people would mark. So, I - I actually wanted to talk to you about that. So.
mn014: Yeah. Maybe after Wednesday?
fe016: OK. Yeah. Cuz this will be, like, after -
me013: Yeah, cuz you have this AS- ASRU deadline.
mn014: Yeah. Yeah.
mn017: Right.
fe016: OK. Yeah. This will be after September anyway, so I -
me013: But that seemed like it would be fairly straight-forward, that if you take the - take the pitch from the real data,
mn014: Yeah. Yeah.
me013: feed it into the synthesizer, and then process the output with a gain box that you also had energy from the - from the real data.
fe016: Right.
mn014: Yeah.
fe016: Yeah. There was just no way to
me013: @@
mn017: Hey! We could use that in the English -
fe016: use the energy in Festival, that was -
mn017: We have to do the English synthesis for SmartKom. What if we make the system really annoyed?
fe016: OK- Anyway. I - I should move on cuz we're running late, but I wanted to say there's one question in my mind, which maybe
me013: Yeah.
fe016: Morgan can talk to Jeremy about, is how to sort of normalize spectral tilt. It's just - I'm sort of in this, uh, area I don't know much about and so we should talk off-line. But if you have a certain speaker
me013: OK. Mm-hmm.
fe016: and you wanna sort of get a bunch of data from that speaker but compare it, you know, directly on a feature to - to like a decision tree that won't normalize anything for you once you feed it the features, how do you sort of normalize over a particular speaker? What kinds of - what - what makes sense to do with that feature?
me013: Well, I'll have to hear what he's using, f- given different suggestions he's gotten. But -
fe016: So. i- Yeah. But that's something we would be glad to have help on.
me013: OK.
fe016: So. Go ahead, Jeremy.
me051: Right. So I've been looking at spectral tilt and different ways of perhaps generating it. And, um, I basically have three ways right now that we're looking at for, uh - we're gonna look at for features. Uh, one is just looking at, um, the first cepstral coefficient and, uh, using that. Um, another is looking at the log ener- the difference of log energies between, um, the high - like a high-frequency band and a low-frequency band. And the third is just, um, taking a slope, um, of the linear fit of the spectrum and using that. So, those are the three - three ways I have right now for generating these spectral tilt numbers. And, um, hopefully soon we can look at some of the labeled stuff and look at, uh, these numbers and see - see which ones w- seem to be working well. And things like that. Um, I also recently wrote a script, um, that, uh, generates the kappa statistic, um, which is a - for labeler agreement. Um, so,
mn014: Yeah.
me051: been looking at that as well.
me013: I mean, wh- what - specifically, what you wanna do is remove the - the - the - the average, uh, speaker tilt in some sense?
fe016: The thing i- Yeah. We - we - you wanna use spectral tilt to try to get at the s- n- the voice quality of these utterances. So you could have something like "no" versus "no!" and these might differ in that way. But the problem is we don't know - th- we don't - we don't know whether the "no" is frustrated or not.
me013: You don't know it. Yeah. Yeah.
fe016: So - Right. Exactly.
me011: Mmm.
fe016: And then you also have the different speakers. And so, the sort of question is,
me013: Yeah.
fe016: do you wanna average all the data together or do you - do you - ? You wanna capture the change in voice quality within a speaker, without having to know ahead of time w- which is which, cuz that would be circular. So,
me013: I mean, m- maybe - maybe this is too obvious to be right, but I mean, the - the - the - the normal thing for Cone would be to - to, uh, get rid of the mean and th- and the variance. Right?
fe016: u- this is -
me013: Does that - ? The mean and variance. Have it be zero mean and unity variance. And then -
fe008: To get rid of what?
me011: Mean and variance.
fe008: OK.
fe016: But do you do this, say, just in the vowel regions, and do you - ? a- There's - there's a whole bunch of, um, sort of unknowns. And we can try all of them and just put them into the tree as features, and -
me013: Right. Well, the answer's yeah. I mean, you want - you want it for every place that's voiced.
mn017: But - but you can't do it - I mean you can't just normalize it based on the utterance because then you're gonna have zero everywhere. Right? So you'd have to normalize it based on the -
me013: No, ev- everything for that speaker.
fe016: Yeah.
mn017: Yeah, OK. But that's not really feasible because you're having a sys- you have a system, a dialogue system,
fe016: Everything up to that point.
mn017: where you only have access to the - what the speaker said before. So it'd have to be sort of a causal,
me013: Yeah?
fe016: Oh, yeah. That's OK. That - that's the sort of - w- we keep - you keep, uh, iterat- you keep updating those numbers for future utterances. Th-
mn017: uh, version of @@ .
me011: Yeah.
mn017: Or you c- u-
me013: Yeah. I mean, but - but the main - I think the main thing is that -
fe016: That - that would work.
me013: the - You're right. I mean, the main distinction is whether it's voiced or - or - voiced or not. If it's - if it's - if it's silence or - or unvoiced regions, then you - you - you don't really want that in there, uh, if you can help it.
fe016: Yeah.
me013: But actually, I mean, just to first order, suppose you just didn't do anything smart at all and just did - you know, did that, it wouldn't be that bad. Because you'd get some number that would be skewed by - be skewed by that -
fe016: So you mean, you're just using a mean and the varian- and a variance?
me013: You know, uh, uh, X- X - X - X- X - X minus mu over sigma. Yeah.
fe016: You mean just a - a Zsquare, like? Right, right. Right. OK. So it is distributed in a way that you can do this. Yeah. OK.
mn017: Mmm.
me013: It - it - it's - it's sort of the first-order thing to do. There's, uh, you know, uh, obviously much - much more arcane things to do and complicated things to do.
fe016: @@ OK. So, that's - so - that was our sort of -
me013: But that's -
fe016: maybe this will work, I don't know . OK.
me013: th- that's the first thing to do. And then - you know, then the next thing is, "well, let's just look at the voiced regions", you know, and that would be a reasonable thing to do. And then if it's really - when you look at what y- i- i- i- Since you're looking at something that's sort of in log domain, cepstral is like log d- linearly transformed of a log domain, it's probably not that terrible an assumption to pretend it's Gaussian anyway. And so the other things that get more - more tricky are, uh, to handle the fact that it's not - not really Gaussian. And - and y- you may - you may not really need that for this.
fe016: Well, we probably won't get that far. Yeah.
me013: Yeah. So I think
fe016: OK.
me013: that would be - that would be the obvious thing to do.
fe016: OK.
mn017: Well, we're not gonna build a parametric model of the - o- o- of the - of the feature. Right? We're just gonna - we- we're gonna use
fe016: Yeah.
me013: No, I understand. It's just - it - it - No, it's more that - that if you felt something wasn't Gaussian and you were trying to
mn017: like thresholding or something.
me013: normalize for some kind of, uh, bias of some sort, you might use a non-parametric
mn017: Right, right. OK.
me013: measure, like you might use a median, you know, and rank statistics, and all that sort of stuff. But I mean, you shouldn't bother with it if it's roughly Gaussian. Just - Yeah.
fe016: m- Median, yeah. We could just plot - plot these for a speaker, and
mn017: Right.
fe016: get a bunch of histograms.
mn017: Right.
fe016: OK.
mn017: OK.
fe016: Right.
mn017: Uh, yeah.
fe016: Thanks.
me013: Sure. Uh, and I already - I already said what I was doing, which is mostly trying to give advice to Dave when he - he - he actually does the real work on this, uh, reverberation thing. But I think it's - it's - it's a real, uh - it's a real learning experience for both of us. And - and, uh, I think it's - it's a problem ar- problem area that people really haven't dealt with that much, as we know. So, uh, w- h- he kind of did - he started off with what was in some sense sort of the first obvious thing to do, although hardly anybody had done it yet. And, uh, it - it does work very well under some conditions and other conditions it doesn't. And now we're understanding - trying to understand what those are.
mn017: Mm-hmm.
me013: It- it's - it's - it's fun. Do you want to add some- anything? - to say anything? How was y- Did you catch fish, or - ?
me011: She just got back.
fe008: No.
me013: No. No fish. OK.
fe008: No.
me013: You know, when Bush catches fish they actually put a bunch of fish in the lake for him.
fe016: Really s- really hungry fish.
fe008: Oh.
me001: It's part of the budget.
me013: I'm - I'm not kidding. Really. They just - they - they pre-stocked it with - with a - a - I'm really not kidding.
me011: The Secret Service is out there throwing fish into the ocean - into the lake.
me001: How they - They got, like, scuba gear on and, like, hooking them.
mn017: But they didn't tell her.
me011: Hmm. "Hey, I caught one - this one - and it's already cooked!"
mn017: It - you know, to keep -
fe016: It's already dead.
mn017: to keep us, uh -
me013: Yeah. So we're ready to increase our federal funding.
me011: I think we're done. Should we do, uh, simultaneous digits so that we actually have time for tea?
me013: Why - why don't we? Yeah, let's do that.
mn017: OK. Hmm.
me013: I still don't know if these are gonna be any good but it sure does get us out of here quicker. A one, and a two, and a three.
me011: Ready?
me013: And you were worried we wouldn't have any overlap today.
me011: Got plenty of overlap.
mn017: So, did you - Jeremy, did you know that whoever finishes last has to buy cappuccino for everybody?
me011: And - And we'r-