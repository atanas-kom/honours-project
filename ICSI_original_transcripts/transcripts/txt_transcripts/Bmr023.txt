fe016: OK, we're recording.
mn014: It's recording.
me013: Oh. Wait a minute. Wait a minute.
me018: Gotta turn this on.
me013: Yeah. Oh boy, I got the harness. @@
me001: Uh-oh.
me013: Um.
me018: Hmm.
me001: One.
me013: OK. Boy, this - these things sure are weird. OK.
fe016: Yeah.
mn014: Channel.
mn017: What channel am I on? Oh, channel two.
fe016: Make sure to turn your microphone on. There's a battery.
mn014: Channel.
me001: There we go.
fe016: OK. Your channel number's already on this blank sheet. So you just - If you can -
me001: Yeah.
me013: Channel five? Channel five. I'm on channel five.
mn014: Channel whatever.
me001: Camera one, camera two.
mn014: What am I?
me013: Little low?
mn014: Channel four?
me013: Channel five.
mn014: This number four? OK.
me013: Channel five. OK.
fe016: The gai- the gain's up at it - what it usually is, but if you think it's -
me013: Is it?
fe016: Yeah. It's sort of a default. But I can set it higher if you like.
me013: Oh. Maybe it should be a little higher.
fe016: Yeah?
me013: It's not showing much. Test, test, test, test, test, test, test, test, test, test. OK, that - that seems better? Yeah? OK, good. Ah, that's good, that's good.
fe016: Yeah.
me013: Can't get it on ? That's good, that's good. OK. Ahh. Mmm. So I - I had a question for Adam. Have we started already?
fe016: Well, we started recording, but - Yeah.
me013: Yeah. Is Jane around or - ?
me018: I saw her earlier.
me013: Uh.
fe016: She can just walk in, I guess, or -
me018: I think - Yeah. She'll probably come up.
me013: Right.
fe016: Since we're starting late I figured we'd better just start.
me013: Yeah. Great idea. I was gonna ask Adam to, uh, say if he thought anymore about the demo stuff because it occurred to me that this is late May and the DARPA meeting is in mid July. Uh, but I don't remember w- what we - I know that we were gonna do something with the transcriber interface is one thing, but I thought there was a second thing. Anybody remember?
fe016: Well, we were gonna do a mock-up, like, question answering or something, I thought, that was totally separate from the interface. Do you remember? Remember, like,
me013: Mm-hmm.
fe016: asking questions and retrieving, but in a pre-stored fashion.
me013: Right.
fe016: That was the thing we talked about, I think, before the transcriber - Come on in.
me013: Yeah. Alright. So anyway, you have to sort out that out and get somebody going on it cuz we're - got a - got a month left basically. So.
fe016: You like these. Right? OK, good.
me013: OK. Um OK. So, what are we g- else we got? You got - you just wrote a bunch of stuff.
fe016: No. That was all, um, previously here.
me013: Oh.
fe016: I was writing the digits and then I realized I could xerox them,
me013: Oh, oh.
fe016: because I didn't want people to turn their heads from these microphones. So.
me013: Oh.
fe016: We all, by the way, have the same digit form, for the record. So.
me013: That's cool.
fe016: Yeah.
me013: So, the choice is, uh, which - which do we want more, the - the - the comparison, uh, of everybody saying them at the same time or the comparison of people saying the same digits at different times that - ?
fe016: It's just cuz I didn't have any more digit sheets.
me013: I know that.
fe016: So.
me013: But, you know, which opportunity should we exploit?
fe016: Yeah.
mn017: Unison.
fe016: I mean, it - Actually it might be good to
me013: Unison.
fe016: have them separately and have the same exact strings. I mean, we could use them for normalizing or something, but it of course goes more quickly doing them in unison. I don't know.
me013: I guess we'll see i- I guess it's dependent on
fe016: See how long we go.
me013: how long we go and how good the snack is out there. Yeah. Hmm. Get some advance intelligence.
mn014: But anyway, they won't be identical as somebody is saying zero in some - sometimes, you know, saying O, and so, it's not i- not identical.
mn017: Yeah.
fe016: Right. Right.
me013: Yeah. We'd have to train.
fe016: We'd be like a chorus.
mn014: OK.
me013: Yeah. We'd have to get s- get some experience.
mn017: Greek chorus.
me001: Yeah.
fe016: Yes.
me013: Yeah. Really boring chorus. Um. Do we have an agenda? Adam usually tries to put those together, but he's ill. So.
me018: I've got a couple of things to talk about.
me013: Yeah. Uh ju- what - what might those be?
me018: Uh, IBM stuff and, um, just getting uh, meeting information organized.
me013: Meeting info organized. OK. Um.
mn017: Are you implying that it's currently disorganized?
me018: In my mind.
me013: Is there stuff that's happened about, um, uh, the SRI recognizer et cetera, tho- those things that were happening before with - ? Y- y- you guys were doing a bunch of experiments with different front-ends and then with -
mn017: Well.
me013: Is - is that still sort of where it was, uh, the other day?
mn017: We're improving.
me013: We're improving.
mn017: Yeah.
me018: Now the - the - You saw the note that the PLP now is getting basically the same as the MFCC. Right?
me013: Right. Right.
mn017: Yeah. Actually it looks like it's getting better.
me013: Oh.
mn017: So. But - but it's not -
me013: Just with - with age, kind of.
mn017: With age. Yeah.
me013: Yeah. Yeah.
mn017: But, uh, that's not d- directly related to me. Doesn't mean we can't talk about it. Um, it seems - It looks l- I haven't - The - It's - The experiment is still not complete, but, um, it looks like the vocal tract length normalization is working beautifully, actually, w- using the warp factors that we computed for the SRI system and just applying them to the ICSI front-end.
me013: Mm-hmm. That's pretty funny. OK.
mn017: Yeah.
fe016: So you just need to copy over to this one.
mn017: Just had to take the reciprocal of the number because
fe008: OK.
fe016: @@
mn017: they have different meanings in the two systems.
me013: Ah! Yeah. Well, that's always good to do. OK.
mn017: Yeah.
me013: OK. Uh -
mn017: But one issue actually that just came up in discussion with Liz and - and Don
me013: Yeah.
mn017: was, um, as far as meeting recognition is concerned, um, we would really like to, uh, move, uh, to, uh, doing the recognition on automatic segmentations. Because in all our previous experiments, we had the - uh, you know, we were essentially cheating by having the, um, you know, the h- the hand-segmentations as the basis of the recognition.
me013: Mm-hmm.
mn017: And so now with Thilo's segmenter working so well, I think we should consider
mn014: Mmm. So.
me001: Come on.
mn017: doing a -
mn014: Yeah. We - But -
me013: Y- think - you think we should increase the error rate. Good.
mn017: uh, doing -
mn014: Anyway. Yeah. Yeah.
mn017: Yeah. Yeah.
me013: Yeah.
mn014: That- that's what I wanted to do anyway, so we should just
fe016: Yeah.
mn017: Yeah. Yeah.
fe016: And even -
mn014: get together and -
fe016: The good thing is that since you, um, have high recall, even if you have low precision cuz you're over-generating, that's good because we could train
mn014: Yeah.
mn017: Right.
fe016: noise models in the recognizer for these kinds of,
mn014: Yeah.
fe016: uh, transients and things that come from the microphones, but I know that if we run recognition unconstrained on a whole waveform, we do very poorly because we're - we're getting insertions in places what - that you may well be cutting out. So we do need some kind of pre-segmentation.
mn017: Well -
mn014: Yeah.
me013: Mm-hmm.
mn017: We should - we should consider doing some extra things, like, um, you know, retraining or adapting the -
fe016: Mmm.
mn017: the models for background noise to the - to this environment, for instance.
fe016: Yeah.
mn014: Yeah.
fe016: And, yeah, using Thilo's,
mn017: So.
fe016: you know, posteriors or some kind of - or - right now they're - they're discrete, yes or no for a speaker,
mn014: Yeah.
fe016: to consider those particular speaker background models. So. There's lots of ins- interesting things that could be done.
mn017: Right.
mn014: Yeah. Yeah. We should do that.
fe016: So.
me013: Good. So, uh, why don't we, uh, do the IBM stuff? You had some thing about that?
me018: Yeah. So, um, talked with Brian and gave him the alternatives to the single beep at the end of each utterance that we had
me013: Right.
me018: generated before. And so -
me013: The, uh, Chuck chunks.
me018: Yeah. The Chuck chunks. Right.
mn014: Hmm.
me018: And so he talked it over with the transcriber and the transcriber thought that the easiest thing for them would be if there was a beep and then the nu- a number, a digit, and then a beep,
me013: Yeah. Yeah.
me018: uh, at the beginning of each one and that would help keep them from getting lost. And, um, so Adam wrote a little script to generate those style, uh, beeps and so we're -
mn017: Where'd you get the digits from?
me018: I came up here and just recorded the numbers one through ten.
fe008: They sound really good.
me018: So.
fe016: That's a great idea.
me018: Does it sound OK?
fe008: Yeah.
me018: So, um - Yeah. We just used those.
mn017: And do you splice them into the waveform? Or - ?
me018: Yeah. He - then he d- I recorded - Actually, I recorded one through ten three times at three different speeds and then he picked.
mn017: Right. Mm-hmm.
me018: He liked the fastest one, so he just cut those out and spliced them in between, uh, two beeps.
mn014: It will be funny uh -
fe008: It sounds like a radio announcer's voice. Really.
me018: Does it?
fe008: Yeah, yeah.
mn014: It will be funny when you're really reading digits, and then there are the chunks with - with your digits in?
me018: Yeah. With my -
fe016: Oh, right.
fe008: Oh that's right.
mn014: Yeah.
fe008: Now actually,
me018: That'll throw them, huh?
fe008: we're - Are we handling - ?
me013: Uh, maybe we should have you record A, B, C for those or something.
mn014: Yeah.
me018: Yeah. Huh! Maybe. And she said it wasn't gonna - the transcriber said it wouldn't be a problem cuz they can actually make a template, uh, that has beep, number, beep. So for them it'll be very quick
mn014: OK.
me013: Yeah.
me018: to - to put those in there when they're transcribing. So, um, we - We're gonna send them one more sample meeting, uh, and Thilo has run his segmentation. Adam's gonna generate the chunked file. And then, um, I'll give it to Brian and they can try that out. And when we get that back we'll see if that sort of fixes the problem we had with, uh, too many beeps in the last transcription.
me013: OK. Do w- do - what - Do you have any idea of the turn-around on - on those steps you just said?
fe016: Great.
me013: Uh.
me018: Uh. Our s- our - On our side? or including IBM's?
me013: Including IBM's.
me018: Well, I don't know. The last one seemed like it took a couple of weeks.
me013: OK.
me018: Um, maybe even three. Uh, that's just the IB M side. Our side is quick. I mean, I - I don't know. How long does your - ?
mn014: It should @@ be finished today or something. Yeah.
me013: Well, I meant the overall thing. e- e- u- u- The reason I'm asking is because, uh, Jane and I have just been talking, and she's just been
me018: Yeah.
me013: doing. Uh, e- a, you know, further hiring of transcribers. And so we don't sort of really know
me018: Mm-hmm. Mm-hmm.
me013: exactly what they'll be doing, how long they'll be doing it, and so forth, because right now she has no choice but to operate in the mode that we already have working. And, uh,
me018: Right.
me013: so it'd be - It'd be good to sort of get that resolved, uh, soon as we could, and then -
me018: Yeah. I - Yeah, I - I hope @@ we can get a better estimate from this one that we send them.
me013: Mm-hmm.
me018: So. Um. I - I don't know yet
me013: Yeah. Um -
me018: how long that'll take.
me013: I mean in particular I would - I would really hope that when we do this DARPA meeting in July that we sort of have - we're - we're into production mode, somehow - You know, that we - we actually
me018: Mm-hmm.
me013: have a stream going and we know how - how well it does and how -
me018: Yeah.
me013: and how it operates. I think that would - that would certainly be a - a very good thing to know.
me018: Right. Right.
me013: OK. Uh. Maybe before we do the meeting info organize thing, maybe you could say relevant stuff about where we are in transcriptions.
fe008: OK. So, um, we - Uh, the transcribers have continued to work past what I'm calling "set one", which was the s- the set that I've been, uh - OK, talking about up to this point, but, uh, they've gotten five meetings done in that set. Right now they're in the process of being edited. Um, the, um - Let's see, I hired two transcribers today. I'm thinking of hiring another one, which will - because we've had a lot of attrition. And that will bring our total to -
me013: They die off after they do this for a while. Yeah.
fe008: Yeah.
me018: Burn-out.
fe008: Well, you know, it's - it's various things. So, one of them had a baby. Um, you know, one of them really w- wasn't planning -
mn017: Oh, that was an unfor- unforeseen side effect of -
fe008: Eh, one of them, um, had never planned to work past January. I mean, it's th- all these various things, cuz we, you know, we presented it as possibly a month project back in January and - and -
me013: Yeah.
fe008: and - and - Um, so it makes sense. Uh, through attrition we - we've - we're down to - to two, but they're really solid. We're really lucky the two that we kept. And, um - Well, I don't mean - I don't mean anything against the others. What I mean is we've got a good cause - a good core. No. We had a good core -
fe016: Well, they won't hear this since they're going. They won't be transcribing this meeting.
fe008: Yeah, but still. I mean, I d- it's just a matter of we - w- we're - we've got, uh,
me013: No backs.
fe008: two of the ones who - who, um, ha- had been putting in a lot of hours up to this point and they're continuing to put in a - a lot of hours, which is wonderful, and excellent work. And so, then, in addition, um, I hired two more today and I'm planning to h- hire a third one with this - within this coming week, but - but the plan is - just as, uh, Morgan was saying we discussed this, and the plan right now is to keep the staff on the - on the leaner side, you know, rather than hiring, like, eight to ten right now,
me013: Mm-hmm.
fe008: because if the IBM thing comes through really quickly, then, um, we wouldn't wanna have to, uh, you know, lay people off and stuff. So. And this way it'll - I mean, I got really a lot of response for - for my notice and I think I could hire additional people if I wish to.
me013: Yeah. An- and the other thing is, I mean, in the unlikely event - and since we're so far from this, it's a little hard to plan this way - in the unlikely event that we actually find that we have, uh, transcribers on staff who are twiddling their thumbs because, you know, there's, you know, all the stuff that - that was sitting there has been transcribed and they're - and they're faster - the - the pipeline is faster than - uh, than the generation, um, eh, i- in - in the day - e- event that that day actually dawns, uh, I - I bet we could find some other stuff for them to do. So I - I think
fe008: Oh, yes.
me013: that, eh, eh, a- as we were talking, if we - if we hire twelve, then we could, you know, run into a problem later. I mean, we also just couldn't sustain that forever. But - but, um - for all sorts of reasons - but if we hire f- you know, f- we have five on staff - five or six on staff at any given time, then it's a small enough number so we can be flexible either way.
fe008: Good. OK.
me013: Good.
fe016: It'd be great, too, if, um, we can - we might need some help again getting the tighter boundaries or some hand - to experiment with, um - you know, to have a ground truth for this segmentation work, which - I guess you have some already that was really helpful, and we could probably use more.
mn014: Mmm, yeah. That was a thing I - I planned working on, is, uh, to use the - the transcriptions which are done by now, and to - to use them as, uh - Yeah.
fe016: Oh. Oh, the new ones with the tighter boundaries. Yeah.
mn014: Yeah. And to use them for - for training a - or for - fo- whatever. Yeah. To - to create some speech-nonspeech labels out of them, and - Yeah, but that - that's a thing w- was - w- what I'm just looking into.
fe016: OK.
fe008: The - the - the pre-segmentations are so much - are s- so extremely helpful. Now there was, uh, I g- guess - So, a couple weeks ago I needed some new ones and it happened to be during the time that he was on vacation - f- for just very few days you were away.
mn014: Yeah.
fe008: But it happened to be during that time I needed one, so I - so I started them on the non-pre-segmented and then switched them over to yours and, um, they, um - you know, they always appreciate that when they have that available. And he's, uh, usually, eh, uh, um - Um. So they really appreciate it. But I was gonna say that they do adjust it once in a while. You know, once in a while there's something like,
mn014: Yeah, sure.
fe008: um, and e- Actually you talked to them. Didn't you? Did you? Have you - ?
mn014: Yeah. I talked to Helen.
fe008: And - and - and she was - And so, I asked her - I mean, They're very perceptive. I really want to have this meeting of the transcribers. I haven't done it yet, but I wanna do that and she's out of town, um, for a couple of weeks, but I wanna do that when she returns. Um, cuz she was saying, you know, in a - in a span of very short period - we asked - It seems like the ones that need to be adjusted are these - these - these things, and she was saying the short utterances, uh, the, um -
fe016: Hmm.
mn014: Mmm. Yeah.
fe008: you know, I mean, you're - You're aware of this.
mn014: Yeah.
fe008: But - but actually i- it's so correct for so much of the time, that it's an enormous time saver and it just gets tweaked a little around the boundaries.
fe016: That's great.
fe008: So. Um. Yeah. I think it'd be interesting to combine these.
mn014: Yeah.
fe016: Is there actually a record of where they change? I mean, you can compare, do a diff on the - just so that we knew -
fe008: You could do it. It's - it's complicated in that
mn014: Yeah.
fe008: um, hhh, i- hhh, i-
mn014: Actually, when - when they create new - yeah, new segments or something, it will be, uh, not that easy but - hmm.
fe016: I mean, if we keep a old copy of the old time marks just so that if we run it we know whether we're - which ones were cheating and
mn014: I think one could do that. Yeah. Yeah. Yeah. That would be great, yeah, to know that.
fe016: which one would be good.
fe008: There is a - there is one problem with that and that is when they start part way through then what I do is I merge what they've done with the pre-segmented version. So it's not a pure -
mn014: Yeah.
fe008: it's not a pure condition. Wha- what you'd really like is that
fe016: Mm-hmm.
fe008: they started with pre-segmented and were pre-segmented all the way through. And, um - @@ - I, uh - the - it wasn't possible for about four of the recent ones. But, it will be possible in the future because we - we're, um.
mn014: Yeah.
fe008: @@
fe016: Mmm, that's great.
mn014: It would. Yeah.
fe016: Yeah. As long as we have a record, I guess, of
mn014: Yeah.
fe016: the original automatic one, we can always find out
mn014: Yeah.
fe016: how well we would do fr- from the recognition side by using those boundaries. Um. You know, a completely non-cheating version. Also if you need someone to record this meeting, I mean, I'm happy to - for the transcribers -
mn014: Yeah. Yeah.
fe016: I could do it, or Chuck or Adam.
fe008: Thank you.
me013: OK. So, uh, u- you were saying something about organizing the meeting info?
me018: Yeah. So, um, uh, Jane and Adam and I had a meeting where we talked about the reorganization of the directory structure for all of the meeting -
me013: Did you record it?
me018: No. For all the Meeting Recorder data. We should have. Um. And so we've got a plan for what we're gonna do there. And then, Jane also s- prepared a - um, started getting all of the - the meetings organized, so she prepared a - a spreadsheet, which I spent the last couple of days adding to. So I went through all of the data that we have collected so far, and have been putting it into, uh, a spreadsheet with start time, the date, the old meeting name, the new meeting name, the number of speakers, the duration of the meeting, comments, you know, what its transcription status is, all that kind of stuff. And so, the idea is that we can take this and then export it as HTML and put it on the Meeting Recorder web page so we can keep people updated about what's going on.
fe016: Oh, great.
me018: Um, I've gotta get some more information from Jane cuz I have some - some gaps here that I need to get her to fill in, but so far, um, as of Monday, the fourteenth, um, we've had a total number of meeting- sixty-two hours of meetings that we have collected. And, um - Uh, some other interesting things, average number of speakers per meeting is six. Um, and I'm gonna have on here the total amount that's been transcribed so far, but I've got a bunch of - uh, that's what I have to talk to Jane about, figuring out exactly which ones have - have been completed and so forth. But, um, this'll be a nice thing that we can put up on the - the web site and people can be informed of the status of various different ones. And it'll also list, uh, like under the status, if it's at IBM or if it's at ICSI, uh, or if it's completed or which ones we're excluding and - and there's a place for comments, so we can, um, say why we're excluding things and so forth. So.
me013: Now would the ones that, um, are already transcribed - we h- we have enough there that c- you know, we've already done some studies and so forth and - um, shouldn't we go through and do the business -es u- of - of having the, um, uh, participants approve it, uh, for - approve the transcriptions for distribution and so forth?
fe008: Um, interesting idea. In principle, I - I would say yes, although I still am doing some - the final-pass editing, trying to convert it over to the master file as the - being the channelized version and it's - Yeah, it seems like I get into that a certain way and then something else intervenes and I have to stop. Cleaning up the things like the, uh, uh, places where the transcriber was uncertain, and - and doing spot-checking here and there. So, um, uh, I guess it would make sense to wait until th- that's done, um, but - but -
me013: Well, le- let me put in another sort of a milestone kind of - as - as I did with the, uh, uh - the - the pipeline.
fe008: Yeah.
me013: Um, we are gonna have this DARPA meeting in the middle of July, and I think it w- it'd be -
fe008: Yes.
me013: given that we've been - we've given a couple public talks about it already, spaced by months and months, I think it'd be pretty bad if we continued to say none of this is available. Um.
fe008: It'll certainly be done by then. Yeah.
me013: Right. So we can s- we - we wanna be able to say "here is a subset that is available right now"
fe008: Mm-hmm. That's right.
me013: and that's has been through the legal issues and so forth. So.
fe008: That's right. Yeah. That's right. So that -
me013: OK?
fe008: OK.
me013: So,
mn017: And they don't have to approve,
me013: by - before July.
mn017: you know, th- an edited version, they can just give their approval to whatever
me013: Well, in principle, yes. But, I mean, i- if - if - if somebody actually did get into some legal issue with it then we-
fe008: Well, maybe -
mn017: version Bu- Yeah. But th- I mean, the editing will continue. Presumably if - if s- errors are found, they will be fixed, but they won't change the -
me018: Content, really.
mn017: the content of the meetings. So.
fe008: Well, see, this is the - this is the issue. Subtleties.
fe016: Well, i- if Jane is clarifying question question, then, you know, how can they agree to it before they know her final version?
fe008: The other thing, too, is there can be subtleties where a person uses this word instead of that word, which @@ could've been transcribed in the other way.
me013: Yeah.
fe016: Thing -
fe008: And no- and they wouldn't have been slanderous if it had been this other word. You know?
me013: I- it - you know, there- there is a point at which I agree it becomes ridiculous because, you know, you could do this final thing and then a year from now somebody could say, you know, that should be a period and not a question mark. Right? And you don't - you - there's no way that we're gonna go back and ask everybody "do you approve this, uh, you know - this document now?" So - So I think what it is is that the - the - the - the thing that they sign - I - I haven't looked at it in a while, but it has to be open enough that it sort of says "OK, from now on - you know, now that I've read this, you can use - do anything you want with these data."
fe008: Mm-hmm.
me013: And, uh - But, i- I think we wanna - So, assuming that it's in that kind of wording, which I don't remember, um, I think i- we just wanna have enough confidence ourselves that it's so close to the final form it's gonna be in, a year from now that they're -
fe008: Mm-hmm. I agree. Mmm. I totally agree. It's just, uh, a question of,
me013: Uh.
fe008: uh, if - if the person is using the transcript as the way of them judging what they said and whether it was slanderous, then it seems like it's - it's - i- it needs to be more correct than if we could count on them re-listening to the meeting. Because it becomes, eh, in a way a - a f- uh, a legal document i- if they've agreed to that.
me013: Well, I forget how we end- Right. I forget how we ended up on this, but I remember my taking the position of not making it so - so easy for everybody to observe everything and Adam was taking the position of - of having it be really straightforward for people to check every aspect of it including the audio. And I don't remember who won, Adam or me, but - uh, the -
fe008: Well, if it's only the transcript, though - I mean, th- this - this is my point, that - that
me013: Uh, that- that's why I'm bringing this up again, because I can't remember how we ended up.
fe008: then it becomes -
me013: That it was the transcrip- He wanted to do a web interface that would make it -
fe008: Well, if it's just the audio - Well.
me013: that would give you access to the transcript and the audio. That's what Adam wanted.
fe008: Mm-hmm.
me013: And I don't remember how we ended up.
fe016: I mean, with the web interface it's interesting, because you could allow the person who signs to be informed when their transcript changes, or something like that. And, I mean, I would say " no ". Like, I don't wanna know, but some people might be really interested and then y- In other words, they would be informed if there was some significant change other than typos and things like that.
me013: You decided you were whispering Satanic incantations under your breath when you were -
fe016: Well, I don't know what happened to the small heads thing, but I j- Um, I'm just saying that, like, you know, you can sort of say that any things that are deemed -
me013: They disappeared from view.
fe016: Anyway. I mean, I agree that at some point people probably won't care about typos but they would care about significant meaning changes and then they could be asked for their consent, I guess, if - if those change. Cuz assumi- assuming we - we don't really distribute things that have any significant changes from what they sign anyway.
mn017: Tha- That's - How about having them approve the audio and not the transcripts?
fe016: Oh, my God.
me013: Uh.
fe008: That would be simpler, if we could count on them listening.
me018: Talk.
fe016: But no one will listen to the hours and hours of -
mn017: Well, that's O K. We just have to give them a chance to listen to it, and if they don't, that's their problem.
me001: That's - hmm, hmm.
fe016: You - you d-
fe008: Well.
fe016: That's like -
fe008: Unfortunately, uh, in - in the sign- thing that they signed, it says " transcripts ". "You'll be - you'll be provided the transcripts when they're available."
mn017: No, I'm serious. Really?
fe016: I- I - I think
me013: Yeah.
me001: Mmm.
mn014: Yeah.
mn017: Mmm.
fe016: that's a lot to ask for people that have been in a lot of meetings.
fe008: Yeah. Yeah.
me013: W- anyway, haven't we - we've gone down this path a number of times. I know this can lead to extended conversations and - and not really get anywhere, so let - let me just suggest that - uh, off-line that, uh, the people involved figure it out and take care of it before it's July.
fe008: Yes.
me013: OK. So - so that in July we can tell people
fe008: Yes.
me013: "yes, we have this and you can use it".
fe008: It's done, ready, available. Good.
me013: Uh. So, let's see. What else we got? Uh. Don did - did a report about his project in class and, uh - an oral and written - written version. So that was stuff he was doing with you.
fe016: Well. I mean, it's - I guess one thing we're learning is that the amount - We have
me013: Yeah.
fe016: eight meetings there because we couldn't use the non-native - all non-native meetings and it's, well, probably below threshold on enough data for us for the things we're looking at because the prosodic features are very noisy and so you - you need a lot of data in order to model them. Um, so we're starting to see some patterns and we're hoping that maybe with, I don't know, double or triple the data - with twenty meetings or so, that we would start to get better results. But we did find that some of the features that, I gue- Jane would know about, that are expressing sort of the distance of, um, boundaries from peaks in the utterance and some local, um, range - pitch range effects, like how close people are to their floor, are showing up in these classifiers, which are also being given some word features that are cheating, cuz they're true words. Um, so these are based on forced alignment. Word features like, um, word frequency and whether or not something's a backchannel and so forth. So, we're starting to see, I think, some
me013: So the dominant features, including everything, were those - those quasi-cheating things. Right? Where these are -
fe016: interesting patterns.
me001: Sometimes not.
fe016: I think it depends what you're looking at, a- actually.
me001: Yeah. Sometimes positions in sentences obviously, or in spurts, was helpful. I don't know if that's cheating, too.
fe016: Right. Um,
mn017: Spurts wouldn't be. Right?
fe016: spurts is not cheating except that of course you know the real words, but roughly speaking, the recognized words are gonna give you a similar type of position. It's either early or late.
me001: Right. Right. Would they give you the same number of words, though?
me013: Right.
fe016: Not exactly, but i-
mn017: No-
me001: But ra- somewhat?
fe016: Y- yeah it should be.
me013: On the average.
fe016: Well, we don't know and actually that's one of the things we're interested in doing, is a sort of -
mn017: Have you tried using just time, as opposed to number of words?
me013: Uh-huh.
fe016: So.
me001: I think ti- uh - Just p- time position, like when the word starts?
mn017: Yeah.
me001: I don't know if that was in the -
mn017: Well, no, I mean t- time - time position relative to the
fe016: Eh - You know, uh-
me001: Start.
mn017: beginning of the spurt.
fe016: Yeah, uh, we didn't try it, but it's s-
me001: Yeah. There's all these things to do. Like, there's a lot of different features you could just pull out.
mn017: Yeah. I mean that wouldn't be cheating because you can detect pause pretty well within the time.
me001: Right.
fe016: Right. And it depends on speaking rate -
me013: How about time position normalized by speak- Yeah. Yeah.
fe016: speaking rate. Yeah.
me001: Yeah.
fe016: Yeah. That's actually why I didn't use it at first. But we - one of the interesting things was
me013: Yeah.
mn017: Mm-hmm.
fe016: I guess you reported on some te- punctuation type - finding sentence boundaries, finding
me001: Yeah.
fe016: disfluency boundaries, and then I had done some work on finding from the foreground speech whether or not someone was likely to interrupt, so where - you know, if I'm talking now and someone - and - and Andreas is about to interrupt me, is he gonna choose a certain place in my speech, either prosodically or word-based. And there the prosodic features actually showed up and a neat thing - even though the word features were available. And a neat thing there too is I tried some - putting the speaker - So, I gave everybody a short version of their name. So the real names are in there, which we couldn't use. Uh, we should use IDs or something. And those don't show up. So that means that overall, um, it wasn't just modeling Morgan, or it wasn't just modeling a single person,
me013: Mm-hmm.
fe016: um, but was sort of trying to, uh, get a general idea - the model - the tree classifier was trying to find general locations that were applicable to different speakers, even though there are huge speaker effects. So. The - but the main limitation now is I - because we're only looking at things that happen every ten words or every twenty words, we need more - more data and more data per speaker. So. It'd also be interesting to look at the EDU meetings because we did include meeting type as a feature, so whether you were in a r- Meeting Recorder meeting or a Robustness meeting did matter to interrupts because there are just fewer interrupts in the Robustness meetings.
me001: Mm-hmm.
fe016: And so the classifier learns more about Morgan than it does about sort of the average person, which is
me013: Mm-hmm.
fe016: not bad. It'd probably do better than - Um, but it wasn't generalizing. So it's -
me013: Yeah.
fe016: And I think Don, um - Well, we have a long list of things he's starting to look at now over the summer, where we can - And he'll be able to report on more things in the future. But it was great that we could at least go from the - you know, Jane's transcripts and the, uh, recognizer output and get it to this point. And I think it's something Mari can probably use in her preliminary report - like, "yeah, we're at the point where we're training these classifiers and we're just reporting very preliminary but suggestive results that some features, both word and pro- prosodic, work. " The other thing that was interesting to me is that the pitch features are better than in Switchboard. And I think that really is from the close-talking mikes, cuz the pitch processing that was done has much cleaner behavior than - than the Switchboard telephone bandwidth.
me013: Hmm.
mn017: W- wh- wh- wh- Better in what sense?
fe016: Um. Well, first of all, the pitch tracks are m- have less, um, halvings and doublings than - than Switchboard and there's a lot less dropout, so if you ask how many regions where you would normally expect some vowels to be occurring
me013: Mm-hmm.
fe016: are completely devoid of pitch information, in other words the pitch tracker just didn't get a high enough probability of voicing for words - for - for,
me013: Hmm.
fe016: you know, five word- there are much fewer than in Switchboard. So the missing - We had a big missing data problem in Switchboard and, so the features weren't as reliable cuz they were often just not available. So that's actually good.
me018: Could it have to do with the - the lower frequency cut-off on the Switchboard?
fe016: Ma- maybe. I mean, the tele- we had telephone bandwidth for Switchboard and we had the an- annoying sort of telephone handset movement problem that I think may also affect it.
me018: Hmm.
fe016: So we're just getting better signals in - in this data. Which is nice. So.
me013: Yeah.
fe016: Anyway, Don's been doing a great job and we hope to
me013: Great.
fe016: continue with, um, Andreas's help and also some of Thilo's help on this, to - to try to get a non-cheating version of how all this would work.
mn014: Y- Yeah. Sure. Yeah.
me013: Has - has, uh - ? We just - I think, just talked about this the other day, but h- has - has anybody had a chance to try changing, uh, insertion penalty sort of things with the - with the, uh - uh, using the tandem system
mn017: Oh, yeah. I tried that. It didn't,
me013: input for the - ?
mn017: um, help dramatically. Um.
me018: Were they out of balance? I didn't - I didn't notice.
mn017: The - There were a little - the relative number of - I think there were a higher number of deletions, actually.
me013: Oh.
fe016: Deletions?
mn017: So, you, uh - So, actually it - it preferred to have a positive - er, negative insertion penalty, which means
me013: Uh- huh.
mn017: that, um - But, you know, it didn't change th- the - by adjusting that - the, um -
me013: OK.
mn017: Yeah. The error changed by probably one percent or so. But, you know, given that that word error rate is so high, that's not a -
me013: OK. So that - So that's - So that's not the problem. Yeah.
mn017: That's not the problem. No. But, uh, we s- just, um, uh - you know, Chuck and I talked and the @@ next thing to do is probably to tune the - um, the size of the Gaussian system, um, @@ to - to this - to this feature vector, which we haven't done at all. We just used the same configuration as we used for the -
me013: Hmm.
mn017: for the standard system. And, for instance, uh, Dan - @@ Dan just sent me a message saying that CMU used, um, something like ten Gaussians per cluster - @@ You know, each - each mixture has ten Gaussians
me018: Mm-hmm. Hmm. We're using sixty- four, right?
mn017: and - and we're using sixty-four, so that's
me018: Yeah.
mn017: obviously a big difference and it might be way off and give very poorly trained,
me013: Hmm.
mn017: uh, you know, Gaussians that way, uh, an- and poorly trained mixture weights. So - so, we have - The turn-around time on the training when we train only the - a male system with, uh, you know, our small training set, is less than twenty-four hours, so we can run lots of - uh, basically just brute force, try a whole bunch of different um, settings. And, uh, with the new machines it'll be even better. So.
me013: OK. Yeah. We get twelve of those, huh?
mn017: Yeah.
me013: OK.
mn017: But the PLP features work - um, uh, you know, continue to improve the, um - As I said before, the - uh using Dan's, uh, uh, vocal tract normalization option works very well.
me013: Mm-hmm.
mn017: So, um, @@ I ran one experiment where we're just did the vocal tract le- normalization only in the test data, so I didn't bother to retrain the models at all, and it improved by one percent, which is about what we get with - uh, with, you know, just @@ actually doing both training and test normalization, um, with, um, the, uh - uh, with the standard system. So, in a few hours we'll have the numbers for the - for retraining everything with vocal tract length normalization and - So, that might even improve it further.
me013: Great.
mn017: So, it looks like the PLfea- P features do very well now with - after having figured out all these little tricks to - to get it to work.
me013: Yeah.
mn017: So.
fe016: Wait. So you mean you improve one percent over
me013: Good.
fe016: a system that doesn't have any VT L in it already?
mn017: Exactly. Yeah.
fe016: OK.
me013: Yeah. OK . So then - then we'll have our baseline to - to compare the currently hideous, uh, uh, new thing with. But -
mn017: Right. a- Right. And - and what that suggests also is of course that the current
me013: Yeah.
mn017: Switchboard MLP isn't trained on very good features. Uh, because it was trained on whatever, you know, was used, uh, last time you did Hub-five stuff, which didn't have any of the -
me013: Right. But all of these effects were j- like a couple percent.
mn017: Uh.
me013: Right? I mean, y- the -
mn017: Well, but if you add them all up you have, uh, almost five percent difference now.
me013: Add all of them. I thought one was one point five percent and one was point eight.
mn017: Yeah. And now we have another percent with the VT L.
me013: That's three point three.
mn017: Um, actually, and it's, @@ um, What's actually qu- interesting is that with - um, well, you m- prob- maybe another half percent if you do the VTL in training, and then interestingly, if you optimize you get more of a win out of rescoring the, um, uh, the N best lists, uh, and optimizing the weights, um, uh than - Yeah.
me018: Than you do with the standard?
mn017: So -
me013: Yeah. But the part that's actually adjustment of the front- end per se as opposed to doing - putting VTLN in or something is - it was a couple percent.
mn017: Right.
me013: Right? It was - it was - there was - there was one thing that was one and a half percent and one that was point eight. So - and - and - let me see if I remember what they were. One of them was, uh, the change to, uh - because it did it all at once, to - uh, from bark scale to mel scale,
mn017: Mm-hmm.
me013: which I really feel like saying in quotes, because @@ they're essentially the same scale but the - but - but - but
fe016: Yeah. Why did that cha- ?
me013: any i- individual particular implementation of those things puts things in a particular place.
mn017: Mm-hmm.
me013: So that's why I wanted to look - I still haven't looked at it yet. I - I wanna look at exactly where the filters were in the two, and it -
mn017: Mm-hmm.
me013: it's probably something like there's one fewer or one more filter in the sub one kilohertz band and for whatever reason with this particular experiment it was better one way or the other.
mn017: Mm-hmm.
fe016: Hmm.
me013: Um, it could be there's something more fundamental but it - you know, I - I don't know it yet. And the other - and the other - that was like one and a half or something, and then there was point eight percent, which was - what was the other thing?
me018: Well, that was combined with the triangular. Right?
me013: Yeah. Those - those two were together. We d- weren't able to separate them out cuz it was just done in one thing. But then there was a point eight percent which was something else. Do you remember the - ?
me018: Yeah. Right. The low-frequency cut-off.
me013: Oh, yeah. So that was - that was, uh - that one I can claim credit for, uh, i- in terms of screwing it up in the first place. So that someone e- until someone else fixed it, which is that, um, I never put - when I- u- We had some problems before with offsets. This inf- this went back to, uh, I think Wall Street Journal. So we - we had, uh -
mn017: Hmm.
me013: ea- everybody else who was doing Wall Street Journal knew that there were big DC offsets in th- in these data - in those data and - and - and nobody happened to mention it to us, and we were getting these,
mn017: Hmm.
me013: like, really terrible results, like two, three times the error everybody else was getting. And then in casual conversation someone ment- mentioned "uh, well, I guess, you know, of course you're taking care of the offsets. " I said " what offsets?" And at that point, you know, we were pretty new to the data and we'd never really, like, looked at it on a screen and then when we just put it on the screen and wroop!
mn017: Mm-hmm.
me001: Mmm.
me013: there's this big DC offset.
mn017: Mm-hmm.
me013: So, um, in PLP-
fe016: There was a - like a hum or some- or - when they recorded it? Or just - ?
me013: No. It's just, it - it's - it's not at all uncommon for - for recorded electronics to have different, um, DC offsets.
fe016: Huh.
me013: It's - it's, you know, no big deal. It's - you know, you could have ten, twenty, maybe thirty millivolts, whatever, and it's consistently in there. The thing is, most people's front-ends have pre- emphasis with it, with zero at zero frequency, so that it's irrelevant. Uh, but with PL P, we didn't actually have that. We had - we had the equivalent of pre-emphasis in a - a, uh, Fletcher-Munson style weighting that occurs in the middle of PL P, but it doesn't actually have a zero at zero frequency, like, eh, uh, typical simple fr- pre- emphasis does.
fe016: Hmm.
me013: We had something more fancy. It was later on it didn't have that. So at that point I reali- "oh sh- we better have a - have a high-pass filter " just, you know - just take care of the problem. So I put in a high-pass filter at, uh, I think ninety - ninety hertz or so uh, for a sixteen kilohertz sampling rate. And I never put anything in to adjust it for different - different sampling rates. And so - well, so, you know, the code doesn't know anything about that and so this is all at eight kilohertz and so it was at forty- five hertz instead of at -
mn017: Hmm.
me013: instead of at ninety. So, um, I don't know if Dan fixed it or - or, uh,
mn017: Well, he made it a parameter.
me013: what he - He made it a parameter. So. Yeah, I guess if he did it right, he did fix it and then - and then it's taking care of sampling rate, which is great.
me018: What - what is the parameter? Is it, uh, just the f- lower cut-off that you want?
me013: He had a -
mn017: It's called, uh, H- HPF.
me013: H - Yeah. Does HPF on - on his feat- feature.
mn017: u- And - but HPF, you know, when you put a number after it, uses that as the
me018: Mm-hmm.
mn017: hertz value of the cut-off. So.
me013: Yeah.
me018: Oh, OK.
me013: I mean, frankly, we never did that with the RASTA filter either, so the RASTA filter is actually doing a different thing
mn017: Mm-hmm.
me013: in the modulation spectral domain depending on what sampling rate you're doing, which is another old - old bug of mine.
mn017: Mm-hmm.
me013: But, um - Um. So that - that was the problem there was th- we - we - we had always intended to cut off below a hundred hertz and it just
mn017: Mm-hmm.
me013: wasn't doing it, so now it is. So, that hep- that helped us by, like, eight tenths of a percent. It still wasn't a big deal.
mn017: OK. Well, but, um - Well, uh, again, after completing the current experiments, we'll - we can add up all the
me013: Oh, yeah. But -
mn017: uh differences and - and - an-
me013: but, I guess my - my point was that - that, um, the hybrid system thing that we did was, uh, primitive in many ways.
mn017: Y- Right.
me013: And I think I agree with you that if we fixed lots of different things and they would all add up, we would probably have a - a - a competitive system. But I think not that much of it is due to the front-end per se. I think maybe a couple percent of it is, as far as I can see from this.
mn017: Mm-hmm.
me013: Uh, unless you call - well, if you call VTL the front-en- front-end, that's, uh, a little more. But that's sort of more both, kind of. Right? But.
me018: One experiment we should - we'll probably need to do though when - um, at some point, is, since we're using that same - the net that was trained on PLP without all these things in it, for the tandem system, we may wanna go back and retrain,
mn017: Well, that's what I meant, in fact. Yeah.
me018: yeah, yeah, for the tandem. You know, so we can see if it - what effect it has on the tandem processing.
mn017: So - so, the thing is - is
me013: Mm-hmm.
mn017: do we expect - ? eh At this point I'm as- I mean, you know - e- I'm wondering is it - Can we expect, uh, a tandem system to do better than a properly trained - you know, a Gaussian system trained directly on the features with, you know, the right ch- choice of parameters?
me013: Well, that's what we're seeing in other areas. Yes. Right? So, it's - so, um, um -
me018: So, we - But - but we may not. I mean, if it doesn't perform as well, we may not know why. Right? Cuz we need to do
mn017: Right.
me018: the exact experiment.
me013: I mean, the reason to think it should is because you're putting in the same information and you're transforming it to be more discriminative. So. Um. Now the thing is, in some databases I wouldn't expect it to necessarily give you much and - and part of what I view as the real power of it is that it gives you a transformational capability for taking all sorts of different wild things that we do, not just th- the standard front-end, but other things, like with multiple streams and so forth,
mn017: Mm-hmm.
me013: and allows you to feed them to the other system with this - through this funnel. Um, so I think - I think that's the real power of it. I wouldn't expect huge in- huge improvements. Um, but it should at least be roughly the same and maybe a little better. If it's, you know, like way way worse then, you know -
mn017: Mm-hmm. Right.
me018: So, Morgan, an- another thing that Andreas and I were talking about was, so @@ in the first experiment that he did we just took the whole fifty-six, uh, outputs and that's, um, basically compared to a thirty-nine input feature vector
me013: Mm-hmm. Mm-hmm.
me018: from either MFCC or PLP. But one thing we could do is -
me013: Let - let me - let me just ask you something. When you say take the fifty-six outputs, these are the pre- final nonlinearity outputs and they're - and -
me018: Yeah. Through the regular tandem outputs.
me013: through the KLT.
me018: Through the KLT. All that kinda stuff.
me013: OK. And so - so then you u- Do you use all fifty-six of the KLT or - ?
me018: That's what we did. Right?
me013: OK.
me018: So one thing we were wondering is, if we did principal components and, say, took out just thirteen, and then did deltas and double-deltas on that - so we treated the th-
me013: Yes. Yes.
me018: first thirteen as though they were standard features.
me013: Yeah.
me018: I mean, did Dan do experiments like that to - ?
me013: Uh. Talk with Stephane. He did some things like that. It was either him or Carmen. I forget.
mn017: Mm-hmm.
me018: Mmm.
me013: I mean these were all different databases and different - you know, in HTK and all that, so i- it - it may not apply. But
me018: Yeah.
me013: my recollection of it was that it didn't make it better but it didn't make it worse.
me018: Hmm.
me013: But, again, given all these differences, maybe it's more important in your case that you not take a lot of these low-variance, uh, components.
me018: Cuz in a sense, the net's already got quite a bit of context in
me013: Yeah.
me018: those features, so if we did deltas and double-deltas on top of those, we're getting sort of even more.
me013: Which could be good or not. Yeah.
me018: Yeah.
me013: Yeah. Worth trying.
mn017: But there the main point is that, um, you know, it took us a while but we have the procedure for coupling the two systems debugged now and - I mean, there's still conceivably some bug somewhere in the way we're feeding the tandem features - uh, either generating them or feeding them to this - to the
me018: Mm-hmm. Yeah.
mn017: SRI system, but
me013: There might be, cuz that's a pretty big difference.
mn017: it's - Yeah.
me013: But
mn017: And I'm wondering how we can -
me018: Yeah.
mn017: how we can debug that. I mean how - Um.
me013: Hmm.
mn017: I'm actually f- quite sure that the -
me013: What if - ?
mn017: feeding the features into the system and training it up, that - that - I think that's - this - that's essentially the same as we use with the ce- with the PL P fe- features. And that's obviously working great. So. I- um.
me018: Yeah. There could be a bug in - in the -
mn017: There - we could -
me018: somewhere before that.
mn017: the - another degree of freedom is how do you generate the KL T transform?
me018: Mm-hmm.
me013: That's -
mn017: Right? We to-
me018: Right.
me013: well, and another one is the normalization of the inputs to the net.
mn017: Yeah.
me013: These nets are trained with particular normalization and when that gets screwed up it - it can really hurt it.
me018: I'm doing what Eric - E- Eric coached me through then - that part of it, so I'm pretty confident in that. I mean, the only
me013: OK.
me018: slight difference is that I use normalization values that, um, Andreas calculated from the original PLP, which is right. N- Yeah.
mn017: Right. Right.
me018: So, I u- I do - Oh, we actually don't do that normalization for the PLP, do we? For the st- just the straight PLP features?
mn017: No. The - the SRI system does it.
me018: SR I system does that. Right.
mn017: Yeah.
me013: Right. Well, you might e- e-
me018: So that's - that's another -
mn017: So, there's - there is - there is room for bugs that we might not have
me018: Yeah.
me013: Yeah.
me018: Mm-hmm.
me013: Yeah. I -
mn017: discovered, but -
me013: I would actually double check with Stephane at this point, cuz he's probably the one here - I mean, he and Dan are the ones who are at this point most experienced with the tandem
me018: Mm-hmm.
me013: thing and there may - there may be some little bit here and there that is not - not being handled right.
me018: Yeah. It's hard with features, cuz you don't know what they should look like. I mean, you can't just, like, print the - the values out in ASCII and, you know, look at them, see if they're -
me013: Not unless you had a lot of time and -
fe016: Well - eh, and also they're not - I mean, as I understand it, you - you don't have a way to optimize the features for the final word error. Right?
mn017: Right.
fe016: I mean, these are just discriminative, but they're not, um, optimized for the final -
mn017: They're optimized for phone discrimination, not for -
fe016: Right. So it - there's always this question of whether you might do better with those features if there was a way to train it
me013: That's right. Well, the other -
fe016: for the word error metric that you're actually -
me013: Yeah, th- the -
mn017: Mm- Mmm.
me013: Well, you actually are.
fe016: that you're actually -
me013: But - but it - but in an indirect way.
fe016: Well, right. It's indirect, so you don't know -
me013: So wha- w- what - an- and you may not be in this case, come to think of it, because, uh, you're just taking something that's trained up elsewhere. So, what - what you - what you do in the full procedure is you, um, uh, have an embedded training. So in fact you - the - the net is trained on, uh, uh, a, uh, Viterbi alignment of the training data that comes from your full system. And so that's where the feedback comes all around, so that it is actually discriminant. You can prove that it's - it's a, uh - If you believe in the Viterbi assumption that, uh, getting the best path, uh, is almost equivalent to getting the best, uh, total probability, um, then you actually do improve that by, uh - by training up on local - local, uh - local frames. But, um, we aren't actually doing that here, because we did - we did that for a hybrid system, and now we're plugging it into another system and so it isn't - i- i- i- it wouldn't quite apply here.
me018: So another huge experiment we could do would be to
mn017: Do y-
me018: take the tandem features, uh, do SRI
me013: Mm-hmm.
me018: forced alignments using those features, and then re-do the net with those.
fe016: Mmm, uh - Exactly. Exactly.
me013: Yeah.
fe016: So that you can optimize it for the word error. Yeah.
me013: Yeah. Another thing is since you're not using the net for recognition per se but just for this transformation, it's probably bigger than it needs to be.
mn017: But -
me013: So that would save a lot of time.
mn017: And there's a mismatch in the phone sets.
me018: Mmm.
mn017: So, you're using a l- a long- a larger phone set than what -
me013: Yeah. Actually all those things could - could - could - could, uh - could affect it as well.
me018: Yeah. Yeah.
me013: The other thing, uh, just to mention that Stephane - this was an innovation of Stephane's, which was a pretty neat one, uh, and might particularly apply here, given all these things we're mentioning. Um, Stephane's idea was that, um, discriminant, uh, approaches are great. Even the local ones, given, you know, these potential outer loops which, you know, you can convince yourself turn into the global ones. Um, however, there's times when it is not good. Uh, when something about the test set is different enough from the training set that - that, uh, the discrimination that you're learning is - is - is not a good one.
mn017: Mm-hmm.
me013: So, uh, his idea was to take as the input feature vector to the, uh, Gaussian mixture system, uh, a concatenation of the neural net outputs and the regular features.
fe016: Yeah. That -
mn017: Oh, we already talked about that.
me013: Yeah.
me018: Mm-hmm.
fe016: Didn't you - did you do that already or - ?
mn017: El- Yeah. No, but we - we - when - when we - when I first started corresponding with Dan about how to go about this,
fe016: Oh. That makes a lot of sense. Huh.
mn017: I think that was one of the things that we definitely went there .
me013: Yeah. Yeah. I mean, I'm sure that Stephane wasn't the first to think of it, but actually Stephane did it and -
mn017: Yeah. Uh-huh. And i- does it help?
me013: and - and it helped a lot. Yeah.
mn017: Oh, OK.
me013: So that's - that - that's our current best - best system in the, uh -
mn017: Oh. OK.
me013: uh, in the Aurora thing. Yeah.
fe016: Yeah. That makes sense.
mn017: And do you do a KLT transform on the con- on the combined feature vector?
fe016: As - you should never do worse.
me013: I - I, uh, missed what you said.
mn017: Do you - d- you do a KLT transform on the combined feature vector?
me013: Yeah.
mn017: OK.
me013: Well, actually, I, uh - you should check with him, because he tried several different combinations.
mn017: Because you end up with this huge feature vector, so that might be a problem, a- unless you do some form of dimensionality reduction.
me013: Yeah. I, uh, th- what I don't remember is which came out best. So he did one where he put o- put e- the whole thing into one KLT, and another one, since the - the PLP things are already orthogonalized,
mn017: Mm-hmm.
me013: he left them alone and - and just did a KLT on the - on the - on the net outputs and then concatenated that.
mn017: Mmm.
me013: And I don't remember which was better.
me018: Did he - did he try to - ? So he always ended up with a feature vector that was twice as long as either one of the - ?
me013: No. I don't know, i- I - I don't know. You have to check with him.
me018: Yeah.
mn017: OK. Actually, I have to run.
me013: I'm into big ideas these days.
fe016: Yeah.
mn017: Uh.
fe016: We need to close up cuz I need to save the data and,
me013: @@ Not to mention the fact that we're missing snacks. Yeah.
fe016: um, get a call. Right.
me013: Uh-
fe016: Did people wanna do the digits or, um, do them together? I don't know.
me013: Um. I - I g- I think, given that we're in a hurry for snacks, maybe we should do them together.
fe016: Should we just - ? OK. I mean, are we trying to do them in synchrony? That might be fun. Adam's not here, so he's not here to tell me no.
me013: Well, it's - it's - it's not - You know, it's not gonna work out but we could - we could just, uh, uh, see if we find a rhythm, you know, what -
fe016: Sure.
me013: Uh, O 's or zeroes, we wanna agree on that? @@
fe016: Maybe just whatever people would naturally do? I don't know.
me013: Oh, but if we were a singing group, we would wanna decide. Right?
fe016: Be harmony. Yeah. Yeah.
fe008: Mine's identical to yours. Is that correct?
me013: We might wa-
fe016: Sorry. So I set up and we didn't have enough digit forms so I xeroxed the same one seven times.
fe008: Oh. I see.
me013: So these are excellent.
fe008: Oh. I see.
me013: Why don't we do zer- i- Anyone have a problem with saying zero?
fe016: No.
me013: Is zero OK?
fe008: Yeah.
me013: OK. One and a two and three.
fe016: e-
me013: Once more with feeling. No, just k- just kidding.
fe016: And th-
me013: Oh, yeah. It was.
fe016: Light kind of music.
me001: We should start a cult.
me018: Yeah.
me013: It sounded like a cult, didn't it? Really. It sounded very lethargic.
me018: I needed protein. And now we're gonna go out and have snacks with no protein in them.
me001: It was the lack of prosodic, uh - Now we will eat snacks.
fe016: Exactly. Everybody sort of lowers their pitch range.
me001: Right, and applesauce.
me018: Ask everybody con- to contribute to the third worl-